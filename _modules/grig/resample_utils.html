<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>grig.resample_utils &#8212; Grig 1.0.1.dev4+g74c80f7 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/pyramid.css?v=a5b9c134" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <script src="../../_static/documentation_options.js?v=9559a862"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="../../_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head><body>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Grig 1.0.1.dev4+g74c80f7 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">grig.resample_utils</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for grig.resample_utils</h1><div class="highlight"><pre>
<span></span><span class="c1"># Licensed under a 3-clause BSD style license - see LICENSE.rst</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numba</span> <span class="k">as</span> <span class="nn">nb</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>
<span class="kn">from</span> <span class="nn">numba.typed</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">from</span> <span class="nn">numba.core</span> <span class="kn">import</span> <span class="n">boxing</span>
<span class="kn">from</span> <span class="nn">scipy.integrate</span> <span class="kn">import</span> <span class="n">nquad</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">gamma</span>
<span class="kn">from</span> <span class="nn">types</span> <span class="kn">import</span> <span class="n">ModuleType</span><span class="p">,</span> <span class="n">FunctionType</span>
<span class="kn">from</span> <span class="nn">gc</span> <span class="kn">import</span> <span class="n">get_referents</span>

<span class="kn">from</span> <span class="nn">grig.toolkit.func</span> <span class="kn">import</span> <span class="n">taylor</span>

<span class="n">nb</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">THREADING_LAYER</span> <span class="o">=</span> <span class="s1">&#39;threadsafe&#39;</span>
<span class="k">assert</span> <span class="n">List</span>
<span class="k">assert</span> <span class="n">Dict</span>
<span class="k">assert</span> <span class="n">boxing</span>

<span class="n">_condition_limit</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
<span class="n">_fast_flags</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nsz&#39;</span><span class="p">,</span> <span class="s1">&#39;nnan&#39;</span><span class="p">,</span> <span class="s1">&#39;ninf&#39;</span><span class="p">}</span>
<span class="n">_fast_flags_all</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nnan&#39;</span><span class="p">,</span>  <span class="c1"># no NaNs</span>
                   <span class="s1">&#39;ninf&#39;</span><span class="p">,</span>  <span class="c1"># no infinities</span>
                   <span class="s1">&#39;ninf&#39;</span><span class="p">,</span>  <span class="c1"># no signed zeros</span>
                   <span class="s1">&#39;nsz&#39;</span><span class="p">,</span>  <span class="c1"># no signed zeros</span>
                   <span class="s1">&#39;arcp&#39;</span><span class="p">,</span>  <span class="c1"># allow reciprocal</span>
                   <span class="s1">&#39;contract&#39;</span><span class="p">,</span>  <span class="c1"># allow floating-point contraction</span>
                   <span class="s1">&#39;afn&#39;</span><span class="p">,</span>  <span class="c1"># approximate functions</span>
                   <span class="s1">&#39;reassoc&#39;</span>  <span class="c1"># allow re association transformations</span>
                   <span class="p">}</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;polynomial_exponents&#39;</span><span class="p">,</span> <span class="s1">&#39;polynomial_derivative_map&#39;</span><span class="p">,</span>
           <span class="s1">&#39;evaluate_derivative&#39;</span><span class="p">,</span> <span class="s1">&#39;evaluate_derivatives&#39;</span><span class="p">,</span>
           <span class="s1">&#39;scale_coordinates&#39;</span><span class="p">,</span> <span class="s1">&#39;scale_forward_scalar&#39;</span><span class="p">,</span> <span class="s1">&#39;scale_forward_vector&#39;</span><span class="p">,</span>
           <span class="s1">&#39;scale_reverse_scalar&#39;</span><span class="p">,</span> <span class="s1">&#39;scale_reverse_vector&#39;</span><span class="p">,</span>
           <span class="s1">&#39;polynomial_terms&#39;</span><span class="p">,</span> <span class="s1">&#39;single_polynomial_terms&#39;</span><span class="p">,</span>
           <span class="s1">&#39;multiple_polynomial_terms&#39;</span><span class="p">,</span>
           <span class="s1">&#39;sscp&#39;</span><span class="p">,</span> <span class="s1">&#39;solve_coefficients&#39;</span><span class="p">,</span> <span class="s1">&#39;solve_amat_beta&#39;</span><span class="p">,</span> <span class="s1">&#39;fit_residual&#39;</span><span class="p">,</span>
           <span class="s1">&#39;weighted_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;weighted_variance&#39;</span><span class="p">,</span> <span class="s1">&#39;weighted_mean_variance&#39;</span><span class="p">,</span>
           <span class="s1">&#39;weighted_fit_variance&#39;</span><span class="p">,</span> <span class="s1">&#39;fit_phi_value&#39;</span><span class="p">,</span> <span class="s1">&#39;fit_phi_variance&#39;</span><span class="p">,</span>
           <span class="s1">&#39;solve_inverse_covariance_matrices&#39;</span><span class="p">,</span>
           <span class="s1">&#39;covariance_matrix_inverse&#39;</span><span class="p">,</span> <span class="s1">&#39;estimated_covariance_matrix_inverse&#39;</span><span class="p">,</span>
           <span class="s1">&#39;solve_rchi2_from_error&#39;</span><span class="p">,</span> <span class="s1">&#39;solve_rchi2_from_variance&#39;</span><span class="p">,</span>
           <span class="s1">&#39;solve_mean_fit&#39;</span><span class="p">,</span> <span class="s1">&#39;calculate_fitting_weights&#39;</span><span class="p">,</span>
           <span class="s1">&#39;fasttrapz&#39;</span><span class="p">,</span>
           <span class="s1">&#39;relative_density&#39;</span><span class="p">,</span>
           <span class="s1">&#39;array_sum&#39;</span><span class="p">,</span> <span class="s1">&#39;update_mask&#39;</span><span class="p">,</span>
           <span class="s1">&#39;multivariate_gaussian&#39;</span><span class="p">,</span>
           <span class="s1">&#39;shaped_adaptive_weight_matrices&#39;</span><span class="p">,</span>
           <span class="s1">&#39;shaped_adaptive_weight_matrix&#39;</span><span class="p">,</span>
           <span class="s1">&#39;scaled_adaptive_weight_matrices&#39;</span><span class="p">,</span>
           <span class="s1">&#39;scaled_adaptive_weight_matrix&#39;</span><span class="p">,</span>
           <span class="s1">&#39;calculate_adaptive_distance_weights_scaled&#39;</span><span class="p">,</span>
           <span class="s1">&#39;calculate_adaptive_distance_weights_shaped&#39;</span><span class="p">,</span>
           <span class="s1">&#39;calculate_distance_weights_from_matrix&#39;</span><span class="p">,</span>
           <span class="s1">&#39;calculate_distance_weights&#39;</span><span class="p">,</span>
           <span class="s1">&#39;coordinate_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;coordinate_covariance&#39;</span><span class="p">,</span> <span class="s1">&#39;offset_variance&#39;</span><span class="p">,</span>
           <span class="s1">&#39;variance_from_offsets&#39;</span><span class="p">,</span> <span class="s1">&#39;distribution_variances&#39;</span><span class="p">,</span>
           <span class="s1">&#39;derivative_mscp&#39;</span><span class="p">,</span>
           <span class="s1">&#39;check_edges&#39;</span><span class="p">,</span> <span class="s1">&#39;check_edge_with_ellipsoid&#39;</span><span class="p">,</span>
           <span class="s1">&#39;check_edge_with_distribution&#39;</span><span class="p">,</span> <span class="s1">&#39;check_edge_with_box&#39;</span><span class="p">,</span>
           <span class="s1">&#39;check_edge_with_range&#39;</span><span class="p">,</span>
           <span class="s1">&#39;check_orders&#39;</span><span class="p">,</span> <span class="s1">&#39;check_orders_with_bounds&#39;</span><span class="p">,</span>
           <span class="s1">&#39;check_orders_without_bounds&#39;</span><span class="p">,</span> <span class="s1">&#39;check_orders_with_counts&#39;</span><span class="p">,</span>
           <span class="s1">&#39;apply_mask_to_set_arrays&#39;</span><span class="p">,</span> <span class="s1">&#39;no_fit_solution&#39;</span><span class="p">,</span>
           <span class="s1">&#39;solve_polynomial_fit&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="s1">&#39;logistic_curve&#39;</span><span class="p">,</span>
           <span class="s1">&#39;half_max_sigmoid&#39;</span><span class="p">,</span> <span class="s1">&#39;stretch_correction&#39;</span><span class="p">,</span> <span class="s1">&#39;solve_fits&#39;</span><span class="p">,</span> <span class="s1">&#39;solve_fit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;convert_to_numba_list&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="polynomial_exponents">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.polynomial_exponents">[docs]</a>
<span class="k">def</span> <span class="nf">polynomial_exponents</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_max_order</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a set of polynomial exponents.</span>

<span class="sd">    The resampling algorithm uses defines a set of polynomial exponents as an</span>
<span class="sd">    array of shape (dimensions, terms) for an equation of the form:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f( \Phi ) = \sum_{m=1}^{M}{c_m \Phi_m}</span>

<span class="sd">    for :math:`M` terms.  Here, :math:`\Phi_m` represents the product of</span>
<span class="sd">    independent variables, each raised to an appropriate power as defined by</span>
<span class="sd">    `exponents`. For example, consider the equation for 2-dimensional data</span>
<span class="sd">    with independent variables :math:`x` and :math:`y`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x, y) = c_1 + c_2 x + c_3 x^2 + c_4 y + c_5 x y + c_6 y^2</span>

<span class="sd">    In this case::</span>

<span class="sd">        exponents = [[0, 0],  # represents a constant or x^0 y^0</span>
<span class="sd">                     [1, 0],  # represents x</span>
<span class="sd">                     [2, 0],  # represents x^2</span>
<span class="sd">                     [0, 1],  # represents y</span>
<span class="sd">                     [1, 1],  # represents xy</span>
<span class="sd">                     [0, 2]]  # represents y^2</span>

<span class="sd">    The resampling algorithm solves for the coefficients (:math:`c`) by</span>
<span class="sd">    converting :math:`f(X) \rightarrow f(\Phi)` for</span>
<span class="sd">    :math:`K-\text{dimensional}` independent variables (:math:`X`)</span>
<span class="sd">    and `exponents` (:math:`p`) by setting:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Phi_m = \prod_{k=1}^{K}{X_{k}^{p_{m, k}}}</span>

<span class="sd">    In most of the code, the :math:`\Phi` terms are interchangable with</span>
<span class="sd">    &quot;polynomial terms&quot;, and in the above example :math:`\Phi_5 = xy` since</span>
<span class="sd">    exponents[4] = [1, 1] representing :math:`x^1 y^1`.</span>

<span class="sd">    Note that for all terms (:math:`m`) in each dimension :math:`k`,</span>
<span class="sd">    :math:`\sum_{k=1}^{K}{p_{m, k}} \leq max(\text{order})`.  In addition,</span>
<span class="sd">    if `use_max_order` is `False` (default),</span>
<span class="sd">    :math:`p_{m,k} \leq \text{order}[k]`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    order : int or array_like of int</span>
<span class="sd">        Polynomial order for which to generate exponents.  If an array</span>
<span class="sd">        will create full polynomial exponents over all len(order)</span>
<span class="sd">        dimensions.</span>

<span class="sd">    ndim : int, optional</span>
<span class="sd">        If set, return Taylor expansion for `ndim` dimensions for</span>
<span class="sd">        the given `order` if `order` is not an array.</span>

<span class="sd">    use_max_order : bool, optional</span>
<span class="sd">        This keyword is only applicable for multi-dimensional data when orders</span>
<span class="sd">        are unequal across dimensions.  When `True`, the maximum exponent for</span>
<span class="sd">        each dimension is equal to max(order).  If `False`, the maximum</span>
<span class="sd">        available exponent for dimension k is equal to order[k].</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    exponents : numpy.ndarray</span>
<span class="sd">        (n_terms, n_dimensions) array of polynomial exponents.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; polynomial_exponents(3)</span>
<span class="sd">    array([[0],</span>
<span class="sd">           [1],</span>
<span class="sd">           [2],</span>
<span class="sd">           [3]])</span>

<span class="sd">    &gt;&gt;&gt; polynomial_exponents([1, 2])</span>
<span class="sd">    array([[0, 0],</span>
<span class="sd">           [1, 0],</span>
<span class="sd">           [0, 1],</span>
<span class="sd">           [1, 1],</span>
<span class="sd">           [0, 2]])</span>

<span class="sd">    &gt;&gt;&gt; polynomial_exponents(3, ndim=2)</span>
<span class="sd">    array([[0, 0],</span>
<span class="sd">           [1, 0],</span>
<span class="sd">           [2, 0],</span>
<span class="sd">           [3, 0],</span>
<span class="sd">           [0, 1],</span>
<span class="sd">           [1, 1],</span>
<span class="sd">           [2, 1],</span>
<span class="sd">           [0, 2],</span>
<span class="sd">           [1, 2],</span>
<span class="sd">           [0, 3]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">order</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Order must have 0 or 1 dimensions&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">order</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ndim</span> <span class="o">=</span> <span class="n">order</span><span class="o">.</span><span class="n">size</span>
        <span class="n">check_maximum_order</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">use_max_order</span>
        <span class="n">max_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">order</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ndim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ndim</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">check_maximum_order</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">max_order</span> <span class="o">=</span> <span class="n">order</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="nb">list</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">taylor</span><span class="p">(</span><span class="n">max_order</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">ndim</span><span class="p">))])</span>
    <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">exponents</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">check_maximum_order</span><span class="p">:</span>
        <span class="n">keep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">exponents</span> <span class="o">&gt;</span> <span class="n">order</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">exponents</span> <span class="o">=</span> <span class="n">exponents</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">exponents</span></div>



<div class="viewcode-block" id="polynomial_derivative_map">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.polynomial_derivative_map">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">polynomial_derivative_map</span><span class="p">(</span><span class="n">exponents</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a mapping from polynomial exponents to derivatives.</span>

<span class="sd">    Please see :func:`polynomial_exponents` for details on how a polynomial</span>
<span class="sd">    equation is defined within the resampling algorithm, and the use of the</span>
<span class="sd">    `exponents` array in defining the polynomial terms (:math:`\Phi`).</span>

<span class="sd">    Within the confines of the resampling algorithm, the polynomial exponents</span>
<span class="sd">    should have always been defined in a way that will always allow the</span>
<span class="sd">    derivative of a polynomial fit to be calculated from existing,</span>
<span class="sd">    pre-calculated :math:`\Phi` terms.</span>

<span class="sd">    For example, consider the 2-dimensional 2nd order polynomial equation and</span>
<span class="sd">    its derivatives in each dimension:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x, y) = c_1 + c_2 x + c_3 x^2 + c_4 y + c_5 x y + c_6 y^2</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial x} = c_2 + 2 c_3 x + c_5 y</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial y} = c_4 + c_5 x + 2 c_6 y</span>

<span class="sd">    Converting :math:`f(x, y) \rightarrow f(\Phi)` we get:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(\Phi) = c_1 \Phi_1 + c_2 \Phi_2 + c_3 \Phi_3 + c_4 \Phi_4 +</span>
<span class="sd">                  c_5 \Phi_5 + c_6 \Phi_6</span>

<span class="sd">    It can then be seen that</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial x} = c_2 \Phi_1 + 2 c_3 \Phi_2 + c_5 \Phi_4</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial y} = c_4 \Phi_1 + c_5 \Phi_2 + 2 c_6 \Phi_4</span>

<span class="sd">    Generalizing for a polynomial equation consisting of :math:`M` terms of the</span>
<span class="sd">    independent variable :math:`X` in :math:`K-\text{dimensions}`, a mapping</span>
<span class="sd">    (:math:`h`) can be devised enabling calculation of the derivatives from</span>
<span class="sd">    pre-existing terms.  For dimension :math:`k`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial X_k} = \sum_{m=1}^{M}</span>
<span class="sd">            {h_{k, 0, m} \cdot c_{h_{k, 1, m}} \cdot \Phi_{h_{k, 2, m}}}</span>

<span class="sd">    This allows the derivative to be calculated from the existing polynomial</span>
<span class="sd">    terms (:math:`\Phi`) and coefficients (:math:`c`).  In addition, the</span>
<span class="sd">    mapping can be calculated prior to reduction and will therefore only need</span>
<span class="sd">    to be calculated once along with :math:`\Phi`.  Once the coefficients are</span>
<span class="sd">    known, the derivatives can then be calculated using :math:`h`.</span>

<span class="sd">    Derivatives may be evaluated using :func:`evaluate_derivative` and</span>
<span class="sd">    :func:`evaluate_derivatives`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    exponents : numpy.ndarray (n_terms, n_dimensions)</span>
<span class="sd">        The exponents defining a polynomial equation.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    derivative_map : numpy.ndarray of int</span>
<span class="sd">        An array of shape (n_dimensions, 3, n_valid_terms).  The second</span>
<span class="sd">        dimension (of size 3) gives a constant multiplier in the first element,</span>
<span class="sd">        the coefficient index in the second element, and the phi index in the</span>
<span class="sd">        second element.  The third dimension will generally be of a smaller</span>
<span class="sd">        size than the number of terms in the polynomial equation as not all</span>
<span class="sd">        are required to calculate the derivative.  Due to the fact that some</span>
<span class="sd">        dimensions may contain more valid terms than others, `n_valid_terms`</span>
<span class="sd">        is set to the maximum number of valid terms over all dimensions.  Any</span>
<span class="sd">        invalid terms still remaining in the mapping array will have</span>
<span class="sd">        multipliers set to zero, and index pointers set to -1.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_terms</span><span class="p">,</span> <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">exponents</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">derivative_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n_terms</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>
    <span class="n">terms_found_per_dimension</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">term_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_terms</span><span class="p">):</span>
        <span class="n">term_exponents</span> <span class="o">=</span> <span class="n">exponents</span><span class="p">[</span><span class="n">term_index</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">dimension</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">terms_found</span> <span class="o">=</span> <span class="n">terms_found_per_dimension</span><span class="p">[</span><span class="n">dimension</span><span class="p">]</span>
            <span class="n">derivative_exponent</span> <span class="o">=</span> <span class="n">term_exponents</span><span class="p">[</span><span class="n">dimension</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">derivative_exponent</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># the term vanished</span>
                <span class="k">continue</span>

            <span class="c1"># Now search for matching exponents in the original exponent set</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_terms</span><span class="p">):</span>
                <span class="n">check_match</span> <span class="o">=</span> <span class="n">exponents</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">dimension</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">check_match</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">derivative_exponent</span><span class="p">:</span>
                            <span class="k">break</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">check_match</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">term_exponents</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                            <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># match found</span>
                    <span class="c1"># The lowered power as a constant in front of the new term</span>
                    <span class="n">derivative_map</span><span class="p">[</span><span class="n">dimension</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">terms_found</span><span class="p">]</span> <span class="o">=</span> <span class="n">term_exponents</span><span class="p">[</span>
                        <span class="n">dimension</span><span class="p">]</span>
                    <span class="c1"># The coefficient index</span>
                    <span class="n">derivative_map</span><span class="p">[</span><span class="n">dimension</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">terms_found</span><span class="p">]</span> <span class="o">=</span> <span class="n">term_index</span>
                    <span class="c1"># The index of the phi term that can be used</span>
                    <span class="n">derivative_map</span><span class="p">[</span><span class="n">dimension</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">terms_found</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
                    <span class="n">terms_found_per_dimension</span><span class="p">[</span><span class="n">dimension</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">break</span>

    <span class="c1"># Clean up</span>
    <span class="n">max_found</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">n_found</span> <span class="o">=</span> <span class="n">terms_found_per_dimension</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">n_found</span> <span class="o">&gt;</span> <span class="n">max_found</span><span class="p">:</span>
            <span class="n">max_found</span> <span class="o">=</span> <span class="n">n_found</span>
        <span class="n">derivative_map</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">n_found</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">derivative_map</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_found</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">derivative_map</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_found</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">return</span> <span class="n">derivative_map</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">max_found</span><span class="p">]</span></div>



<div class="viewcode-block" id="evaluate_derivative">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.evaluate_derivative">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">evaluate_derivative</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">phi_point</span><span class="p">,</span> <span class="n">derivative_map</span>
                        <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the derivative of a polynomial at a single point.</span>

<span class="sd">    Please see :func:`polynomial_derivative_map` for a full description of</span>
<span class="sd">    how the derivatives are calculated from a polynomial equation defined by</span>
<span class="sd">    :func:`polynomial_exponents`.  These also explain how one should transform</span>
<span class="sd">    the independent variables to the &quot;phi&quot; (:math:`\Phi`) terms (which may be</span>
<span class="sd">    done using :func:`polynomial_terms`).</span>

<span class="sd">    The derivative at a point is calculated by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial X_k} = \sum_{m=1}^{M}</span>
<span class="sd">            {h_{k, 0, m} \cdot c_{h_{k, 1, m}} \cdot \Phi_{h_{k, 2, m}}}</span>

<span class="sd">    for a polynomial equation consisting of :math:`M` terms at the coordinate</span>
<span class="sd">    :math:`X` in dimension :math:`k`, where :math:`h` is the derivative map.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coefficients : numpy.ndarray (n_terms,)</span>
<span class="sd">        The coefficients of the polynomial equation for each term.</span>
<span class="sd">    phi_point : numpy.ndarray (n_terms,)</span>
<span class="sd">        The polynomial terms of the fittin equation at a single coordinate.</span>
<span class="sd">    derivative_map : numpy.ndarray</span>
<span class="sd">        An array of shape (n_dimensions, 3, n_valid_terms).  The second</span>
<span class="sd">        dimension (of size 3) gives a constant multiplier in the first element,</span>
<span class="sd">        the coefficient index in the second element, and the phi index in the</span>
<span class="sd">        second element.  The third dimension will generally be of a smaller</span>
<span class="sd">        size than the number of terms in the polynomial equation as not all</span>
<span class="sd">        are required to calculate the derivative.  Due to the fact that some</span>
<span class="sd">        dimensions may contain more valid terms than others, `n_valid_terms`</span>
<span class="sd">        is set to the maximum number of valid terms over all dimensions.  Any</span>
<span class="sd">        invalid terms still remaining in the mapping array will have</span>
<span class="sd">        multipliers set to zero, and index pointers set to -1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    derivative : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The partial derivative of the polynomial equation with respect to each</span>
<span class="sd">        dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ndim</span> <span class="o">=</span> <span class="n">derivative_map</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nterms</span> <span class="o">=</span> <span class="n">derivative_map</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">ndim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">dimension_map</span> <span class="o">=</span> <span class="n">derivative_map</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">dimension_map</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">continue</span>

        <span class="n">value</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nterms</span><span class="p">):</span>
            <span class="n">lowered_power_constant</span> <span class="o">=</span> <span class="n">dimension_map</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">term</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">lowered_power_constant</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">coefficient</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">[</span><span class="n">dimension_map</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">term</span><span class="p">]]</span>
            <span class="n">term_phi</span> <span class="o">=</span> <span class="n">phi_point</span><span class="p">[</span><span class="n">dimension_map</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">term</span><span class="p">]]</span>
            <span class="n">value</span> <span class="o">+=</span> <span class="n">lowered_power_constant</span> <span class="o">*</span> <span class="n">coefficient</span> <span class="o">*</span> <span class="n">term_phi</span>

        <span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">return</span> <span class="n">gradients</span></div>



<div class="viewcode-block" id="evaluate_derivatives">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.evaluate_derivatives">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">evaluate_derivatives</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">phi_points</span><span class="p">,</span> <span class="n">derivative_map</span>
                         <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the derivative of a polynomial at multiple points.</span>

<span class="sd">    Please see :func:`polynomial_derivative_map` for a full description of</span>
<span class="sd">    how the derivatives are calculated from a polynomial equation defined by</span>
<span class="sd">    :func:`polynomial_exponents`.  These also explain how one should transform</span>
<span class="sd">    the independent variables to the &quot;phi&quot; (:math:`\Phi`) terms (which may be</span>
<span class="sd">    done using :func:`polynomial_terms`).</span>

<span class="sd">    The derivative at a point is calculated by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial X_k} = \sum_{m=1}^{M}</span>
<span class="sd">            {h_{k, 0, m} \cdot c_{h_{k, 1, m}} \cdot \Phi_{h_{k, 2, m}}}</span>

<span class="sd">    for a polynomial equation consisting of :math:`M` terms at the coordinate</span>
<span class="sd">    :math:`X` in dimension :math:`k`, where :math:`h` is the derivative map.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coefficients : numpy.ndarray (n_terms,)</span>
<span class="sd">        The coefficients of the polynomial equation for each term.</span>
<span class="sd">    phi_points : numpy.ndarray (n_terms, n_points)</span>
<span class="sd">        The polynomial terms of the fitting equation at a multiple points.</span>
<span class="sd">    derivative_map : numpy.ndarray</span>
<span class="sd">        An array of shape (n_dimensions, 3, n_valid_terms).  The second</span>
<span class="sd">        dimension (of size 3) gives a constant multiplier in the first element,</span>
<span class="sd">        the coefficient index in the second element, and the phi index in the</span>
<span class="sd">        second element.  The third dimension will generally be of a smaller</span>
<span class="sd">        size than the number of terms in the polynomial equation as not all</span>
<span class="sd">        are required to calculate the derivative.  Due to the fact that some</span>
<span class="sd">        dimensions may contain more valid terms than others, `n_valid_terms`</span>
<span class="sd">        is set to the maximum number of valid terms over all dimensions.  Any</span>
<span class="sd">        invalid terms still remaining in the mapping array will have</span>
<span class="sd">        multipliers set to zero, and index pointers set to -1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    derivatives : numpy.ndarray (n_dimensions, n_points)</span>
<span class="sd">        The partial derivative of the polynomial equation with respect to each</span>
<span class="sd">        dimension at each point.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ndim</span> <span class="o">=</span> <span class="n">derivative_map</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ndata</span> <span class="o">=</span> <span class="n">phi_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">nterms</span> <span class="o">=</span> <span class="n">derivative_map</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ndim</span><span class="p">,</span> <span class="n">ndata</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">dimension_map</span> <span class="o">=</span> <span class="n">derivative_map</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">dimension_map</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nterms</span><span class="p">):</span>
            <span class="n">lowered_power_constant</span> <span class="o">=</span> <span class="n">dimension_map</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">term</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">lowered_power_constant</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">coefficient</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">[</span><span class="n">dimension_map</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">term</span><span class="p">]]</span>
            <span class="k">if</span> <span class="n">coefficient</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">term_phi</span> <span class="o">=</span> <span class="n">phi_points</span><span class="p">[</span><span class="n">dimension_map</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">term</span><span class="p">]]</span>
            <span class="n">multiplier</span> <span class="o">=</span> <span class="n">lowered_power_constant</span> <span class="o">*</span> <span class="n">coefficient</span>

            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
                <span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">multiplier</span> <span class="o">*</span> <span class="n">term_phi</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">gradients</span></div>



<div class="viewcode-block" id="derivative_mscp">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.derivative_mscp">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">derivative_mscp</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">phi_samples</span><span class="p">,</span> <span class="n">derivative_map</span><span class="p">,</span>
                    <span class="n">sample_weights</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the weighted mean-square-cross-product (mscp) of sample derivatives.</span>

<span class="sd">    Given a polynomial equation of the form:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(\Phi) = c \cdot \Phi</span>

<span class="sd">    The derivative is calculated as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{\partial f}{\partial X_k} = \sum_{m=1}^{M}</span>
<span class="sd">        {h_{k, 0, m} \cdot c_{h_{k, 1, m}} \cdot \Phi_{h_{k, 2, m}}}</span>

<span class="sd">    for an equation of :math:`M` terms at the coordinate :math:`X` in</span>
<span class="sd">    dimension :math:`k`, where :math:`h` is the `derivative_map` and :math:`c`</span>
<span class="sd">    are the `coefficients`.  Please see :func:`polynomial_derivative_map` for</span>
<span class="sd">    a more complete description of the derivative calculation.</span>

<span class="sd">    One the derivatives (:math:`g = \frac{df}{dX}`) are calculated for all</span>
<span class="sd">    samples, they are averaged, and the cross-product is returned as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{g}^2 = \frac{1}{tr(W W^T)} g^T W W^T g</span>

<span class="sd">    where :math:`W = diag(\text{weights})`.</span>

<span class="sd">    For example, for polynomial fit of 2-dimensional data :math:`f(x, y)`, the</span>
<span class="sd">    returned matrix will be:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{g}^2 =</span>
<span class="sd">            \begin{bmatrix}</span>
<span class="sd">                \frac{\partial f}{\partial x} \frac{\partial f}{\partial x} &amp;</span>
<span class="sd">                \frac{\partial f}{\partial x} \frac{\partial f}{\partial y} \\</span>
<span class="sd">                \frac{\partial f}{\partial y} \frac{\partial f}{\partial x} &amp;</span>
<span class="sd">                \frac{\partial f}{\partial y} \frac{\partial f}{\partial y}</span>
<span class="sd">            \end{bmatrix}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coefficients : numpy.ndarray (n_terms,)</span>
<span class="sd">        The coefficients of a polynomial fit for each term.</span>
<span class="sd">    phi_samples : numpy.ndarray (n_terms, n_samples)</span>
<span class="sd">        The polynomial terms of the sample coordinates.  Please see</span>
<span class="sd">        :func:`polynomial_exponents` for a description of this variable.</span>
<span class="sd">    derivative_map : numpy.ndarray</span>
<span class="sd">        An array of shape (n_dimensions, 3, n_valid_terms).  Please see</span>
<span class="sd">        :func:`polynomial_derivative_map` for an explanation of this variable.</span>
<span class="sd">    sample_weights : numpy.ndarray (n_samples,)</span>
<span class="sd">        The weighting to apply to each sample when determining the weighted</span>
<span class="sd">        mean (as a multiplier).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mscp : numpy.ndarray (n_dimensions, n_dimensions)</span>
<span class="sd">        An array where sscp[i, j] = derivative[i] * derivative[j].</span>
<span class="sd">        where derivative is the weighted mean derivatives over all samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">evaluate_derivatives</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">phi_samples</span><span class="p">,</span> <span class="n">derivative_map</span><span class="p">)</span>
    <span class="n">gradient_mscp</span> <span class="o">=</span> <span class="n">sscp</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">gradient_mscp</span></div>



<div class="viewcode-block" id="scale_coordinates">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.scale_coordinates">[docs]</a>
<span class="k">def</span> <span class="nf">scale_coordinates</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply scaling factors and offsets to N-dimensional data.</span>

<span class="sd">    The two available transforms are controlled by the `reverse`.  The</span>
<span class="sd">    transform functions apply the following functions:</span>

<span class="sd">    +-----------------+----------------------+</span>
<span class="sd">    |    Reverse      | f(x)                 |</span>
<span class="sd">    +=================+======================+</span>
<span class="sd">    | False (default) | (x - offset) / scale |</span>
<span class="sd">    +-----------------+----------------------+</span>
<span class="sd">    | True            | (x * scale) + offset |</span>
<span class="sd">    +-----------------+----------------------+</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (N, M) or (N,)</span>
<span class="sd">        Either a 1 or 2-dimensional array may be supplied.  If a 1-dimensional</span>
<span class="sd">        array is supplied, it is assumed that it represents a single</span>
<span class="sd">        coordinates in N-dimensions.  If a 2-dimensional array is supplied,</span>
<span class="sd">        it should be of shape (N, M) where N is the number of dimensions, and</span>
<span class="sd">        M is the number of coordinates.</span>
<span class="sd">    scale : numpy.ndarray (N,)</span>
<span class="sd">        The scaling factor to apply to each dimension.</span>
<span class="sd">    offset : numpy.ndarray (N,)</span>
<span class="sd">        The offset to apply to each dimension.</span>
<span class="sd">    reverse : bool, optional</span>
<span class="sd">        If `True`, apply the reverse transform.  The default is `False`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (N, M) or (N,)</span>
<span class="sd">        The scaled `coordinates` array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scalar</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">reverse</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">scalar</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">scale_reverse_scalar</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">scale_reverse_vector</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">scalar</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">scale_forward_scalar</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">scale_forward_vector</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span></div>



<div class="viewcode-block" id="scale_forward_scalar">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.scale_forward_scalar">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scale_forward_scalar</span><span class="p">(</span><span class="n">coordinate</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the function `f(x) = (x - offset) / scale` to a single coordinate.</span>

<span class="sd">    This is a :mod:`numba` jit compiled function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinate : numpy.ndarray (N,)</span>
<span class="sd">        An array where N is the number of dimensions.</span>
<span class="sd">    scale : numpy.ndarray (N,)</span>
<span class="sd">        The scaling factor to apply to each dimension.</span>
<span class="sd">    offset : numpy.ndarray (N,)</span>
<span class="sd">        The offset to apply to each dimension.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (N,)</span>
<span class="sd">        The scaled `coordinates` array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">coordinate</span><span class="o">.</span><span class="n">size</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">coordinate</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">offset</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">/</span> <span class="n">scale</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="scale_forward_vector">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.scale_forward_vector">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scale_forward_vector</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the function `f(x) = (x - offset) / scale` to a coordinate array.</span>

<span class="sd">    This is a :mod:`numba` jit compiled function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (N, M)</span>
<span class="sd">        An array where N is the number of dimensions, and M is the number of</span>
<span class="sd">        coordinates.</span>
<span class="sd">    scale : numpy.ndarray (N,)</span>
<span class="sd">        The scaling factor to apply to each dimension.</span>
<span class="sd">    offset : numpy.ndarray (N,)</span>
<span class="sd">        The offset to apply to each dimension.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (N, M)</span>
<span class="sd">        The scaled `coordinates` array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">ndata</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">features</span><span class="p">,</span> <span class="n">ndata</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
            <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">coordinates</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">offset</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">/</span> <span class="n">scale</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="scale_reverse_vector">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.scale_reverse_vector">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scale_reverse_vector</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the function `f(x) = (x * scale) + offset` to a coordinate array.</span>

<span class="sd">    This is a :mod:`numba` jit compiled function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (N, M)</span>
<span class="sd">        An array where N is the number of dimensions, and M is the number of</span>
<span class="sd">        coordinates.</span>
<span class="sd">    scale : numpy.ndarray (N,)</span>
<span class="sd">        The scaling factor to apply to each dimension.</span>
<span class="sd">    offset : numpy.ndarray (N,)</span>
<span class="sd">        The offset to apply to each dimension.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (N, M)</span>
<span class="sd">        The scaled `coordinates` array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">ndata</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">features</span><span class="p">,</span> <span class="n">ndata</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
            <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">scale</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">offset</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="scale_reverse_scalar">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.scale_reverse_scalar">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scale_reverse_scalar</span><span class="p">(</span><span class="n">coordinate</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">offset</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the function `f(x) = (x * scale) + offset` to a single coordinate.</span>

<span class="sd">    This is a :mod:`numba` jit compiled function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinate : numpy.ndarray (N,)</span>
<span class="sd">        An array where N is the number of dimensions.</span>
<span class="sd">    scale : numpy.ndarray (N,)</span>
<span class="sd">        The scaling factor to apply to each dimension.</span>
<span class="sd">    offset : numpy.ndarray (N,)</span>
<span class="sd">        The offset to apply to each dimension.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (N,)</span>
<span class="sd">        The scaled `coordinates` array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">coordinate</span><span class="o">.</span><span class="n">size</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">coordinate</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">scale</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">offset</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="polynomial_terms">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.polynomial_terms">[docs]</a>
<span class="k">def</span> <span class="nf">polynomial_terms</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">exponents</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Derive polynomial terms given coordinates and polynomial exponents.</span>

<span class="sd">    Raises a single coordinate or multiple coordinates by a power and then</span>
<span class="sd">    calculates the product over all dimensions.  For example, the output of</span>
<span class="sd">    an (x, y) vector with `exponent=[[2, 3]]` would be :math:`x^2y^3`.</span>

<span class="sd">    Note that multiple sets of exponents are expected to be provided during</span>
<span class="sd">    this operation, so the `exponents` parameter should be a 2-dimensional</span>
<span class="sd">    array.  If a single N-dimensional vector is provided, the output will be</span>
<span class="sd">    a 1-dimensional array with a single value for each exponent set.  If</span>
<span class="sd">    multiple vectors are provided, the output will be of shape (number of</span>
<span class="sd">    exponent sets, number of vectors).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (N, n_vectors) or (N,)</span>
<span class="sd">        Sets of coordinates in N-dimensions or a single coordinate of</span>
<span class="sd">        N-dimensions.</span>
<span class="sd">    exponents : numpy.ndarray (n_exponents, N)</span>
<span class="sd">        Sets of polynomial exponents to apply to coordinates.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (n_exponents, n_vectors) or (n_exponents,)</span>
<span class="sd">        The polynomial terms.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">multiple_polynomial_terms</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">exponents</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">single_polynomial_terms</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">exponents</span><span class="p">)</span></div>



<div class="viewcode-block" id="single_polynomial_terms">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.single_polynomial_terms">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">single_polynomial_terms</span><span class="p">(</span><span class="n">coordinate</span><span class="p">,</span> <span class="n">exponents</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Derive polynomial terms for a single coordinate given polynomial exponents.</span>

<span class="sd">    Raises a single coordinate by a power and then calculates the product over</span>
<span class="sd">    all dimensions.  For example, the output of an (x, y) vector with</span>
<span class="sd">    `exponent=[[2, 3]]` would be :math:`x^2y^3`.</span>

<span class="sd">    Note that multiple sets of exponents are expected to be provided during</span>
<span class="sd">    this operation, so the `exponents` parameter should be a 2-dimensional</span>
<span class="sd">    array.  The return value will be a 1-dimensional array with size equal</span>
<span class="sd">    to the number of exponent sets provided.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinate : numpy.ndarray (N,)</span>
<span class="sd">        The coordinate in each dimension.</span>
<span class="sd">    exponents : numpy.ndarray (n_exponents, N)</span>
<span class="sd">        Sets of exponents to apply to the coordinate.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (n_exponents,)</span>
<span class="sd">        The polynomial terms for the coordinate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_coefficients</span><span class="p">,</span> <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">exponents</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">pp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_coefficients</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coefficients</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">coordinate</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">exponent</span> <span class="o">=</span> <span class="n">exponents</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">val_e</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">exponent</span><span class="p">):</span>
                <span class="n">val_e</span> <span class="o">*=</span> <span class="n">val</span>
            <span class="n">x</span> <span class="o">*=</span> <span class="n">val_e</span>
        <span class="n">pp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">pp</span></div>



<div class="viewcode-block" id="multiple_polynomial_terms">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.multiple_polynomial_terms">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiple_polynomial_terms</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">exponents</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Derive polynomial terms for a coordinate set given polynomial exponents.</span>

<span class="sd">    Raises multiple coordinates by a power and then calculates the product over</span>
<span class="sd">    all dimensions.  For example, the output of an (x, y) vector with</span>
<span class="sd">    `exponent=[[2, 3]]` would be :math:`x^2y^3`.</span>

<span class="sd">    Note that multiple sets of exponents are expected to be provided during</span>
<span class="sd">    this operation, so the `exponents` parameter should be a 2-dimensional</span>
<span class="sd">    array.  The return value will be a 2-dimensional array with the size of</span>
<span class="sd">    the first dimension equal to the number of exponent sets, and the size of</span>
<span class="sd">    the second dimension equal to the number of vector sets.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (N, n_vectors)</span>
<span class="sd">        Sets of vectors in N-dimensions.</span>
<span class="sd">    exponents : numpy.ndarray (n_exponents, N)</span>
<span class="sd">        Sets of exponents by which to raise the vector.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (n_exponents, n_vectors)</span>
<span class="sd">        The product of the exponentiation of the vectors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_coefficients</span><span class="p">,</span> <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">exponents</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n_vectors</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">pp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_coefficients</span><span class="p">,</span> <span class="n">n_vectors</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vectors</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coefficients</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="n">exponent</span> <span class="o">=</span> <span class="n">exponents</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">val_e</span> <span class="o">=</span> <span class="mf">1.0</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">exponent</span><span class="p">):</span>
                    <span class="n">val_e</span> <span class="o">*=</span> <span class="n">val</span>
                <span class="n">x</span> <span class="o">*=</span> <span class="n">val_e</span>
            <span class="n">pp</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">pp</span></div>



<div class="viewcode-block" id="sscp">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.sscp">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sscp</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the sum-of-squares-and-cross-products of a matrix.</span>

<span class="sd">    For the matrix :math:`A`, calculates :math:`A^TA`.  If weights (:math:`W`)</span>
<span class="sd">    are provided.</span>

<span class="sd">    .. math::</span>

<span class="sd">        sscp = WA^TAW^T</span>

<span class="sd">    Note that the `weight` should only contain the diagonal elements of</span>
<span class="sd">    :math:`W`, and as such should be a 1-dimensional array.</span>

<span class="sd">    If `normalize=True`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        sscp = \frac{WA^TAW^T}{trace(W^TW)}</span>

<span class="sd">    where :math:`W = I`, the identity matrix if `weight` is not supplied.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    matrix : numpy.ndarray (M, N)</span>
<span class="sd">        Input matrix.</span>
<span class="sd">    weight : numpy.ndarray (N,), optional</span>
<span class="sd">        Weights to be applied during sscp.</span>
<span class="sd">    normalize : bool, optional</span>
<span class="sd">        If True, scales result as described above.  Default is False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray of numpy.float64 (M, M)</span>
<span class="sd">        Square output array containing the sum-of-squares-and-cross-products</span>
<span class="sd">        matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
                <span class="n">a_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                    <span class="n">a_sum</span> <span class="o">+=</span> <span class="n">matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">matrix</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="n">ata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_sum</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">ata</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_sum</span>
        <span class="n">w2sum</span> <span class="o">=</span> <span class="n">n</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">w2sum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">w2</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">weight</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
                <span class="n">w2sum</span> <span class="o">+=</span> <span class="n">w2</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
                <span class="n">a_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                    <span class="n">a_sum</span> <span class="o">+=</span> <span class="n">w2</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">matrix</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="n">ata</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_sum</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">ata</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_sum</span>

    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">ata</span> <span class="o">/=</span> <span class="n">w2sum</span>

    <span class="k">return</span> <span class="n">ata</span></div>



<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scaled_matrix_inverse</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the inverse of a matrix scaled by N / (N - rank(matrix)).</span>

<span class="sd">    The return value given `matrix` :math:`A` is</span>

<span class="sd">    .. \frac{N}{N - rank(A)} A^{-1}</span>

<span class="sd">    Note that if `n` is not provided or `rank` &gt;= `n`, the return value will</span>
<span class="sd">    be :math:`A^{-1}` and :math:`A^{-1}A = I`.  Otherwise, if scaling is</span>
<span class="sd">    applied, the diagonal elements of :math:`A^{-1}A` will be equal to</span>
<span class="sd">    :math:`N / (N - rank(A))`, with offset elements equal to zero.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    matrix : (N, M)</span>
<span class="sd">        Matrix to invert</span>
<span class="sd">    n : int or float, optional</span>
<span class="sd">        Refers to N in the above description.  If not passed in, no scaling</span>
<span class="sd">        will occur.</span>
<span class="sd">    rank : int or float, optional</span>
<span class="sd">        The rank of the matrix, optionally passed in for speed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inverse_matrix (M, N)</span>
<span class="sd">        The inverse of matrix A where the diagonal elements of A^(-1)A are</span>
<span class="sd">        equal to N / (N - rank(A)) if scaling options were provided, else</span>
<span class="sd">        A^(-1)A = I.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="k">return</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>


<div class="viewcode-block" id="solve_coefficients">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_coefficients">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_coefficients</span><span class="p">(</span><span class="n">amat</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Find least squares solution of Ax=B and rank of A.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    amat : numpy.ndarray (ncoeffs, ndata)</span>
<span class="sd">        The coefficient array.</span>
<span class="sd">    beta : numpy.ndarray (ncoeffs,) or (ncoeffs, N)</span>
<span class="sd">        Dependent values.  If 2-dimensional, the least-squares solution is</span>
<span class="sd">        calculated for each column.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rank, x : int, numpy.ndarray (min(M, N),)</span>
<span class="sd">        The rank of `amat` and least-squares solution of x.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">coefficients</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">amat</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rank</span><span class="p">,</span> <span class="n">coefficients</span></div>



<div class="viewcode-block" id="solve_amat_beta">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_amat_beta">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_amat_beta</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convenience function returning matrices suitable for linear algebra.</span>

<span class="sd">    Given independent variables :math:`\Phi`, data :math:`y`, and weights</span>
<span class="sd">    :math:`W`, returns matrices :math:`A` and :math:`B` where:</span>

<span class="sd">    .. math::</span>

<span class="sd">        A = \Phi W \Phi^T</span>

<span class="sd">        B = \Phi W y</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    phi : numpy.ndarray (n_terms, n_samples)</span>
<span class="sd">        Polynomial terms of independent variables for each sample in the fit.</span>
<span class="sd">    data : numpy.ndarray (n_samples,)</span>
<span class="sd">        Sample data values.</span>
<span class="sd">    weights : numpy.ndarray (n_samples,)</span>
<span class="sd">        Squared weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    A, B : numpy.ndarray (n_terms, n_terms), numpy.ndarray (n_terms,)</span>
<span class="sd">        The :math:`A` and :math:`B` terms described above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ncoeffs</span><span class="p">,</span> <span class="n">ndata</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">ncoeffs</span><span class="p">,</span> <span class="n">ndata</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">ncoeffs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">sqrt_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">ndata</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
        <span class="n">sqrt_weight</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncoeffs</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">sqrt_weight</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">wa</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
            <span class="n">b</span> <span class="o">+=</span> <span class="n">wa</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">wa</span>
        <span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

    <span class="n">amat</span> <span class="o">=</span> <span class="n">sscp</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">amat</span><span class="p">,</span> <span class="n">beta</span></div>



<div class="viewcode-block" id="relative_density">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.relative_density">[docs]</a>
<span class="k">def</span> <span class="nf">relative_density</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">weight_sum</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">max_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the relative density of samples compared to a uniform distribution.</span>

<span class="sd">    The relative local density is defined as 1 for a uniform distribution,</span>
<span class="sd">    &lt; 1 for a distribution that is sparse near the center, and &gt; 1 when</span>
<span class="sd">    clustered around the center.</span>

<span class="sd">    The sum of the `distance_weights` returned from a Gaussian weighting</span>
<span class="sd">    function on the samples is required for this calculation.  The</span>
<span class="sd">    weighting function should be of the form:</span>

<span class="sd">    .. math::</span>

<span class="sd">        w(\Delta x) = exp \left(</span>
<span class="sd">            -\sum_{k=1}^{K}{\frac{-\Delta x_k^2}{2 \sigma_k^2}}</span>
<span class="sd">            \right)</span>

<span class="sd">    over :math:`K` dimensions where :math:`\Delta x_k` is the offset of a</span>
<span class="sd">    sample in dimension :math:`k` from the point of interest, and</span>
<span class="sd">    :math:`\sigma` must be supplied to `relative_density` as `sigma`, where</span>
<span class="sd">    `distance_weights` = :math:`\sum_{i=1}^{N}{w(x_i)}` and</span>
<span class="sd">    `counts` = :math:`N`.  Note that :math:`\sigma` and :math:`x` must be</span>
<span class="sd">    scaled such that the principle axis of an ellipsoid window</span>
<span class="sd">    containing all samples are equal to unity (principle axis in dimension</span>
<span class="sd">    :math:`k` is :math:`\Omega_k = 1` such that</span>
<span class="sd">    :math:`\prod_{k=1}^{K}{\Omega_k} = 1` below).</span>

<span class="sd">    The local relative density is then given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \rho = \frac{\rho(\text{measured})}{\rho(\text{uniform})}</span>

<span class="sd">    where,</span>

<span class="sd">    .. math::</span>

<span class="sd">        \rho(\text{uniform}) = N \frac{\Gamma \left( 1 + \frac{K}{2} \right)}</span>
<span class="sd">                                      {\pi^{K/2} \prod_{k=1}^{K}{\Omega_k}}</span>

<span class="sd">    .. math::</span>

<span class="sd">        \rho(\text{measured}) = \frac</span>
<span class="sd">            {\sum_{i=1}^{N}{w_i}}</span>
<span class="sd">            {\int \cdots \int_{R} w(\mathbf{\Delta x}) \, {dx}_1 \cdots {dx}_K}</span>

<span class="sd">    and region :math:`R` satisfies the requirement</span>
<span class="sd">    :math:`\| \mathbf{\Delta x} \|_2 \leq 1`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sigma : np.ndarray (n_dimensions,)</span>
<span class="sd">        The standard deviation of the Gaussian weighting function used to</span>
<span class="sd">        calculate the `distance_weights` for each dimension.</span>
<span class="sd">    counts : int or float or numpy.ndarray (N,)</span>
<span class="sd">        The number of data samples included in the sum of distance weights.</span>
<span class="sd">    weight_sum : int or float or numpy.ndarray (N,)</span>
<span class="sd">        The sum of weights as returned from a Gaussian weighting function.</span>
<span class="sd">    tolerance : float, optional</span>
<span class="sd">        Relative error tolerance passed to `scipy.integrate.quad` when</span>
<span class="sd">        determining the integral of the weighting function.  The default of</span>
<span class="sd">        10^(2*dim - 7) determined by testing, balancing precision with</span>
<span class="sd">        speed and convergence.</span>
<span class="sd">    max_dim : int, optional</span>
<span class="sd">        If the number of dimensions is greater than max_dim, do not attempt</span>
<span class="sd">        to calculate the relative density since the integral calculation</span>
<span class="sd">        is unlikely to converge and will take a vast amount of time.  The</span>
<span class="sd">        return output will be 1.0 or an array of ones (N,).  The maximum</span>
<span class="sd">        recommended number of dimensions is 4 (default).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray of float64 (N,)</span>
<span class="sd">        The relative density.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">.</span><span class="n">size</span>  <span class="c1"># number of dimensions</span>

    <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">max_dim</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">weight_sum</span> <span class="o">*</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">tolerance</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">tolerance</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">-</span> <span class="mi">7</span><span class="p">)</span>

    <span class="c1"># Assumes the window is 1 in all dimensions.  Coordinates passed into the</span>
    <span class="c1"># distance weighting function and sigma should be scaled accordingly.</span>
    <span class="n">prod_omega</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="n">window_volume</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">**</span> <span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">prod_omega</span>
    <span class="n">window_volume</span> <span class="o">/=</span> <span class="n">gamma</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">uniform_density</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">window_volume</span>

    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="n">limits</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]]</span> <span class="o">*</span> <span class="n">m</span>

    <span class="k">def</span> <span class="nf">nd_weighting</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">args</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">calculate_windowed_distance_weight</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">opts</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">tolerance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">options</span><span class="p">[</span><span class="s1">&#39;epsrel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">tolerance</span><span class="p">)</span>

        <span class="c1"># Assign break points in the function</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">options</span><span class="p">[</span><span class="s1">&#39;points&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">points</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">points</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
                <span class="n">options</span><span class="p">[</span><span class="s1">&#39;points&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="n">points</span><span class="p">,</span> <span class="n">points</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">options</span>

    <span class="n">integration</span> <span class="o">=</span> <span class="n">nquad</span><span class="p">(</span><span class="n">nd_weighting</span><span class="p">,</span> <span class="n">limits</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">[</span><span class="n">opts</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">weight_sum</span> <span class="o">/</span> <span class="n">uniform_density</span> <span class="o">/</span> <span class="n">integration</span>

    <span class="k">return</span> <span class="n">result</span></div>



<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">calculate_windowed_distance_weight</span><span class="p">(</span>
        <span class="n">coordinate</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates exp(-(dx^2) / alpha) for a single coordinate.</span>

<span class="sd">    If the L2 norm of dx &gt; 1, then the returned weight is zero.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinate : numpy.ndarray (ndim,)</span>
<span class="sd">        The coordinate in each dimension.</span>
<span class="sd">    center : numpy.ndarray (ndim,)</span>
<span class="sd">        The center in each dimension where dx = coordinate - center.</span>
<span class="sd">    alpha : numpy.ndarray (ndim,)</span>
<span class="sd">        The alpha values for each dimension.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weight : float</span>
<span class="sd">        The returned weight.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">coordinate</span><span class="o">.</span><span class="n">size</span>

    <span class="n">weight</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">coordinate</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">coordinate</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">center</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">d</span> <span class="o">*=</span> <span class="n">d</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">weight</span> <span class="o">+=</span> <span class="n">d</span>

    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">weight</span><span class="p">)</span>


<div class="viewcode-block" id="fit_residual">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.fit_residual">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fit_residual</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the residual of a polynomial fit to data.</span>

<span class="sd">    The residual is calculated using the matrix operation Y - CX where</span>
<span class="sd">    Y is the `dataset`, C are the `coefficients` and X is the `phi` polynomial</span>
<span class="sd">    terms.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : numpy.ndarray (n_samples,)</span>
<span class="sd">        Data from which coefficients were derived.</span>
<span class="sd">    phi : numpy.ndarray (n_terms, n_samples)</span>
<span class="sd">        Polynomial terms of independent values of each sample.</span>
<span class="sd">    coefficients : numpy.ndarray (n_terms,)</span>
<span class="sd">        Coefficient values.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    residual : numpy.ndarray (n_samples,)</span>
<span class="sd">        The residual</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">phi</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">residual</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">residual</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">residual</span></div>



<div class="viewcode-block" id="weighted_mean">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.weighted_mean">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">weighted_mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the weighted mean of a data set.</span>

<span class="sd">    The weighted mean of data :math:`y` with weights :math:`w` is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{y} = \frac{\sum_{i=1}^{N}{w_i y_i}}</span>
<span class="sd">                       {\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    This is a jit compiled :mod:`numba` function for use within other</span>
<span class="sd">    functions in `sofia_redux.toolkit.resampling`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : numpy.ndarray (ndata,)</span>
<span class="sd">        Data.</span>
<span class="sd">    weights : numpy.ndarray (ndata,)</span>
<span class="sd">        Weights.</span>
<span class="sd">    weightsum : int or float, optional</span>
<span class="sd">        Sum of `weights`, optionally passed in for speed if pre-calculated.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weighted_mean : float</span>
<span class="sd">        The weighted mean.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span>
    <span class="n">data_sum</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">if</span> <span class="n">weightsum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">weightsum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">data_sum</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">data_sum</span> <span class="o">/</span> <span class="n">weightsum</span></div>



<div class="viewcode-block" id="weighted_variance">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.weighted_variance">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">weighted_variance</span><span class="p">(</span>
        <span class="n">error</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>   <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Utility function to calculate the biased weighted variance.</span>

<span class="sd">    Calculates the biased weighted variance from data errors as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V = \frac{\sum{(w\sigma)^2}}{(\sum{w})^2}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    error : numpy.ndarray (ndata,)</span>
<span class="sd">        1-sigma error values.</span>
<span class="sd">    weights : numpy.ndarray (ndata,)</span>
<span class="sd">        Data weights.</span>
<span class="sd">    weightsum : int or float, optional</span>
<span class="sd">        Sum of weights.  Optionally passed in for speed if pre-calculated.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weighted_variance : float</span>
<span class="sd">        The weighted variance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">size</span>
    <span class="n">v_sum</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">if</span> <span class="n">weightsum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">weightsum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">ew</span> <span class="o">=</span> <span class="n">error</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">w</span>
        <span class="n">v_sum</span> <span class="o">+=</span> <span class="n">ew</span> <span class="o">*</span> <span class="n">ew</span>

    <span class="k">return</span> <span class="n">v_sum</span> <span class="o">/</span> <span class="n">weightsum</span> <span class="o">/</span> <span class="n">weightsum</span></div>



<div class="viewcode-block" id="weighted_mean_variance">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.weighted_mean_variance">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">weighted_mean_variance</span><span class="p">(</span>
        <span class="n">variance</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculated mean weighted variance.</span>

<span class="sd">    Propagate variance as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{V} = \frac{\sum_{i=1}^{N}{w_i^2 V_i}}</span>
<span class="sd">                       {(\sum_{i=1}^{N}{w_i})^2}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    variance : numpy.ndarray (ndata,)</span>
<span class="sd">        Variance array.</span>
<span class="sd">    weights : numpy.ndarray (ndata,)</span>
<span class="sd">        Weights.</span>
<span class="sd">    weightsum : int or float, optional</span>
<span class="sd">        Sum of weights.  Passed in for speed if pre-calculated.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mean_variance : float</span>
<span class="sd">        The propagated variance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">variance</span><span class="o">.</span><span class="n">size</span>
    <span class="n">v_sum</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">if</span> <span class="n">weightsum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">weightsum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">v_sum</span> <span class="o">+=</span> <span class="n">variance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">w</span> <span class="o">*</span> <span class="n">w</span>

    <span class="k">return</span> <span class="n">v_sum</span> <span class="o">/</span> <span class="n">weightsum</span> <span class="o">/</span> <span class="n">weightsum</span></div>



<div class="viewcode-block" id="weighted_fit_variance">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.weighted_fit_variance">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">weighted_fit_variance</span><span class="p">(</span>
        <span class="n">residuals</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate variance of a fit from the residuals of the fit to data.</span>

<span class="sd">    For data :math:`y`, weights :math:`w`, and fitted function</span>
<span class="sd">    :math:`f(x) = fit(x, y, w)`, the residual is given as</span>
<span class="sd">    :math:`r = y - f(x)`.  The variance is then given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V = \frac{1}{N - M}</span>
<span class="sd">            \frac{\sum_{i=1}^{N}{w_i r_i^2}}</span>
<span class="sd">                 {\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    where :math:`M` = `dof` if :math:`M &lt; N` and :math:`M = N - 1` otherwise.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    residuals : numpy.ndarray (ndata,)</span>
<span class="sd">        The residuals given as data - fit.</span>
<span class="sd">    weights : numpy.ndarray (ndata,)</span>
<span class="sd">        The weights.</span>
<span class="sd">    weightsum : int or float, optional</span>
<span class="sd">        The sum of weights optionally passed in for speed if pre-calculated.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        The degrees of freedom used in the variance calculation is taken as</span>
<span class="sd">        ndata - rank.  The default is 1 and applies the Bessel correction.</span>
<span class="sd">        If ndata &lt; rank, rank is automatically set to ndata - 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    variance : float</span>
<span class="sd">        Variance calculated from residuals.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">residuals</span><span class="o">.</span><span class="n">size</span>

    <span class="k">if</span> <span class="n">weightsum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">weightsum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">r2sum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">residuals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">r2sum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">r</span> <span class="o">*</span> <span class="n">r</span>

    <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="n">rank</span><span class="p">:</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">r2sum</span> <span class="o">/</span> <span class="n">weightsum</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">r2sum</span> <span class="o">/</span> <span class="n">weightsum</span>

    <span class="k">return</span> <span class="n">variance</span></div>



<div class="viewcode-block" id="fit_phi_value">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.fit_phi_value">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fit_phi_value</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the dot product of phi and coefficients.</span>

<span class="sd">    A utility function for use in calculating the polynomial fit based on the</span>
<span class="sd">    polynomial terms of the independent values (`phi`), and a set of calculated</span>
<span class="sd">    `coefficients`.</span>

<span class="sd">    The return value for `phi` (:math:`\Phi`) terms and coefficients</span>
<span class="sd">    (:math:`c`) each consisting of :math:`L` terms is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = \sum_{l=1}^{L}{c_l \Phi_l}</span>

<span class="sd">    The polynomial terms :math:`\Phi` are pre-calculated and used in place of</span>
<span class="sd">    regular independent values :math:`x` in the resampling algorithm to avoid</span>
<span class="sd">    the unnecessary recalculation of terms in a polynomial equation.  For</span>
<span class="sd">    example, if fitting</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = 5 x_0 x_1 + 6 x_0 x_3^2 + 7 x_1^3 x_4^2 + 8 x_0 x_1 x_2 x_3</span>

<span class="sd">    we set</span>

<span class="sd">    .. math::</span>

<span class="sd">       c = [5,\, 6,\, 7,\, 8]</span>

<span class="sd">       \Phi = [x_0 x_1,\, x_0 x_3^2,\, x_1^3 x_4^2,\, x_0 x_1 x_2 x_3]</span>

<span class="sd">    and then only need to perform the simple fast calculation</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = c \cdot \Phi</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    phi : numpy.ndarray (n_coefficients,)</span>
<span class="sd">        Polynomial terms of independent values.</span>
<span class="sd">    coefficients : numpy.ndarray (n_coefficients,)</span>
<span class="sd">        Coefficients used to determine fit.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fit : float</span>
<span class="sd">        The fitted value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fit</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">coefficients</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">fit</span> <span class="o">+=</span> <span class="n">coefficients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">fit</span></div>



<div class="viewcode-block" id="fit_phi_variance">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.fit_phi_variance">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fit_phi_variance</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">inv_covariance</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates variance given the polynomial terms of a coordinate.</span>

<span class="sd">    The output variance for given polynomial terms `phi` (:math:`\Phi`) is</span>
<span class="sd">    given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V = \Phi^T Var(\hat{c}) \Phi</span>

<span class="sd">    where :math:`Var(\hat{c})` is the covariance matrix inverse of the</span>
<span class="sd">    fit coefficients (`inv_covariance`) such that :math:`Var(\hat{c})_{i, j}`</span>
<span class="sd">    gives the covariance between the coefficients for terms :math:`i` and</span>
<span class="sd">    :math:`j`, and the coefficients :math:`\hat{c}` define the fit:</span>

<span class="sd">    .. math::</span>

<span class="sd">        y = \hat{c} \cdot \Phi</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    phi : numpy.ndarray (ncoeffs,)</span>
<span class="sd">        The polynomial terms.</span>
<span class="sd">    inv_covariance : numpy.ndarray (ncoeffs, ncoeffs)</span>
<span class="sd">        The covariance matrix inverse of the fit coefficients.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    variance : float</span>
<span class="sd">        The calculated variance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ncoeffs</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">size</span>
    <span class="n">var</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1"># Note that for this specific usage, covariance matrix C may</span>
    <span class="c1"># not always = C^T</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncoeffs</span><span class="p">):</span>
        <span class="n">phi_i</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ncoeffs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">phi_ij</span> <span class="o">=</span> <span class="n">phi_i</span> <span class="o">*</span> <span class="n">phi_i</span>
                <span class="n">inv_cov_ij</span> <span class="o">=</span> <span class="n">inv_covariance</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">phi_ij</span> <span class="o">=</span> <span class="n">phi_i</span> <span class="o">*</span> <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">inv_cov_ij</span> <span class="o">=</span> <span class="n">inv_covariance</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">inv_covariance</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>

            <span class="n">var</span> <span class="o">+=</span> <span class="n">inv_cov_ij</span> <span class="o">*</span> <span class="n">phi_ij</span>

    <span class="k">return</span> <span class="n">var</span></div>



<div class="viewcode-block" id="solve_inverse_covariance_matrices">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_inverse_covariance_matrices">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_inverse_covariance_matrices</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
                                      <span class="n">error_weighted_amat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                      <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                      <span class="n">calculate_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">calculate_residual</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">estimate_covariance</span><span class="o">=</span><span class="kc">False</span>
                                      <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Inverse covariance matrices on fit coefficients from errors and residuals.</span>

<span class="sd">    A utility function to calculate the inverse covariance matrices of the fit</span>
<span class="sd">    coefficients (:math:`c`) based on the :math:`1\sigma` error values of the</span>
<span class="sd">    sample measurements and/or the residuals of the fit</span>
<span class="sd">    :math:`y - c \cdot \Phi`.</span>

<span class="sd">    The function used to calculate the error covariance may be either</span>
<span class="sd">    :func:`estimated_covariance_matrix_inverse` or</span>
<span class="sd">    :func:`covariance_matrix_inverse`.  However,</span>
<span class="sd">    :func:`estimated_covariance_matrix_inverse` will always be used to</span>
<span class="sd">    calculate the covariance matrix derived from residuals.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    phi : numpy.ndarray (nterms, N)</span>
<span class="sd">        The polynomial terms for each of the N samples.</span>
<span class="sd">    error : numpy.ndarray (N,)</span>
<span class="sd">        The 1-sigma error values for each sample.</span>
<span class="sd">    residuals : numpy.ndarray (N,)</span>
<span class="sd">        The residuals of the fit y - c.phi.</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The weighting of each sample in the fit.</span>
<span class="sd">    error_weighted_amat : numpy.ndarray (nterms, nterms), optional</span>
<span class="sd">        The matrix :math:`A = \Phi^T W Var(y) W \Phi`, optionally passed in for</span>
<span class="sd">        speed if pre-calculated.</span>
<span class="sd">    rank : int or float, optional</span>
<span class="sd">        The rank of `error_weighted_amat`, if provided, and it&#39;s rank was</span>
<span class="sd">        pre-calculated.  Otherwise, it will be solved for.</span>
<span class="sd">    calculate_error : bool, optional</span>
<span class="sd">        If True, calculate the covariance of the fit coefficients based upon</span>
<span class="sd">        the `error` values.</span>
<span class="sd">    calculate_residual : bool, optional</span>
<span class="sd">        If True, calculate the covariance of the fit coefficients based upon</span>
<span class="sd">        `residuals` of the fit.</span>
<span class="sd">    estimate_covariance : bool, optional</span>
<span class="sd">        If True, calculate the covariance of the fit coefficients from the</span>
<span class="sd">        `error` values using :func:`estimated_covariance_matrix_inverse`.</span>
<span class="sd">        Otherwise, use :func:`covariance_matrix_inverse`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    e_inv, r_inv : numpy.ndarray, numpy.ndarray</span>
<span class="sd">        The inverse covariance calculated from `error`, and the inverse</span>
<span class="sd">        covariance calculated from `residuals`.  If `calculate_error` is True,</span>
<span class="sd">        the shape of e_cov will be (nterms, nterms) or (0, 0) otherwise.  The</span>
<span class="sd">        same is true for `calculate_residual` and r_cov.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">calculate_error</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">calculate_residual</span><span class="p">:</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cov</span><span class="p">,</span> <span class="n">cov</span>

    <span class="c1"># e_cov is the covariance determined from error values</span>
    <span class="k">if</span> <span class="n">calculate_error</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">estimate_covariance</span><span class="p">:</span>
            <span class="n">e_inv</span> <span class="o">=</span> <span class="n">estimated_covariance_matrix_inverse</span><span class="p">(</span>
                <span class="n">phi</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">error_weighted_amat</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">amat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">amat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">error_weighted_amat</span><span class="p">)</span>
            <span class="n">e_inv</span> <span class="o">=</span> <span class="n">covariance_matrix_inverse</span><span class="p">(</span>
                <span class="n">amat</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">e_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="c1"># r_cov is the covariance determined from residuals</span>
    <span class="k">if</span> <span class="n">calculate_residual</span><span class="p">:</span>
        <span class="c1"># Always use the estimated covariance for residuals since they</span>
        <span class="c1"># would otherwise define a poor solution.</span>
        <span class="n">r_inv</span> <span class="o">=</span> <span class="n">estimated_covariance_matrix_inverse</span><span class="p">(</span>
            <span class="n">phi</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">calculate_error</span><span class="p">:</span>
            <span class="n">e_inv</span> <span class="o">=</span> <span class="n">r_inv</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">r_inv</span> <span class="o">=</span> <span class="n">e_inv</span>

    <span class="k">return</span> <span class="n">e_inv</span><span class="p">,</span> <span class="n">r_inv</span></div>



<div class="viewcode-block" id="covariance_matrix_inverse">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.covariance_matrix_inverse">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">covariance_matrix_inverse</span><span class="p">(</span><span class="n">amat</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">None</span>
                              <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the inverse covariance matrix inverse of the fit coefficients.</span>

<span class="sd">    If the least-squares solution to a fit is given as</span>
<span class="sd">    :math:`y = \hat{c} \cdot \Phi` when :math:`y = c \cdot \Phi + \epsilon`,</span>
<span class="sd">    the inverse covariance on the estimated fit coefficients :math:`\hat{c}` is</span>
<span class="sd">    given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Sigma^{-1} = \frac{N}{N - M} (\Phi^T W Var(y) \Phi)^{-1}</span>

<span class="sd">    where :math:`N` are the number of samples fit, :math:`M` are the lost</span>
<span class="sd">    degrees of freedom, `W` are the fit `weights`, and :math:`Var(y)` is</span>
<span class="sd">    related to the `error` (:math:`\sigma`) by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        Var(y) = diag(1 / \sigma^2)</span>

<span class="sd">    Note that during the fitting process, it is common for the inverse of the</span>
<span class="sd">    covariance matrix :math:`\Sigma` to have already been calculated (not</span>
<span class="sd">    factoring in lost degrees of freedom) if inverse variance was included as a</span>
<span class="sd">    weighting factor for the fit.  If so, it should be passed in as `amat`</span>
<span class="sd">    (:math:`A`), and the final covariance is simply given by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Sigma^{-1} = \frac{N}{N - M}A^{-1}</span>

<span class="sd">    If `amat` was not calculated, it should be supplied as an array of shape</span>
<span class="sd">    (0, 0) (because :mod:`numba`).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    amat : numpy.ndarray (n_terms, n_terms)</span>
<span class="sd">        The matrix A as described above.  If the shape of amat is set</span>
<span class="sd">        to (0, 0), it will be calculated using the error, weights, and</span>
<span class="sd">        phi terms.  This should only be done if A was weighted by both</span>
<span class="sd">        `error` and `weights`.</span>
<span class="sd">    phi : numpy.ndarray (n_terms, N)</span>
<span class="sd">        The polynomial terms for each of the N data samples.</span>
<span class="sd">    error : numpy.ndarray (N,)</span>
<span class="sd">        The 1-sigma errors.</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The weighting factor applied to each sample when determining the</span>
<span class="sd">        least squares solution of the fit.  Note that this *must not*</span>
<span class="sd">        factor in any error based weighting.  Therefore, in the case of</span>
<span class="sd">        the resampling algorithm, it should refer to the distance</span>
<span class="sd">        weighting factor of each sample from the resampling point, or</span>
<span class="sd">        an array of ones (np.ones(N)) if distance weighting was not</span>
<span class="sd">        applied.</span>
<span class="sd">    rank : int or float, optional</span>
<span class="sd">        The matrix rank of `amat`, optionally passed in for speed if</span>
<span class="sd">        pre-calculated.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inverse_covariance : numpy.ndarray (nterms, nterms)</span>
<span class="sd">        The covariance matrix inverse of fit coefficients.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">size</span>

    <span class="k">if</span> <span class="n">amat</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scaled_matrix_inverse</span><span class="p">(</span><span class="n">amat</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>

    <span class="n">weighting</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">error</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">weighting</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">error</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weighting</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Here, amat = phi.T @ diag(weights / error^2) @ phi</span>
    <span class="n">amat</span> <span class="o">=</span> <span class="n">sscp</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weighting</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scaled_matrix_inverse</span><span class="p">(</span><span class="n">amat</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span></div>



<div class="viewcode-block" id="estimated_covariance_matrix_inverse">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.estimated_covariance_matrix_inverse">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">estimated_covariance_matrix_inverse</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">None</span>
                                        <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates covariance matrix inverse of fit coefficients from mean error.</span>

<span class="sd">    An estimate to the covariance of fit parameters is given by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Sigma = \frac{N}{N - M} \bar{\sigma}^2 (\Phi^T W \Phi)^{-1}</span>

<span class="sd">    where `N` are the number of samples used in the fit, :math:`M` are the</span>
<span class="sd">    number of lost degrees of freedom, :math:`W` are the `weights` applied to</span>
<span class="sd">    the samples during the fit, and the estimated coefficients :math:`\hat{c}`</span>
<span class="sd">    are used to fit :math:`y = \hat{c} \cdot \Phi + \sigma` to the sample</span>
<span class="sd">    population :math:`y = c \cdot \Phi + \epsilon`.  The weighted mean of the</span>
<span class="sd">    squared `error` (:math:`\bar{\sigma}^2`) is given by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{\sigma}^2 = \frac{\sum_{i=1}^{N}{w_i e_i^2}}</span>
<span class="sd">                              {\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    The final returned matrix is :math:`\Sigma^{-1}`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    phi : numpy.ndarray (nterms, N)</span>
<span class="sd">        The polynomial terms for each of the N data samples.</span>
<span class="sd">    error : numpy.ndarray (N,)</span>
<span class="sd">        The 1-sigma errors or residuals to the fit.</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The weighting of each sample in the fit, not including any error</span>
<span class="sd">        weighting.</span>
<span class="sd">    rank : int or float, optional</span>
<span class="sd">        The matrix rank of :math:`\Phi^T W \Phi`, optionally passed in for</span>
<span class="sd">        speed if pre-calculated.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    covariance_inverse : numpy.ndarray (nterms, nterms)</span>
<span class="sd">        The inverse covariance matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">size</span>
    <span class="n">v_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">w_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">weighting</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">weighting</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">w_sum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">v_sum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">error</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">error</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">v_mean</span> <span class="o">=</span> <span class="n">v_sum</span> <span class="o">/</span> <span class="n">w_sum</span>
    <span class="n">amat</span> <span class="o">=</span> <span class="n">sscp</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">weighting</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">scaled_matrix_inverse</span><span class="p">(</span><span class="n">amat</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span> <span class="o">*</span> <span class="n">v_mean</span></div>



<div class="viewcode-block" id="solve_rchi2_from_error">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_rchi2_from_error">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_rchi2_from_error</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span>
                           <span class="n">weightsum</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the reduced chi-squared given residuals and sample errors.</span>

<span class="sd">    For `weights` :math:`w`, `errors` :math:`\sigma`, and residuals :math:`r`</span>
<span class="sd">    where :math:`r = y - f(x)`, the reduced chi-squared is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \chi_r^2 = \frac{N}{N - M}</span>
<span class="sd">                  \frac{\sum_{i=1}^{N}{w_i r_i^2 / \sigma_i^2}}</span>
<span class="sd">                       {\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    where :math:`M` is given by `rank`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    residuals : numpy.ndarray (N,)</span>
<span class="sd">        The residuals to the fit, or y - f(x).</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The weights to each sample in the fit.</span>
<span class="sd">    errors : numpy.ndarray (N,)</span>
<span class="sd">        The 1-sigma measurement errors for each sample in the fit.</span>
<span class="sd">    weightsum : int or float, optional</span>
<span class="sd">        The sum of the sample weights, optionally passed in for speed.</span>
<span class="sd">    rank : int or float, optional</span>
<span class="sd">        The degrees of freedom used in the reduced chi-squared value is taken</span>
<span class="sd">        as N - rank.  The default is 1 and applies the Bessel correction.</span>
<span class="sd">        If N &lt; rank, rank is automatically set to N - 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rchi2 : float</span>
<span class="sd">        The reduced chi-squared value for the fit.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">r2sum</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">residuals</span><span class="o">.</span><span class="n">size</span>
    <span class="n">calculate_weightsum</span> <span class="o">=</span> <span class="n">weightsum</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">calculate_weightsum</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">residuals</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">sig</span> <span class="o">=</span> <span class="n">residuals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">errors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">r2sum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">sig</span> <span class="o">*</span> <span class="n">sig</span>
        <span class="k">if</span> <span class="n">calculate_weightsum</span><span class="p">:</span>
            <span class="n">weightsum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="n">rchi2</span> <span class="o">=</span> <span class="n">r2sum</span> <span class="o">/</span> <span class="n">weightsum</span> <span class="o">*</span> <span class="n">n</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rchi2</span> <span class="o">=</span> <span class="n">r2sum</span> <span class="o">/</span> <span class="n">weightsum</span>

    <span class="k">return</span> <span class="n">rchi2</span></div>



<div class="viewcode-block" id="solve_rchi2_from_variance">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_rchi2_from_variance">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_rchi2_from_variance</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span>
                              <span class="n">weightsum</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the reduced chi-squared given residuals and constant variance.</span>

<span class="sd">    For `weights` :math:`w`, `variance` :math:`V`, and residuals :math:`r`</span>
<span class="sd">    where :math:`r = y - f(x)`, the reduced chi-squared is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \chi_r^2 = \frac{1}{N - M}</span>
<span class="sd">                  \frac{\sum_{i=1}^{N}{w_i r_i^2}}</span>
<span class="sd">                       {V \sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    where :math:`M` is given by `rank`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    residuals : numpy.ndarray (N,)</span>
<span class="sd">        The residuals to the fit, or y - f(x).</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The weights to each sample in the fit.</span>
<span class="sd">    variance : int or float</span>
<span class="sd">        The constant variance of the fit.</span>
<span class="sd">    weightsum : int or float, optional</span>
<span class="sd">        The sum of the sample weights, optionally passed in for speed.</span>
<span class="sd">    rank : int or float, optional</span>
<span class="sd">        The degrees of freedom used in the reduced chi-squared value is taken</span>
<span class="sd">        as N - rank.  The default is 1 and applies the Bessel correction.</span>
<span class="sd">        If N &lt; rank, rank is automatically set to N - 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rchi2 : float</span>
<span class="sd">        The reduced chi-squared value for the fit.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">variance</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    <span class="n">r2sum</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">residuals</span><span class="o">.</span><span class="n">size</span>

    <span class="n">calculate_weightsum</span> <span class="o">=</span> <span class="n">weightsum</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">calculate_weightsum</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">residuals</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">residuals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">r2sum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">r</span> <span class="o">*</span> <span class="n">r</span>
        <span class="k">if</span> <span class="n">calculate_weightsum</span><span class="p">:</span>
            <span class="n">weightsum</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">rchi2</span> <span class="o">=</span> <span class="n">r2sum</span> <span class="o">/</span> <span class="n">weightsum</span> <span class="o">/</span> <span class="n">variance</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="n">rchi2</span> <span class="o">/=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">rank</span>

    <span class="k">return</span> <span class="n">rchi2</span></div>



<div class="viewcode-block" id="solve_mean_fit">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_mean_fit">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_mean_fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">calculate_variance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">calculate_rchi2</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the weighted mean of data, variance, and reduced chi-squared.</span>

<span class="sd">    For `data` (:math:`y`), `error` (:math:`\sigma`), and weights (:math:`w`),</span>
<span class="sd">    the weighted mean is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{y} = \frac{\sum_{i=1}^{N}{w_i y_i}}</span>
<span class="sd">                       {\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    The returned variance (:math:`V`) will depend on `use_error`.  If</span>
<span class="sd">    `use_error` is `True`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V = \frac{\sum_{i=1}^{N}{(w_i\sigma_i)^2}}{(\sum_{i=1}^{N}{w_i})^2}</span>

<span class="sd">    If `use_error` is `False`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V = \frac{1}{N - 1}</span>
<span class="sd">            \frac{\sum_{i=1}^{N}{w_i (y_i - \bar{y})^2}}</span>
<span class="sd">                 {\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    Finally, the reduced chi-squared statistic is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \chi_r^2 = \frac{N}{N - 1}</span>
<span class="sd">          \frac{\sum_{i=1}^{N}{w_i (y_i - \bar{y})^2 / \sigma_i^2}}</span>
<span class="sd">               {\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    Note that :math:`\chi_r^2 = 1` is `use_error` is `False`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : numpy.ndarray (N,)</span>
<span class="sd">        The data array consisting of N samples.</span>
<span class="sd">    error : numpy.ndarray (N,)</span>
<span class="sd">        The associated 1-sigma error values for each of the N data samples.</span>
<span class="sd">    weight : numpy.ndarray (N,)</span>
<span class="sd">        The weighting applied to each of the N data samples.</span>
<span class="sd">    weightsum : int or float, optional</span>
<span class="sd">        The sum of the weights, optionally passed in for speed if</span>
<span class="sd">        pre-calculated.</span>
<span class="sd">    calculate_variance : bool, optional</span>
<span class="sd">        If `True`, calculate the variance.  Otherwise, variance will be</span>
<span class="sd">        returned as a float value of zero.</span>
<span class="sd">    calculate_rchi2 : bool, optional</span>
<span class="sd">        If `True`, calculate the reduced chi-squared statistic.  Otherwise, it</span>
<span class="sd">        will be returned as a float value of zero.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mean, variance, rchi2 : float, float, float</span>
<span class="sd">        The weighted mean, variance and reduced chi-squared statistic.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">fitted</span> <span class="o">=</span> <span class="n">weighted_mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="n">weightsum</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">calculate_rchi2</span><span class="p">:</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">fitted</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="n">data</span>  <span class="c1"># dummy for Numba compilation success</span>

    <span class="n">use_error</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">calculate_variance</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_error</span><span class="p">:</span>
            <span class="n">variance</span> <span class="o">=</span> <span class="n">weighted_variance</span><span class="p">(</span><span class="n">error</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="n">weightsum</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">variance</span> <span class="o">=</span> <span class="n">weighted_fit_variance</span><span class="p">(</span>
                <span class="n">residuals</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="n">weightsum</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">if</span> <span class="n">calculate_rchi2</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_error</span><span class="p">:</span>
            <span class="n">rchi2</span> <span class="o">=</span> <span class="n">solve_rchi2_from_error</span><span class="p">(</span>
                <span class="n">residuals</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="n">weightsum</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rchi2</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rchi2</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="n">fitted</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span> <span class="n">rchi2</span></div>



<div class="viewcode-block" id="calculate_fitting_weights">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.calculate_fitting_weights">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">calculate_fitting_weights</span><span class="p">(</span><span class="n">errors</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">error_weighting</span><span class="o">=</span><span class="kc">True</span>
                              <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the final weighting factor based on errors and other weights.</span>

<span class="sd">    If `error_weighting` is applied, the return value is `weights` / `error`^2.</span>
<span class="sd">    Otherwise, simply returns `weights`.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The square root of the weight is used in the polynomial system of</span>
<span class="sd">    equations rather than the actual weight due to how the least-squares</span>
<span class="sd">    solution is derived.</span>

<span class="sd">    For the linear system of equations A.x = B, we are solving</span>
<span class="sd">    (A^T.W.A).C = A^T.W.B, where C are the coefficients we wish to find.</span>
<span class="sd">    If we set X = sqrt(W).A, and Y = sqrt(W).B, this is the same as</span>
<span class="sd">    (X^T.X).C = X^T.Y, which can be solved easily.  Another way of thinking</span>
<span class="sd">    about it is that we are minimizing the squared residuals (y - f(x))^2.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    errors : numpy.ndarray (N,)</span>
<span class="sd">        1-sigma error values to apply to weighting.</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        Other weighting factors, not including any type of error weighting.</span>
<span class="sd">    error_weighting : bool</span>
<span class="sd">        If False, returns `weights`, otherwise returns weights / errors^2.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fit_weighting : numpy.ndarray (N,)</span>
<span class="sd">        The final fitting weights.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">error_weighting</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">weights</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">size</span>
        <span class="n">fit_weighting</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">e</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">errors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">w2</span> <span class="o">=</span> <span class="n">e</span> <span class="o">*</span> <span class="n">e</span> <span class="o">*</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">fit_weighting</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w2</span>

    <span class="k">return</span> <span class="n">fit_weighting</span></div>



<div class="viewcode-block" id="array_sum">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.array_sum">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">array_sum</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the sum of an array.</span>

<span class="sd">    Utility function for fast :mod:`numba` calculation of the sum of a 1-D</span>
<span class="sd">    numpy array.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mask : numpy.ndarray (N,)</span>
<span class="sd">        The input array.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    count : int or float</span>
<span class="sd">        The sum of values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">count</span></div>



<div class="viewcode-block" id="calculate_distance_weights">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.calculate_distance_weights">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">calculate_distance_weights</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">alpha</span>
                               <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a distance weighting based on coordinate offsets.</span>

<span class="sd">    Given a set of :math:`K` dimensional `coordinates` (:math:`x`), a single</span>
<span class="sd">    `reference` position (:math:`x_{ref}`), and the scaling factor `alpha`</span>
<span class="sd">    (:math:`\alpha`), returns the weighting factor:</span>

<span class="sd">    .. math::</span>

<span class="sd">        w(x) = exp \left(</span>
<span class="sd">                   \sum_{k=1}^{K}{\frac{-(x_{ref, k} - x_k)^2}{\alpha_k}}</span>
<span class="sd">                   \right)</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    `alpha` relates to the standard deviation (:math:`\sigma`) in a normal</span>
<span class="sd">    distribution as :math:`\alpha = 2\sigma^2`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, N)</span>
<span class="sd">        An array of N coordinates in n_dimensions.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference position from which to determine distance offsets for the</span>
<span class="sd">        weighting function.</span>
<span class="sd">    alpha : numpy.ndarray (1 or n_dimensions,)</span>
<span class="sd">        The distance scaling factor.  If an array of size 1 is supplied, it</span>
<span class="sd">        will be applied over all dimensions.  Otherwise, a value must be</span>
<span class="sd">        provided for each dimension.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The distance weighting factors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ndim</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">symmetric</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">symmetric</span> <span class="ow">and</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">return</span> <span class="n">weights</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndim</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">symmetric</span> <span class="k">else</span> <span class="n">alpha</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">reference</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="n">d</span> <span class="o">*=</span> <span class="n">d</span>
            <span class="n">d</span> <span class="o">/=</span> <span class="n">a</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">d</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">weights</span></div>



<div class="viewcode-block" id="calculate_distance_weights_from_matrix">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.calculate_distance_weights_from_matrix">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">calculate_distance_weights_from_matrix</span><span class="p">(</span>
        <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">alpha_matrix</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns distance weights based on coordinate offsets and matrix operation.</span>

<span class="sd">    Given a set of :math:`K` dimensional `coordinates` (:math:`x`), a single</span>
<span class="sd">    `reference` position (:math:`o`), and the symmetric matrix `alpha_matrix`</span>
<span class="sd">    (:math:`A`), returns the weighting factor:</span>

<span class="sd">    .. math::</span>

<span class="sd">        w(x) = exp(-\Delta x^T A \Delta x)</span>

<span class="sd">    where :math:`{\Delta x}_k = o_k - x_k` for dimension :math:`k`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">        An array of N coordinates in n_dimensions.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference position from which to determine distance offsets for the</span>
<span class="sd">        weighting function.</span>
<span class="sd">    alpha_matrix : numpy.ndarray (n_dimensions, n_dimensions)</span>
<span class="sd">        Defines the matrix operation to perform on the coordinate offsets.</span>
<span class="sd">        Note that in this implementation, it should be a symmetric matrix</span>
<span class="sd">        such that :math:`A = A^T`.  As such, only the upper triangle is</span>
<span class="sd">        iterated over and any off-diagonal elements in the lower triangle are</span>
<span class="sd">        ignored.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The distance weighting factors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">xi</span> <span class="o">=</span> <span class="n">reference</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">xj</span> <span class="o">=</span> <span class="n">xi</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">xj</span> <span class="o">=</span> <span class="n">reference</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">weight</span> <span class="o">+=</span> <span class="n">xi</span> <span class="o">*</span> <span class="n">xj</span> <span class="o">*</span> <span class="n">alpha_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">weight</span> <span class="o">+=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">xi</span> <span class="o">*</span> <span class="n">xj</span> <span class="o">*</span> <span class="n">alpha_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">weight</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">weights</span></div>



<div class="viewcode-block" id="calculate_adaptive_distance_weights_scaled">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.calculate_adaptive_distance_weights_scaled">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">calculate_adaptive_distance_weights_scaled</span><span class="p">(</span>
        <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">adaptive_alpha</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns distance weights based on offsets and scaled adaptive weighting.</span>

<span class="sd">    Given a set of :math:`K` dimensional `coordinates` (:math:`x`), a single</span>
<span class="sd">    `reference` position (:math:`x_{ref}`), and scaling factors</span>
<span class="sd">    `adaptive_alpha` (:math:`A`), returns the weighting factor:</span>

<span class="sd">    .. math::</span>

<span class="sd">        w(x) = exp</span>
<span class="sd">            \left(</span>
<span class="sd">            -\sum_{i=1}^{K} \sum_{j=1}^{K} {{\Delta x}_i A_{i,j} {\Delta x}_j}</span>
<span class="sd">            \right)</span>

<span class="sd">    where :math:`{\Delta x}_k = x_{ref, k} - x_k` for dimension :math:`k`.</span>

<span class="sd">    Unlike :func:`calculate_distance_weights_from_matrix`, this function</span>
<span class="sd">    applies the function over multiple sets.  In this context, a single set</span>
<span class="sd">    will contain the same independent values (coordinates) as all other sets</span>
<span class="sd">    in a reduction, but the dependent data values may vary between sets.</span>
<span class="sd">    Therefore, it is necessary for the adaptive weighting values to also vary</span>
<span class="sd">    between sets.</span>

<span class="sd">    The algorithm is equivalent to</span>
<span class="sd">    :func:`calculate_adaptive_distance_weights_shaped` except when no rotation</span>
<span class="sd">    is applied, and therefore only a 1-dimensional array, rather than a matrix,</span>
<span class="sd">    is required to perform the transform.  The third axis of `adaptive_alpha`</span>
<span class="sd">    is set to one to allow :mod:`numba` to compile the function successfully,</span>
<span class="sd">    also indicating that there is no need to store the off-diagonal elements</span>
<span class="sd">    since they are all zero.  All stretching will therefore occur along the</span>
<span class="sd">    dimensional axes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">    adaptive_alpha : numpy.ndarray</span>
<span class="sd">       (n_coordinates, n_sets, 1, n_dimensions) array containing the scaled</span>
<span class="sd">       adaptive weighting factors.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weights : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The distance weighting factors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_coordinates</span><span class="p">,</span> <span class="n">n_sets</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">adaptive_alpha</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_coordinates</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">r_ij</span> <span class="o">=</span> <span class="n">reference</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">x_ij</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">a_ij</span> <span class="o">=</span> <span class="n">adaptive_alpha</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
            <span class="n">dx2</span> <span class="o">=</span> <span class="n">r_ij</span> <span class="o">-</span> <span class="n">x_ij</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">dx2</span> <span class="o">*=</span> <span class="n">dx2</span>
            <span class="k">for</span> <span class="n">set_number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sets</span><span class="p">):</span>
                <span class="n">weights</span><span class="p">[</span><span class="n">set_number</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a_ij</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">set_number</span><span class="p">]</span> <span class="o">*</span> <span class="n">dx2</span>

    <span class="k">for</span> <span class="n">set_number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sets</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">set_number</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="n">set_number</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">weights</span></div>



<div class="viewcode-block" id="calculate_adaptive_distance_weights_shaped">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.calculate_adaptive_distance_weights_shaped">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">calculate_adaptive_distance_weights_shaped</span><span class="p">(</span>
        <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">shape_matrices</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns distance weights based on offsets and shaped adaptive weighting.</span>

<span class="sd">    Given a set of :math:`K` dimensional `coordinates` (:math:`x`), a single</span>
<span class="sd">    `reference` position (:math:`o`), and the symmetric matrix `shape_matrices`</span>
<span class="sd">    (:math:`A`), returns the weighting factor:</span>

<span class="sd">    .. math::</span>

<span class="sd">        w(x) = exp(-\Delta x^T A^{-1} \Delta x)</span>

<span class="sd">    where :math:`{\Delta x}_k = o_k - x_k` for dimension :math:`k`.</span>

<span class="sd">    This function is applied to multiple coordinates over multiple sets.  In</span>
<span class="sd">    this context, a single set will contain the same independent values</span>
<span class="sd">    (coordinates) as all other sets in a reduction, but the dependent data</span>
<span class="sd">    values may vary between sets.  Therefore, it is necessary for the adaptive</span>
<span class="sd">    weighting values to also vary between sets.</span>

<span class="sd">    Unlike :func:`calculate_adaptive_distance_weights_scaled`, the matrix</span>
<span class="sd">    :math:`A` allows for the kernel weighting function to be stretched along</span>
<span class="sd">    arbitrarily rotated orthogonal axes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">    shape_matrices : numpy.ndarray</span>
<span class="sd">        (n_coordinates, n_sets, n_dimensions, n_dimensions) array containing</span>
<span class="sd">        the shaped adaptive weighting matrix for all coordinates and sets.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    weights : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The distance weighting factors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_coordinates</span><span class="p">,</span> <span class="n">n_sets</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">shape_matrices</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_coordinates</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">r_i</span> <span class="o">=</span> <span class="n">reference</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">a_ij</span> <span class="o">=</span> <span class="n">shape_matrices</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">x_j</span> <span class="o">=</span> <span class="n">x_i</span>
                <span class="n">r_j</span> <span class="o">=</span> <span class="n">r_i</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x_j</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">r_j</span> <span class="o">=</span> <span class="n">reference</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
                <span class="n">dx2</span> <span class="o">=</span> <span class="p">(</span><span class="n">r_i</span> <span class="o">-</span> <span class="n">x_i</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">r_j</span> <span class="o">-</span> <span class="n">x_j</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">set_number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sets</span><span class="p">):</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">a_ij</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">set_number</span><span class="p">]</span> <span class="o">*</span> <span class="n">dx2</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
                        <span class="c1"># times 2 because we&#39;re only looping over</span>
                        <span class="c1"># upper triangle and it&#39;s certain a = a^T</span>
                        <span class="n">value</span> <span class="o">*=</span> <span class="mi">2</span>
                    <span class="n">weights</span><span class="p">[</span><span class="n">set_number</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>

    <span class="k">for</span> <span class="n">set_number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sets</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">set_number</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="n">set_number</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">weights</span></div>



<div class="viewcode-block" id="update_mask">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.update_mask">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">update_mask</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates a mask, setting False values where weights are zero or non-finite.</span>

<span class="sd">    Utility function update a boolean `mask` in place given `weights`.  mask</span>
<span class="sd">    values where weights are zero or non-finite will be set to `False`, and</span>
<span class="sd">    the total number of `True` values is returned as output.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    weights : numpy.ndarray (N,)</span>
<span class="sd">        The weight values.</span>
<span class="sd">    mask : numpy.ndarray of bool (N,)</span>
<span class="sd">        The mask array to update in place.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    counts : int</span>
<span class="sd">        The number of `True` mask values following the update.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">counts</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">counts</span></div>



<div class="viewcode-block" id="coordinate_mean">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.coordinate_mean">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">coordinate_mean</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the mean coordinate of a distribution.</span>

<span class="sd">    Given a distribution of :math:`N` coordinates in :math:`K` dimensions, the</span>
<span class="sd">    mean coordinate in dimension :math:`k` is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{x_k} = \frac{\sum_{i=1}^{N}{w_i x_{k,i}}}{\sum_{i=1}^{N}{w_i}}</span>

<span class="sd">    where :math:`w_i = 0` if mask[i] is `False` and :math:`w_i = 1` if</span>
<span class="sd">    mask[i] is `True`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">        The coordinate distribution.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_coordinates,), optional</span>
<span class="sd">        An array of bool values where `True` indicates a coordinate should</span>
<span class="sd">        be included in the calculation, and `False` indicates that a coordinate</span>
<span class="sd">        should be ignored.  By default, all coordinates are included.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mean_coordinate : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The mean coordinate of the distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_coordinates</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">have_mask</span> <span class="o">=</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">n_coordinates</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="n">means</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">x_sum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">w_sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">have_mask</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                <span class="k">continue</span>
            <span class="n">x_sum</span> <span class="o">+=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
            <span class="n">w_sum</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_sum</span> <span class="o">/</span> <span class="n">w_sum</span>

    <span class="k">return</span> <span class="n">means</span></div>



<div class="viewcode-block" id="coordinate_covariance">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.coordinate_covariance">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">coordinate_covariance</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dof</span><span class="o">=</span><span class="mi">1</span>
                          <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the covariance of a distribution.</span>

<span class="sd">    Given the sample distribution of :math:`N` `coordinates` (:math:`X`) in</span>
<span class="sd">    :math:`K` dimensions, the sample covariance is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Sigma = E[(X - E[X])(X - E[X])^T]</span>

<span class="sd">    where :math:`\Sigma` is a :math:`K \times K` matrix and :math:`E` denotes</span>
<span class="sd">    the expected value.  In the general case where the expected value of</span>
<span class="sd">    :math:`X` is unknown and derived from the distribution itself, the</span>
<span class="sd">    covariance of the samples between dimension :math:`i` and :math:`j` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Sigma_{ij} = \frac{1}{N - M} \sum_{k=1}^{N}</span>
<span class="sd">                      {(X_{ki} - \bar{X}_i)(X_{kj} - \bar{X}_j)}</span>

<span class="sd">    where :math:`M` is the number of degrees of freedom lost (`dof`) in</span>
<span class="sd">    determining the `mean` (:math:`\bar{X}`).  If the `mean` is not provided,</span>
<span class="sd">    it will be calculated using :func:`coordinate_mean` in which case the</span>
<span class="sd">    default `dof` of 1 is appropriate.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">        The coordinates of the distribution.</span>
<span class="sd">    mean : numpy.ndarray (n_dimensions,), optional</span>
<span class="sd">        The mean of the coordinate distribution in each dimension.  If not</span>
<span class="sd">        provided, the expected value in each dimension will be calculated</span>
<span class="sd">        using :func:`coordinate_mean`.</span>
<span class="sd">    mask : numpy.ndarray (n_coordinates,), optional</span>
<span class="sd">        An array of bool values where `True` indicates a coordinate should</span>
<span class="sd">        be included in the calculation, and `False` indicates that a coordinate</span>
<span class="sd">        should be ignored.  By default, all coordinates are included.</span>
<span class="sd">    dof : int or float, optional</span>
<span class="sd">        The lost degrees of freedom, typically 1 to indicate that the</span>
<span class="sd">        population mean is not known and is replaced by the sample mean.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    covariance : numpy.ndarray of numpy.float64 (n_dimensions, n_dimensions)</span>
<span class="sd">        The covariance of the sample distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_coordinates</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">have_mask</span> <span class="o">=</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">have_mask</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">mask</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">n_coordinates</span>

    <span class="n">n</span> <span class="o">-=</span> <span class="n">dof</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
                <span class="n">covariance</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="n">covariance</span>

    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">coordinate_mean</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>

    <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_coordinates</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
            <span class="n">delta</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">d_ij</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">have_mask</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                    <span class="k">continue</span>
                <span class="n">d_ij</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">delta</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>

            <span class="n">cov_ij</span> <span class="o">=</span> <span class="n">d_ij</span> <span class="o">/</span> <span class="n">n</span>
            <span class="n">covariance</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">cov_ij</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">covariance</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">cov_ij</span>

    <span class="k">return</span> <span class="n">covariance</span></div>



<div class="viewcode-block" id="offset_variance">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.offset_variance">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">offset_variance</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">sigma_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dof</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Variance at reference coordinate derived from distribution uncertainty.</span>

<span class="sd">    Given a distribution of `coordinates` (:math:`X`), calculate the variance</span>
<span class="sd">    at a `reference` coordinate (:math:`X_{ref}`) based upon the uncertainty in</span>
<span class="sd">    the coordinate distribution.  Firstly, the distribution covariance matrix</span>
<span class="sd">    (:math:`\Sigma`) is calculated by :func:`coordinate_covariance` enabling</span>
<span class="sd">    the variance at the reference position to be given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V(X_{ref}) = (X_{ref} - E[X])^{T} \Sigma^{-1} (X_{ref} - E[X])</span>

<span class="sd">    If the expected value of the distribution is known (:math:`E[X]`) or</span>
<span class="sd">    pre-calculated, it can be passed in to the function using the `mean`</span>
<span class="sd">    optional parameter along with the lost degrees of freedom (`dof`) spent in</span>
<span class="sd">    determining :math:`E[X]`.  If not, the default is to use :math:`\bar{X}`</span>
<span class="sd">    and `dof` = 1.</span>

<span class="sd">    The user may optionally specify a `scale` factor (:math:`\beta`) such that:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V(X_{ref}) = (\beta(X_{ref} - E[X]))^{T} \Sigma^{-1}</span>
<span class="sd">                     (\beta(X_{ref} - E[X]))</span>

<span class="sd">    or:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V(X_{ref}) = \beta^2 (X_{ref} - E[X])^{T} \Sigma^{-1} (X_{ref} - E[X])</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">        The coordinates of the distribution.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference coordinate.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_coordinates,), optional</span>
<span class="sd">        An array of bool values where `True` indicates a coordinate should</span>
<span class="sd">        be included in the calculation, and `False` indicates that a coordinate</span>
<span class="sd">        should be ignored.  By default, all coordinates are included.</span>
<span class="sd">    mean : numpy.ndarray (n_dimensions,), optional</span>
<span class="sd">        The mean of the coordinate distribution in each dimension.  If not</span>
<span class="sd">        provided, the expected value in each dimension will be calculated</span>
<span class="sd">        using :func:`coordinate_mean`.</span>
<span class="sd">    scale : int or float, optional</span>
<span class="sd">        The scaling factor described above.</span>
<span class="sd">    dof : int or float, optional</span>
<span class="sd">        The lost degrees of freedom, typically 1 to indicate that the</span>
<span class="sd">        population mean is not known and is replaced by the sample mean.</span>
<span class="sd">    sigma_inv : numpy.ndarray (n_dimensions, n_dimensions), optional</span>
<span class="sd">        If the covariance matrix of the coordinate distribution has already</span>
<span class="sd">        been calculated, the matrix inverse may be passed in as sigma_inv for</span>
<span class="sd">        speed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    variance : float</span>
<span class="sd">        The variance at the reference coordinate determined from the coordinate</span>
<span class="sd">        distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">coordinate_mean</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>

    <span class="n">offset</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean</span> <span class="o">-</span> <span class="n">reference</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span>
    <span class="k">if</span> <span class="n">sigma_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">covariance</span> <span class="o">=</span> <span class="n">coordinate_covariance</span><span class="p">(</span>
            <span class="n">coordinates</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">dof</span><span class="o">=</span><span class="n">dof</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">variance_from_offsets</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">covariance</span><span class="p">,</span> <span class="n">sigma_inv</span><span class="o">=</span><span class="n">sigma_inv</span><span class="p">)</span></div>



<div class="viewcode-block" id="variance_from_offsets">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.variance_from_offsets">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">variance_from_offsets</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">covariance</span><span class="p">,</span> <span class="n">sigma_inv</span><span class="o">=</span><span class="kc">None</span>
                          <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Determine the variance given offsets from the expected value.</span>

<span class="sd">    The output variance is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        V = M^T \Sigma^{-1} M</span>

<span class="sd">    where `offsets` (:math:`M`) are the deviations :math:`X - E[X]` and</span>
<span class="sd">    :math:`\Sigma` is the `covariance`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    offsets : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The observational offsets from the expected value.</span>
<span class="sd">    covariance : numpy.ndarray (n_dimensions, n_dimensions)</span>
<span class="sd">        The covariance matrix of observations.</span>
<span class="sd">    sigma_inv : numpy.ndarray (n_dimensions, n_dimensions), optional</span>
<span class="sd">        The matrix inverse of the covariance matrix, optionally passed in for</span>
<span class="sd">        speed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    variance : float</span>
<span class="sd">        The variance as described above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">sigma_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sigma_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">offsets</span><span class="o">.</span><span class="n">size</span>
    <span class="n">relative_variance</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="n">offset_i</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
            <span class="n">cij</span> <span class="o">=</span> <span class="n">sigma_inv</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">cij</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">var_ij</span> <span class="o">=</span> <span class="n">offset_i</span> <span class="o">*</span> <span class="n">offsets</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">cij</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">relative_variance</span> <span class="o">+=</span> <span class="n">var_ij</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">relative_variance</span> <span class="o">+=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">var_ij</span>

    <span class="k">return</span> <span class="n">relative_variance</span></div>



<div class="viewcode-block" id="distribution_variances">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.distribution_variances">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">distribution_variances</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">covariance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">sigma_inv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dof</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return variance at each coordinate based on coordinate distribution.</span>

<span class="sd">    Given a normal sample distribution :math:`X`, returns the variance at each</span>
<span class="sd">    sample coordinate.  For example, consider a population of zero mean</span>
<span class="sd">    (:math:`\bar{X} = 0`) and a standard deviation of one (:math:`\sigma = 1`).</span>
<span class="sd">    Samples located at :math:`\bar{X} \pm \sigma` will return a variance of</span>
<span class="sd">    1, while samples located at :math:`\bar{X} \pm 2\sigma` will return a</span>
<span class="sd">    variance of 4.</span>

<span class="sd">    By default, the distribution variance is derived using</span>
<span class="sd">    :func:`coordinate_covariance`, and the sample mean is derived using</span>
<span class="sd">    :func:`coordinate_mean` assuming the loss of 1 degree of freedom. However,</span>
<span class="sd">    the expected value (:math:`E[X]`) may be supplied with the `mean` optional</span>
<span class="sd">    parameter along with the `covariance`, and the number of lost degrees of</span>
<span class="sd">    freedom (`dof`).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    mean : numpy.ndarray (n_dimensions,), optional</span>
<span class="sd">        The expected mean value of the distribution.</span>
<span class="sd">    covariance : numpy.ndarray (n_dimensions, n_dimensions), optional</span>
<span class="sd">        The covariance matrix (if known) for the sample distribution.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_samples,), optional</span>
<span class="sd">        An array of bool values where `True` indicates a sample should</span>
<span class="sd">        be included when calculating the mean and covariance, and `False`</span>
<span class="sd">        indicates that a sample should be ignored.  By default, all samples</span>
<span class="sd">        are included.  The output variance will still be calculated for all</span>
<span class="sd">        samples.</span>
<span class="sd">    sigma_inv : numpy.ndarray (n_dimensions, n_dimensions), optional</span>
<span class="sd">        The inverse of the covariance matrix, optionally passed in for speed</span>
<span class="sd">        if the covariance is known, and it&#39;s inverse has been pre-calculated.</span>
<span class="sd">    dof : int or float, optional</span>
<span class="sd">        The lost degrees of freedom, typically 1 to indicate that the</span>
<span class="sd">        population mean is not known and is replaced by the sample mean.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    variance : numpy.ndarray (n_samples,)</span>
<span class="sd">        The variance at each sample coordinate based on the sample</span>
<span class="sd">        distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_coordinates</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">coordinate_mean</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sigma_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">covariance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cov</span> <span class="o">=</span> <span class="n">coordinate_covariance</span><span class="p">(</span>
                <span class="n">coordinates</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">dof</span><span class="o">=</span><span class="n">dof</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>
        <span class="n">cov_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cov_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sigma_inv</span><span class="p">)</span>

    <span class="c1"># So Numba doesn&#39;t barf</span>
    <span class="n">numba_dummy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">offsets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>

        <span class="n">variance</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">variance_from_offsets</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="n">numba_dummy</span><span class="p">,</span>
                                            <span class="n">sigma_inv</span><span class="o">=</span><span class="n">cov_inv</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">variance</span></div>



<div class="viewcode-block" id="check_edges">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_edges">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_edges</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Determine whether a reference position is within a distribution &quot;edge&quot;.</span>

<span class="sd">    The purpose of this function is to allow the resampling algorithm to</span>
<span class="sd">    determine whether a fit should be performed at a `reference` location</span>
<span class="sd">    given a sample distribution of `coordinates`.  If a fit is attempted too</span>
<span class="sd">    far from the mean sample distribution, it will lead to a misleading result</span>
<span class="sd">    which becomes more pronounced at higher fit orders.</span>

<span class="sd">    Therefore, the sample distribution is assigned an &quot;edge&quot; based on one of</span>
<span class="sd">    four definitions.  If the `reference` position is outside of this edge, a</span>
<span class="sd">    `False` value will be returned, and no fitting will occur.</span>

<span class="sd">    For all edge definition algorithms, the `threshold` parameter will</span>
<span class="sd">    determine the distance of the edge from the sample mean.  As `threshold`</span>
<span class="sd">    is increased, the edge approaches the sample mean resulting in a more</span>
<span class="sd">    severe clipping of fit locations away from the center of a distribution.</span>
<span class="sd">    If `threshold` = 0, no edge clipping will occur.</span>

<span class="sd">    Since the main engine of the resampling algorithm relies on :mod:`numba`,</span>
<span class="sd">    the edge `algorithm` should be supplied as an integer.  Please see the</span>
<span class="sd">    relevant function listed below for further details on how the &quot;edge&quot; is</span>
<span class="sd">    defined.</span>

<span class="sd">    +-----------+--------------------------------------+</span>
<span class="sd">    | algorithm | Function                             |</span>
<span class="sd">    +===========+======================================+</span>
<span class="sd">    |         1 | :func:`check_edge_with_distribution` |</span>
<span class="sd">    +-----------+--------------------------------------+</span>
<span class="sd">    |         2 | :func:`check_edge_with_ellipsoid`    |</span>
<span class="sd">    +-----------+--------------------------------------+</span>
<span class="sd">    |         3 | :func:`check_edge_with_box`          |</span>
<span class="sd">    +-----------+--------------------------------------+</span>
<span class="sd">    |         4 | :func:`check_edge_with_range`        |</span>
<span class="sd">    +-----------+--------------------------------------+</span>

<span class="sd">    Generally, algorithms are ordered from most to least robust, and slowest to</span>
<span class="sd">    fastest, so, the default (1) is considered the most robust (although</span>
<span class="sd">    slowest) of the available algorithms.</span>

<span class="sd">    When dealing with more than one dimension, the</span>
<span class="sd">    :func:`check_edge_with_distribution` algorithm is recommended as it</span>
<span class="sd">    accounts for the shape of the distribution.  If the sample distribution is</span>
<span class="sd">    unknown (as opposed to a set of uniformly spaced coordinates), there is a</span>
<span class="sd">    chance for some samples to be (or to approach) a collinear distribution.</span>
<span class="sd">    Attempting a fit at any location in a tangential direction away from the</span>
<span class="sd">    distribution would likely result in a very poor fit.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference coordinate to test.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_samples,)</span>
<span class="sd">        A mask where `True` values indicate a sample should be included in</span>
<span class="sd">        the edge determination.</span>
<span class="sd">    threshold : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        A threshold parameter determining how close an edge should be to the</span>
<span class="sd">        center of the distribution.  Higher values result in an edge closer to</span>
<span class="sd">        the sample mean.  A value should be provided for each dimension.  A</span>
<span class="sd">        zero value in any dimension will result in an infinite edge for that</span>
<span class="sd">        dimension.</span>
<span class="sd">    algorithm : int, optional</span>
<span class="sd">        Integer specifying which edge definition to use.  Please see above for</span>
<span class="sd">        the associated functions.  Invalid choices will disable edge checking.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inside : bool</span>
<span class="sd">        `True` if the reference coordinate is inside the edge of the sample</span>
<span class="sd">        distribution, and `False` otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">threshold</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">check_edge_with_distribution</span><span class="p">(</span>
            <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">check_edge_with_ellipsoid</span><span class="p">(</span>
            <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">check_edge_with_box</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">check_edge_with_range</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span></div>



<div class="viewcode-block" id="check_edge_with_distribution">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_edge_with_distribution">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_edge_with_distribution</span><span class="p">(</span>
        <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines an edge based on statistical deviation from a sample distribution.</span>

<span class="sd">    Given a sample distribution (:math:`X`) of `coordinates`, the deviation of</span>
<span class="sd">    a `reference` coordinate :math:`X_{ref}` from the mean sample distribution</span>
<span class="sd">    :math:`\bar{X}` is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">            \sigma_{ref} = \sqrt{(X_{ref} - \bar{X})^{T} \Sigma^{-1}</span>
<span class="sd">                                 (X_{ref} - \bar{X})}</span>

<span class="sd">    where :math:`\Sigma` is the sample covariance of :math:`X`.  In this</span>
<span class="sd">    definition, the &quot;edge&quot; of the distribution is defined at</span>
<span class="sd">    :math:`\beta = 1 / threshold` so that reference locations where</span>
<span class="sd">    :math:`\sigma_{ref} \leq \beta` are considered inside the distribution</span>
<span class="sd">    edge.  For example, setting `threshold` = 2 will return a `False` value if</span>
<span class="sd">    :math:`\sigma_{ref} &gt; 0.5`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference coordinate.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_samples,)</span>
<span class="sd">        A mask where `False` values exclude the corresponding sample from any</span>
<span class="sd">        distribution statistics.</span>
<span class="sd">    threshold : int or float</span>
<span class="sd">        The &quot;edge&quot; of the distribution is given by 1 / threshold.  If the</span>
<span class="sd">        deviation of the reference coordinate from the distribution mean is</span>
<span class="sd">        greater than the edge, a `False` value will be returned.  Setting</span>
<span class="sd">        threshold to zero results in an edge at infinity, i.e., all reference</span>
<span class="sd">        coordinates will be considered inside the distribution edge.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inside : bool</span>
<span class="sd">        `True` if `reference` is inside the distribution &quot;edge&quot; and `False`</span>
<span class="sd">        otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">offset_variance</span><span class="p">(</span>
        <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span></div>



<div class="viewcode-block" id="check_edge_with_ellipsoid">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_edge_with_ellipsoid">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_edge_with_ellipsoid</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span>
                              <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines an ellipsoid edge around a coordinate distribution.</span>

<span class="sd">    Given a distribution (:math:`X`) of :math:`N` samples in :math:`K`</span>
<span class="sd">    dimensions, the center of mass for dimension :math:`k` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{X}_{k} = \frac{1}{N} \sum_{i=1}^{N}{X_{ik}}</span>

<span class="sd">    The ellipsoid center is at :math:`\bar{X}` with principle axes given by</span>
<span class="sd">    :math:`\beta`, where :math:`\beta = 1 - \text{threshold}`.  Note that</span>
<span class="sd">    the resampling algorithm scales all coordinates to a window parameter such</span>
<span class="sd">    that :math:`|X_k| \leq 1`, and the `threshold` parameter therefore defines</span>
<span class="sd">    a fraction of the window in the range :math:`0 &lt; \text{threshold} &lt; 1`.  If</span>
<span class="sd">    threshold[k] = 0 or 1, then no edge will be defined for dimension</span>
<span class="sd">    :math:`k`, and the ellipsoid definition will only apply over remaining</span>
<span class="sd">    dimensions (dimension :math:`k` will be ignored in all calculations).</span>

<span class="sd">    A reference coordinate (:math:`X_{ref}`) is considered inside the ellipsoid</span>
<span class="sd">    edge if:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \sum_{k=1}^{K}{\frac{(X_{ref, k} - \bar{X}_k)^2}{\beta_k^2}} \leq 1</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference coordinate.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_samples,)</span>
<span class="sd">        A mask where `False` values exclude the corresponding sample from the</span>
<span class="sd">        center-of-mass calculation.</span>
<span class="sd">    threshold : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        Defines the principle axes (1 - threshold) of an ellipsoid centered on</span>
<span class="sd">        the coordinate center of mass in units of the resampling window</span>
<span class="sd">        parameter.  Must be in the range 0 &lt; threshold &lt; 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inside : bool</span>
<span class="sd">        `True` if `reference` is inside the distribution &quot;edge&quot; and `False`</span>
<span class="sd">        otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">ndata</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">beta</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">threshold</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">n2</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">n</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">com</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                <span class="k">continue</span>
            <span class="n">com</span> <span class="o">+=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">reference</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">com</span> <span class="o">/=</span> <span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">offset</span> <span class="o">+=</span> <span class="n">com</span> <span class="o">*</span> <span class="n">com</span>

    <span class="n">offset</span> <span class="o">/=</span> <span class="n">n2</span>
    <span class="k">if</span> <span class="n">offset</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span></div>



<div class="viewcode-block" id="check_edge_with_box">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_edge_with_box">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_edge_with_box</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span>
                        <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines a hyperrectangle edge around a coordinate distribution.</span>

<span class="sd">    Given a distribution (:math:`X`) of :math:`N` samples in :math:`K`</span>
<span class="sd">    dimensions, the center of mass for dimension :math:`k` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{X}_{k} = \frac{1}{N} \sum_{i=1}^{N}{X_{ik}}</span>

<span class="sd">    The hypercube center is at :math:`\bar{X}` and its width in each</span>
<span class="sd">    dimension :math:`k` is :math:`2\beta_k` where</span>
<span class="sd">    :math:`\beta = 1 - \text{threshold}`.  Note that the resampling algorithm</span>
<span class="sd">    scales all coordinates to a window parameter such that</span>
<span class="sd">    :math:`|X_k| \leq 1`, and the `threshold` parameter therefore defines a</span>
<span class="sd">    fraction of the window in the range :math:`0 &lt; \text{threshold} &lt; 1`.  If</span>
<span class="sd">    threshold[k] = 0 or 1, then no edge will be defined for dimension</span>
<span class="sd">    :math:`k`.</span>

<span class="sd">    If this definition the &quot;edge&quot; for dimension :math:`k` is at</span>
<span class="sd">    :math:`\bar{X}_k \pm \beta_k` and `reference` (:math:`X_{ref}`) is</span>
<span class="sd">    considered inside the edge if:</span>

<span class="sd">    .. math::</span>

<span class="sd">        | \bar{X}_k - X_{ref, k} | \leq \beta_k, \, \forall k</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference coordinate.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_samples,)</span>
<span class="sd">        A mask where `False` values exclude the corresponding sample from the</span>
<span class="sd">        center-of-mass calculation.</span>
<span class="sd">    threshold : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        Defines the half-width dimensions (1 - threshold) of the hyperrectangle</span>
<span class="sd">        centered on the coordinate center of mass in units of the resampling</span>
<span class="sd">        window parameter.  Must be in the range 0 &lt; threshold &lt; 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inside : bool</span>
<span class="sd">        `True` if `reference` is inside the distribution &quot;edge&quot; and `False`</span>
<span class="sd">        otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">features</span><span class="p">,</span> <span class="n">ndata</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">beta</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">threshold</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">com</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                <span class="k">continue</span>
            <span class="n">com</span> <span class="o">+=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">reference</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">com</span> <span class="o">/=</span> <span class="n">n</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">com</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span></div>



<div class="viewcode-block" id="check_edge_with_range">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_edge_with_range">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_edge_with_range</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span>
                          <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines an edge based on the range of coordinates in each dimension.</span>

<span class="sd">    Given a distribution of sample `coordinates` (:math:`X`), and a `reference`</span>
<span class="sd">    position (:math:`X_{ref}`) in :math:`K` dimensions, check for each</span>
<span class="sd">    dimension :math:`k`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \{-\beta_k, \beta_k\} \in</span>
<span class="sd">        [min(X_k - X_{ref, k}), max(X_k - X_{ref, k})]</span>
<span class="sd">        , \, \forall k</span>

<span class="sd">    where :math:`\beta = 1 - \text{threshold}`.  In order words, in each</span>
<span class="sd">    dimension :math:`k`, there must be at least one member of :math:`X_k` at</span>
<span class="sd">    a distance of :math:`\beta_k` from :math:`X_{ref, k}` for both the</span>
<span class="sd">    positive and negative directions along :math:`k`.</span>

<span class="sd">    Note that the resampling algorithm scales all coordinates to a window</span>
<span class="sd">    parameter such that :math:`|X_k| \leq 1`, and the `threshold` parameter</span>
<span class="sd">    therefore defines a fraction of the window in the range</span>
<span class="sd">    :math:`0 &lt; \text{threshold} &lt; 1`.  If threshold[k] &lt; 0 or theshold &gt; 1,</span>
<span class="sd">    then no check will be performed for dimension :math:`k`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference coordinate.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_samples,)</span>
<span class="sd">        A mask where `False` values exclude the corresponding sample from the</span>
<span class="sd">        range check.</span>
<span class="sd">    threshold : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        Defines the threshold.  Must be in the range 0 &lt; threshold &lt; 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inside : bool</span>
<span class="sd">        `True` if `reference` is inside the distribution &quot;edge&quot; and `False`</span>
<span class="sd">        otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">ndata</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">neg_threshold</span> <span class="o">=</span> <span class="n">threshold</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="n">left_found</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">right_found</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndata</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span>
                <span class="k">continue</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">reference</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">offset</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">left_found</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">left_found</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">&lt;=</span> <span class="n">neg_threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">offset</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">right_found</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">right_found</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">left_found</span> <span class="ow">and</span> <span class="n">right_found</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span></div>



<div class="viewcode-block" id="check_orders">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_orders">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_orders</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">minimum_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">counts</span><span class="o">=-</span><span class="mi">1</span>
                 <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks the sample distribution is suitable for a polynomial fit order.</span>

<span class="sd">    For a polynomial fit to be successful at a given order, one needs to</span>
<span class="sd">    ensure that the sample distribution is suitable for such a fit.  At a</span>
<span class="sd">    minimum, there need to be enough samples to derive a fit.  However, unless</span>
<span class="sd">    the samples are known to be distributed in such a way where a fit is always</span>
<span class="sd">    possible (such as regularly spaced samples), there is the possibility that</span>
<span class="sd">    the fit may be under-determined.  For example, it is not possible to</span>
<span class="sd">    perform any other fit than the mean of sample values (order 0) if the</span>
<span class="sd">    samples all share the same coordinate.</span>

<span class="sd">    This problem is compounded by the use of :mod:`numba` which does not allow</span>
<span class="sd">    any exception handling.  If a fit fails at a single reference position,</span>
<span class="sd">    the whole algorithm will fail.</span>

<span class="sd">    There are several algorithms available, ordered in decreasing robustness,</span>
<span class="sd">    but increasing speed.  The chosen algorithm must be supplied using an</span>
<span class="sd">    integer label (because :mod:`numba`).  Please see the relevant function</span>
<span class="sd">    listed in the table below for a more detailed description of each.  The</span>
<span class="sd">    `order_algorithm` parameter is supplied to the main resampling algorithm</span>
<span class="sd">    during `__init__` and is used to select the relevant algorithm.</span>

<span class="sd">    +-----------+-------------------------------------+-----------------+</span>
<span class="sd">    | algorithm | Function                            | order_algorithm |</span>
<span class="sd">    +===========+=====================================+=================+</span>
<span class="sd">    |         1 | :func:`check_orders_with_bounds`    | &#39;bounded&#39;       |</span>
<span class="sd">    +-----------+-------------------------------------+-----------------+</span>
<span class="sd">    |         2 | :func:`check_orders_without_bounds` | &#39;extrapolate&#39;   |</span>
<span class="sd">    +-----------+-------------------------------------+-----------------+</span>
<span class="sd">    |         3 | :func:`check_orders_with_counts`    | &#39;counts&#39;        |</span>
<span class="sd">    +-----------+-------------------------------------+-----------------+</span>

<span class="sd">    Generally, :func:`check_orders_with_bounds` is the most robust and ensures</span>
<span class="sd">    that a fit will not only succeed, but is not likely to deviate widely from</span>
<span class="sd">    the expected result.  The :func:`check_orders_without_bounds` function</span>
<span class="sd">    should also allow fits to succeed, but allow fits to be generated away from</span>
<span class="sd">    the sample distribution.  This may be desirable, for example, if one is</span>
<span class="sd">    resampling an image and wishes to perform fits close to the edge.</span>
<span class="sd">    Finally, :func:`check_orders_with_counts` is fast, but there is a decent</span>
<span class="sd">    possibility that the fit will fail if the user cannot guarantee that the</span>
<span class="sd">    samples are distributed appropriately.</span>

<span class="sd">    In rare cases, a distribution of collinear samples, not aligned along any</span>
<span class="sd">    dimensional axis may pass the `check_orders` test causing resampling</span>
<span class="sd">    algorithm to fail.  In this case, please consider using</span>
<span class="sd">    :func:`check_edge_with_distribution` to perform such a check.  This may</span>
<span class="sd">    be invoked by supplying `edge_algorithm=&#39;distribution&#39;` during the</span>
<span class="sd">    initialization of the main resampling algorithm.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    algorithm : int</span>
<span class="sd">        An integer specifying the order checking algorithm to use.  If an</span>
<span class="sd">        invalid option is supplied (not listed in the table above), the return</span>
<span class="sd">        value of -1 will abort any subsequent fitting.</span>
<span class="sd">    orders : numpy.ndarray of int</span>
<span class="sd">        The desired order of the fit as a (1,) or (n_dimensions,) array.  If</span>
<span class="sd">        only a single value is supplied, it will be applied over all</span>
<span class="sd">        dimensions.  This serves as an upper limit for the check.  If the</span>
<span class="sd">        samples are distributed in a way that allows for a fit to be performed</span>
<span class="sd">        using `orders`, the return value will also be `orders`.</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The coordinates of the sample distribution.  Not used by the `counts`</span>
<span class="sd">        algorithm, but must still be supplied as an array with the correct</span>
<span class="sd">        dimensions.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The coordinates of the point at which to perform a fit.  Only required</span>
<span class="sd">        by the &#39;bounded&#39; algorithm, but a value of the correct array shape must</span>
<span class="sd">        still be supplied.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_samples,), optional</span>
<span class="sd">        An optional mask where `False` values indicate the associated sample</span>
<span class="sd">        should not be included in determining the maximum order.</span>
<span class="sd">    minimum_points : int, optional</span>
<span class="sd">        The minimum number of points required to perform a fit of the desired</span>
<span class="sd">        order, optionally passed in for speed if pre-calculated.  Only used by</span>
<span class="sd">        the &#39;counts&#39; algorithm.</span>
<span class="sd">    required : bool, optional</span>
<span class="sd">        If required is `False`, the maximum available order given the</span>
<span class="sd">        distribution will be returned (up to a maximum of `orders`).  If</span>
<span class="sd">        required is `True`, and the maximum available order is less than</span>
<span class="sd">        `orders`, the first element of the return value will be set to -1,</span>
<span class="sd">        indicating the criteria was not met.</span>
<span class="sd">    counts : int, optional</span>
<span class="sd">        This is required by the &#39;counts&#39; algorithm.  If `counts` &lt; 0, it will</span>
<span class="sd">        be determined by sum(mask).  If counts is less than zero, and a mask</span>
<span class="sd">        is not supplied, not fit will be performed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    maximum_orders : numpy.ndarray</span>
<span class="sd">       An array of shape (1,) or (n_dimensions,) based on whether a single</span>
<span class="sd">       `orders` was passed in for all dimensions, or each dimension has a</span>
<span class="sd">       separate order requirement.  If `required` was set to `True`, and the</span>
<span class="sd">       sample distribution did not allow for the requested order, the first</span>
<span class="sd">       element will be set to -1.  Otherwise, if `required` was `False`, the</span>
<span class="sd">       maximum order for each dimension will be returned.  If a single `orders`</span>
<span class="sd">       was to be applied over all dimensions, the return value will also be</span>
<span class="sd">       of size 1, but contains the min(maximum_order) over all dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># check enough points either side</span>
        <span class="k">return</span> <span class="n">check_orders_with_bounds</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span>
                                        <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="n">required</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># allow extrapolation if fitting outside sample span</span>
        <span class="k">return</span> <span class="n">check_orders_without_bounds</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
                                           <span class="n">required</span><span class="o">=</span><span class="n">required</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># check enough points overall</span>
        <span class="k">return</span> <span class="n">check_orders_with_counts</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
                                        <span class="n">minimum_points</span><span class="o">=</span><span class="n">minimum_points</span><span class="p">,</span>
                                        <span class="n">n_dimensions</span><span class="o">=</span><span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                        <span class="n">required</span><span class="o">=</span><span class="n">required</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Must be checked or don&#39;t fit.</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">orders</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span></div>



<div class="viewcode-block" id="check_orders_with_bounds">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_orders_with_bounds">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_orders_with_bounds</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks maximum order for sample coordinates bounding a reference.</span>

<span class="sd">    Given the `coordinates` of a sample distribution (:math:`X`), a `reference`</span>
<span class="sd">    position (:math:`X_{ref}`), and the desired `orders` of fit (:math:`o`),</span>
<span class="sd">    returns the maximum available order of fit.</span>

<span class="sd">    For dimension :math:`k` define the sets of unique values:</span>

<span class="sd">    .. math::</span>

<span class="sd">        s_k^- = \{ x \in X_k |\, x &lt; X_{ref, k} \} \\</span>
<span class="sd">        s_k^+ = \{ x \in X_k |\, x &gt; X_{ref, k} \}</span>

<span class="sd">    The maximum order is then given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        o_k^{max} = min\{ |s_k^-|, |s_k^+|, o_k \}</span>

<span class="sd">    where :math:`|.|` represents the cardinality (size) of the set.</span>

<span class="sd">    For example, consider a 1-dimensional set of coordinates:</span>

<span class="sd">    .. math::</span>

<span class="sd">        X = [1, 1, 1, 2, 3, 4, 5, 5, 5, 5, 6]</span>

<span class="sd">    and we wish to perform an order=3 polynomial fit at :math:`X_{ref}=2.5`.</span>
<span class="sd">    There are 4 unique values of :math:`X &gt; X_{ref}` (:math:`\{3, 4, 5, 6\}`),</span>
<span class="sd">    but only 2 unique values of :math:`X &lt; X_{ref}` (:math:`\{1, 2\}`).  The</span>
<span class="sd">    return value will be 2, indicating that only a 2nd order polynomial fit</span>
<span class="sd">    should be attempted.  If a 1st order polynomial fit was requested, the</span>
<span class="sd">    return value would be 1 since there are enough points less than and greater</span>
<span class="sd">    than the reference.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    orders : numpy.ndarray of int</span>
<span class="sd">        The desired order of the fit as a (1,) or (n_dimensions,) array.  If</span>
<span class="sd">        only a single value is supplied, it will be applied over all</span>
<span class="sd">        dimensions.  This serves as an upper limit for the check.  If the</span>
<span class="sd">        samples are distributed in a way that allows for a fit to be performed</span>
<span class="sd">        using `orders`, the return value will also be `orders`.</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    reference : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The reference coordinate.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_coordinates,), optional</span>
<span class="sd">        An optional mask where `False` values indicate the associated sample</span>
<span class="sd">        should not be included in determining the maximum order.</span>
<span class="sd">    required : bool, optional</span>
<span class="sd">        If required is `False`, the maximum available order given the</span>
<span class="sd">        distribution will be returned (up to a maximum of `orders`).  If</span>
<span class="sd">        required is `True`, and the maximum available order is less than</span>
<span class="sd">        `orders`, the first element of the return value will be set to -1,</span>
<span class="sd">        indicating the criteria was not met.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    maximum_orders : numpy.ndarray</span>
<span class="sd">       An array of shape (1,) or (n_dimensions,) based on whether a single</span>
<span class="sd">       `orders` was passed in for all dimensions, or each dimension has a</span>
<span class="sd">       separate order requirement.  If `required` was set to `True`, and the</span>
<span class="sd">       sample distribution did not allow for the requested order, the first</span>
<span class="sd">       element will be set to -1.  Otherwise, if `required` was `False`, the</span>
<span class="sd">       maximum order for each dimension will be returned.  If a single `orders`</span>
<span class="sd">       was to be applied over all dimensions, the return value will also be</span>
<span class="sd">       of size 1, but contains the min(maximum_order) over all dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_orders</span> <span class="o">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">size</span>
    <span class="n">symmetric</span> <span class="o">=</span> <span class="n">n_orders</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">order_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_orders</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_orders</span><span class="p">):</span>
        <span class="n">order_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">orders</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">symmetric</span> <span class="k">else</span> <span class="n">k</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">order_out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">o_max</span> <span class="o">=</span> <span class="n">check_orders_with_bounds_1d</span><span class="p">(</span>
            <span class="n">o</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">reference</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="n">required</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">o_max</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">order_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">o_max</span> <span class="o">&lt;</span> <span class="n">o</span><span class="p">:</span>
            <span class="n">order_out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">o_max</span>

    <span class="k">return</span> <span class="n">order_out</span></div>



<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_orders_with_bounds_1d</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Support function for `check_orders_with_bounds`.</span>

<span class="sd">    Please see :func:`check_orders_with_bounds` for a full description of the</span>
<span class="sd">    algorithm.  This function performs the necessary calculations across a</span>
<span class="sd">    single dimension.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    order : int</span>
<span class="sd">        The desired order of fit.</span>
<span class="sd">    coordinates : numpy.ndarray (n_coordinates,)</span>
<span class="sd">        The coordinates for 1-dimension of the sample distribution.</span>
<span class="sd">    reference : int or float</span>
<span class="sd">        The reference coordinate.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_coordinates,), optional</span>
<span class="sd">        An optional mask where `False` values indicate the associated sample</span>
<span class="sd">        should not be included in determining the maximum order.</span>
<span class="sd">    required : bool, optional</span>
<span class="sd">        If required is `True`, and the maximum order is less than `order`,</span>
<span class="sd">        returns -1.  Otherwise, returns the maximum order.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    max_order : int</span>
<span class="sd">        The maximum order given the 1-D distribution.  Will be set to -1</span>
<span class="sd">        if less than `order` and `required` is `True`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">order</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="n">left</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">right</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">left_found</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">right_found</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">have_mask</span> <span class="o">=</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">unique_left</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">order</span><span class="p">)</span>
    <span class="n">unique_right</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">order</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">coordinates</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">have_mask</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">reference</span>
        <span class="k">if</span> <span class="n">offset</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">left_found</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">elif</span> <span class="n">left</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">unique_left</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">offset</span>
                <span class="n">left</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">left</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">unique_left</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">offset</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">unique_left</span><span class="p">[</span><span class="n">left</span><span class="p">]</span> <span class="o">=</span> <span class="n">offset</span>
                    <span class="n">left</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">left</span> <span class="o">&gt;=</span> <span class="n">order</span><span class="p">:</span>
                <span class="n">left_found</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="n">offset</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">right_found</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">elif</span> <span class="n">right</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">unique_right</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">offset</span>
                <span class="n">right</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">right</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">unique_right</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">offset</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">unique_right</span><span class="p">[</span><span class="n">right</span><span class="p">]</span> <span class="o">=</span> <span class="n">offset</span>
                    <span class="n">right</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">right</span> <span class="o">&gt;=</span> <span class="n">order</span><span class="p">:</span>
                <span class="n">right_found</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="n">left_found</span> <span class="ow">and</span> <span class="n">right_found</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">order</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">required</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">left</span> <span class="o">&lt;</span> <span class="n">right</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">left</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">right</span>


<div class="viewcode-block" id="check_orders_without_bounds">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_orders_without_bounds">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="n">_fast_flags</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_orders_without_bounds</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span>
                                <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks maximum order based on unique samples, irrespective of reference.</span>

<span class="sd">    Given the `coordinates` of a sample distribution (:math:`X`), and the</span>
<span class="sd">    desired `orders` of fit (:math:`o`), returns the maximum available order of</span>
<span class="sd">    fit.  Unlike :func:`check_orders_with_bounds`, the location of the fit</span>
<span class="sd">    is unimportant.  All that is required is for enough unique sample</span>
<span class="sd">    coordinates to be available for fitting.</span>

<span class="sd">    For dimension :math:`k`, the maximum fit order is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        o_k^{max} = min\{ |X_k| - 1, o_k \}</span>

<span class="sd">    where :math:`|.|` represents the cardinality (size) of the set.</span>

<span class="sd">    For example, consider a 1-dimensional set of coordinates:</span>

<span class="sd">    .. math::</span>

<span class="sd">        X = [1, 1, 1, 2, 3, 4]</span>

<span class="sd">    The maximum order of fit would be 3 since there are 4 unique values</span>
<span class="sd">    (1, 2, 3, 4).  Therefore, when `orders` &gt;= 3, the return value would be 3.</span>
<span class="sd">    For `orders` &lt; 3, `orders` would be returned.</span>

<span class="sd">    If we had a 2-dimensional set of data:</span>

<span class="sd">    .. math::</span>

<span class="sd">        X = [(1, 0), (1, 0), (1, 0), (2, 1), (3, 1), (4, 1)]</span>

<span class="sd">    The maximum order of fit would be 3 in the first dimension, and 1 in the</span>
<span class="sd">    second.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    orders : numpy.ndarray of int</span>
<span class="sd">        The desired order of the fit as a (1,) or (n_dimensions,) array.  If</span>
<span class="sd">        only a single value is supplied, it will be applied over all</span>
<span class="sd">        dimensions.  This serves as an upper limit for the check.  If the</span>
<span class="sd">        samples are distributed in a way that allows for a fit to be performed</span>
<span class="sd">        using `orders`, the return value will also be `orders`.</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">        The coordinates of the sample distribution.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_coordinates,), optional</span>
<span class="sd">        An optional mask where `False` values indicate the associated sample</span>
<span class="sd">        should not be included in determining the maximum order.</span>
<span class="sd">    required : bool, optional</span>
<span class="sd">        If required is `False`, the maximum available order given the</span>
<span class="sd">        distribution will be returned (up to a maximum of `orders`).  If</span>
<span class="sd">        required is `True`, and the maximum available order is less than</span>
<span class="sd">        `orders`, the first element of the return value will be set to -1,</span>
<span class="sd">        indicating the criteria was not met.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    maximum_orders : numpy.ndarray</span>
<span class="sd">       An array of shape (1,) or (n_dimensions,) based on whether a single</span>
<span class="sd">       `orders` was passed in for all dimensions, or each dimension has a</span>
<span class="sd">       separate order requirement.  If `required` was set to `True`, and the</span>
<span class="sd">       sample distribution did not allow for the requested order, the first</span>
<span class="sd">       element will be set to -1.  Otherwise, if `required` was `False`, the</span>
<span class="sd">       maximum order for each dimension will be returned.  If a single `orders`</span>
<span class="sd">       was to be applied over all dimensions, the return value will also be</span>
<span class="sd">       of size 1, but contains the min(maximum_order) over all dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_orders</span> <span class="o">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">size</span>
    <span class="n">symmetric</span> <span class="o">=</span> <span class="n">n_orders</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">order_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">orders</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_orders</span><span class="p">):</span>
        <span class="n">order_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">orders</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">symmetric</span> <span class="k">else</span> <span class="n">k</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">order_out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">maximum_order</span> <span class="o">=</span> <span class="n">check_orders_without_bounds_1d</span><span class="p">(</span>
            <span class="n">o</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="n">required</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">maximum_order</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">order_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="n">maximum_order</span> <span class="o">&lt;</span> <span class="n">o</span><span class="p">:</span>
            <span class="n">order_out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">maximum_order</span>

    <span class="k">return</span> <span class="n">order_out</span></div>



<span class="nd">@njit</span><span class="p">(</span><span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="n">_fast_flags</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_orders_without_bounds_1d</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Support function for `check_orders_without_bounds`.</span>

<span class="sd">    Please see :func:`check_orders_without_bounds` for a full description of</span>
<span class="sd">    the algorithm.  This function performs the necessary calculations across a</span>
<span class="sd">    single dimension.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    order : int</span>
<span class="sd">        The desired order of fit.</span>
<span class="sd">    coordinates : numpy.ndarray (n_coordinates,)</span>
<span class="sd">        The coordinates for 1-dimension of the sample distribution.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_coordinates,), optional</span>
<span class="sd">        An optional mask where `False` values indicate the associated sample</span>
<span class="sd">        should not be included in determining the maximum order.</span>
<span class="sd">    required : bool, optional</span>
<span class="sd">        If required is `True`, and the maximum order is less than `order`,</span>
<span class="sd">        returns -1.  Otherwise, returns the maximum order.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    max_order : int</span>
<span class="sd">        The maximum order given the 1-D distribution.  Will be set to -1</span>
<span class="sd">        if less than `order` and `required` is `True`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">order</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="n">max_order</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">unique_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">have_mask</span> <span class="o">=</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">coordinates</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">have_mask</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">unique_values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_order</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">unique_values</span><span class="p">[</span><span class="n">max_order</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">if</span> <span class="n">max_order</span> <span class="o">&gt;=</span> <span class="n">order</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">max_order</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">required</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">max_order</span>


<div class="viewcode-block" id="check_orders_with_counts">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.check_orders_with_counts">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="n">_fast_flags</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_orders_with_counts</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">minimum_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">n_dimensions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span>
                             <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks maximum order based only on the number of samples.</span>

<span class="sd">    For :math:`N` samples of :math:`K` dimensional data, the minimum number of</span>
<span class="sd">    samples required to perform a polynomial fit with `orders` :math:`o` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        N_{min} = \prod_{k=1}^{K}{(o_k + 1)}</span>

<span class="sd">    if :math:`o_k = o_0, \, \forall k`, then it is possible to suggest a lower</span>
<span class="sd">    order over all dimensions in the case where :math:`N &lt; N_{min}`.  This</span>
<span class="sd">    is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        o_k^{max} = min\{ floor(N ^ {1 / K} - 1), o_k \}</span>

<span class="sd">    The suggested maximum order is returned by setting the `required` keyword</span>
<span class="sd">    to `False`.  If the orders vary between dimensions or `required` is `True`,</span>
<span class="sd">    the value of :math:`o_0` is set to -1 indicating a polynomial fit of the</span>
<span class="sd">    desired order is not possible.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    orders : numpy.ndarray of int</span>
<span class="sd">        The desired order of the fit as a (1,) or (n_dimensions,) array.  If</span>
<span class="sd">        only a single value is supplied, it will be applied over all</span>
<span class="sd">        dimensions.  This serves as an upper limit for the check.  If the</span>
<span class="sd">        samples are distributed in a way that allows for a fit to be performed</span>
<span class="sd">        using `orders`, the return value will also be `orders`.</span>
<span class="sd">    counts : int</span>
<span class="sd">        The number of samples available for the fit.</span>
<span class="sd">    mask : numpy.ndarray of bool (n_coordinates,), optional</span>
<span class="sd">        An optional mask where `False` values indicate the associated sample</span>
<span class="sd">        should not be included in determining the maximum order.  The `counts`</span>
<span class="sd">        parameter will be ignored in favor of sum(mask).</span>
<span class="sd">    minimum_points : int, optional</span>
<span class="sd">        The minimum number of points required to perform a fit of the desired</span>
<span class="sd">        order, optionally passed in for speed.</span>
<span class="sd">    n_dimensions : int, optional</span>
<span class="sd">        If `orders` was supplied as an array of size 1, but should be applied</span>
<span class="sd">        over multiple dimensions, the number of dimensions should be supplied.</span>
<span class="sd">        Otherwise, the number of dimensions is taken to be equal to the number</span>
<span class="sd">        of orders.</span>
<span class="sd">    required : bool, optional</span>
<span class="sd">        If required is `False`, the maximum available order given the</span>
<span class="sd">        distribution will be returned (up to a maximum of `orders`).  If</span>
<span class="sd">        required is `True`, and the maximum available order is less than</span>
<span class="sd">        `orders`, the first element of the return value will be set to -1,</span>
<span class="sd">        indicating the criteria was not met.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    maximum_orders : numpy.ndarray</span>
<span class="sd">       An array of shape (1,) or (n_dimensions,) based on whether a single</span>
<span class="sd">       `orders` was passed in for all dimensions, or each dimension has a</span>
<span class="sd">       separate order requirement.  If `required` was set to `True`, and the</span>
<span class="sd">       sample distribution did not allow for the requested order, the first</span>
<span class="sd">       element will be set to -1.  Unlike :func:`check_orders_with_bounds` or</span>
<span class="sd">       :func:`check_orders_without_bounds`, a suggested maximum order can only</span>
<span class="sd">       be returned by setting `required` to `False` if `orders` are equal</span>
<span class="sd">       in all dimensions.  Otherwise, it is impossible to know which dimension</span>
<span class="sd">       the order should be reduced for.  In this case, the first element of</span>
<span class="sd">       `maximum_orders` will be set to -1.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_orders</span> <span class="o">=</span> <span class="n">orders</span><span class="o">.</span><span class="n">size</span>
    <span class="k">if</span> <span class="n">n_dimensions</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">n_orders</span>  <span class="c1"># assume same number of dimensions</span>

    <span class="n">symmetric</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">first_order</span> <span class="o">=</span> <span class="n">orders</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">order_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_orders</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_orders</span><span class="p">):</span>
        <span class="n">order_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">orders</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">symmetric</span> <span class="ow">and</span> <span class="n">orders</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">first_order</span><span class="p">:</span>
            <span class="n">symmetric</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">minimum_points</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">minimum_points</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">order</span> <span class="o">=</span> <span class="n">orders</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">symmetric</span> <span class="k">else</span> <span class="n">orders</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">minimum_points</span> <span class="o">*=</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">counts</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
                <span class="n">counts</span> <span class="o">+=</span> <span class="n">mask</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">counts</span> <span class="o">==</span> <span class="n">minimum_points</span><span class="p">:</span>  <span class="c1"># only need to go up to here</span>
                    <span class="k">break</span>

    <span class="k">if</span> <span class="n">counts</span> <span class="o">&gt;=</span> <span class="n">minimum_points</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">order_out</span>
    <span class="k">elif</span> <span class="n">required</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">symmetric</span><span class="p">:</span>
        <span class="c1"># If the order is not symmetric, cannot recommend a new order since</span>
        <span class="c1"># we do not know which dimension to reduce.</span>
        <span class="n">order_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">order_out</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">limit</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">n_dimensions</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">limit</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">order_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">order_out</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">(</span><span class="n">limit</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">order_out</span></div>



<div class="viewcode-block" id="apply_mask_to_set_arrays">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.apply_mask_to_set_arrays">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">apply_mask_to_set_arrays</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
                             <span class="n">counts</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set certain arrays to a fixed size based on a mask array.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mask : numpy.ndarray of bool (N,)</span>
<span class="sd">        Mask where `True` values indicate the associated element should be</span>
<span class="sd">        kept, and `False` will result in exclusion from the output arrays.</span>
<span class="sd">    data : numpy.ndarray (N,)</span>
<span class="sd">        The data array.</span>
<span class="sd">    phi : numpy.ndarray (n_terms, N)</span>
<span class="sd">        The polynomial terms of the fit equation.</span>
<span class="sd">    error : numpy.ndarray</span>
<span class="sd">        An array of shape (1,) or (N,).  If an array of size 1 is supplied,</span>
<span class="sd">        it will be expanded to an array of `counts` size.</span>
<span class="sd">    weights : numpy.ndarray</span>
<span class="sd">        An array of shape (1,) or (N,).  If an array of size 1 is supplied,</span>
<span class="sd">        it will be expanded to an array of `counts` size.</span>
<span class="sd">    counts : int</span>
<span class="sd">        The number of `True` values in the mask.  Determines the output</span>
<span class="sd">        size of all arrays.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    data_out, phi_out, error_out, weight_out : 4-tuple of numpy.ndarray.</span>
<span class="sd">       Resized arrays in which the last axis is of size `counts`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_terms</span><span class="p">,</span> <span class="n">n_data</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">phi_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_terms</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">counts</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">data_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">weight_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">single_weight</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span>

    <span class="n">valid_error</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">valid_error</span><span class="p">:</span>
        <span class="n">single_error</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">error_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">error_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">single_error</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_data</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">data_out</span><span class="p">[</span><span class="n">counter</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_terms</span><span class="p">):</span>
                <span class="n">phi_out</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">counter</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">valid_error</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">single_error</span><span class="p">:</span>
                    <span class="n">error_out</span><span class="p">[</span><span class="n">counter</span><span class="p">]</span> <span class="o">=</span> <span class="n">error</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">error_out</span><span class="p">[</span><span class="n">counter</span><span class="p">]</span> <span class="o">=</span> <span class="n">error</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">single_weight</span><span class="p">:</span>
                <span class="n">weight_out</span><span class="p">[</span><span class="n">counter</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">weight_out</span><span class="p">[</span><span class="n">counter</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">counter</span> <span class="o">==</span> <span class="n">counts</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="k">return</span> <span class="n">data_out</span><span class="p">,</span> <span class="n">phi_out</span><span class="p">,</span> <span class="n">error_out</span><span class="p">,</span> <span class="n">weight_out</span></div>



<div class="viewcode-block" id="no_fit_solution">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.no_fit_solution">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">no_fit_solution</span><span class="p">(</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">,</span>
                    <span class="n">fit_out</span><span class="p">,</span> <span class="n">error_out</span><span class="p">,</span> <span class="n">counts_out</span><span class="p">,</span> <span class="n">weights_out</span><span class="p">,</span>
                    <span class="n">distance_weights_out</span><span class="p">,</span> <span class="n">rchi2_out</span><span class="p">,</span> <span class="n">offset_variance_out</span><span class="p">,</span>
                    <span class="n">get_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">get_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_distance_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">get_rchi2</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_offset_variance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">cval</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fill output arrays with set values on fit failure.</span>

<span class="sd">    On fit failure, the output arrays are filled with certain values indicating</span>
<span class="sd">    that a fit is not possible.  Count, and weight arrays contain zeros; the</span>
<span class="sd">    error, reduced chi-squared and offset variance are set to NaN; finally,</span>
<span class="sd">    the data array is set to `cval`, a user set float value.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    set_index : int</span>
<span class="sd">        An integer representing the data set for which a fit cannot be</span>
<span class="sd">        performed.</span>
<span class="sd">    point_index : int</span>
<span class="sd">        An integer representing the index of the fit coordinate at which the</span>
<span class="sd">        fit cannot be performed.</span>
<span class="sd">    fit_out : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The output fit values.</span>
<span class="sd">    error_out : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The output error values on the fit.</span>
<span class="sd">    counts_out : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The number of samples used to create the fit.</span>
<span class="sd">    weights_out : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The sum of full weights applied to samples in the fit.</span>
<span class="sd">    distance_weights_out : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The sum of only the distance weights applied to samples in the fit.</span>
<span class="sd">    rchi2_out : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The reduced chi-squared statistic of the fit.</span>
<span class="sd">    offset_variance_out : numpy.ndarray (n_sets, n_coordinates)</span>
<span class="sd">        The variance as derived from the offset of the fit coordinate from the</span>
<span class="sd">        sample distribution.</span>
<span class="sd">    get_error : bool, optional</span>
<span class="sd">        If `False` do not update `error_out`.</span>
<span class="sd">    get_counts : bool, optional</span>
<span class="sd">        If &#39;False&#39; do not update `counts_out`.</span>
<span class="sd">    get_weights : bool, optional</span>
<span class="sd">        If `False` do not update `weights_out`.</span>
<span class="sd">    get_distance_weights : bool, optional</span>
<span class="sd">        If `False` do not update `distance_weights_out`.</span>
<span class="sd">    get_rchi2 : bool, optional</span>
<span class="sd">        If `False` do not update `rchi2_out`.</span>
<span class="sd">    get_offset_variance : bool, optional</span>
<span class="sd">        If `False` do not update `offset_variance_out`.</span>
<span class="sd">    cval : float, optional</span>
<span class="sd">        The fill value for `data_out` on fit failure.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">        All arrays are updated in-place.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">fit_out</span><span class="p">[</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">cval</span>
    <span class="k">if</span> <span class="n">get_error</span><span class="p">:</span>
        <span class="n">error_out</span><span class="p">[</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">if</span> <span class="n">get_counts</span><span class="p">:</span>
        <span class="n">counts_out</span><span class="p">[</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">get_weights</span><span class="p">:</span>
        <span class="n">weights_out</span><span class="p">[</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">if</span> <span class="n">get_distance_weights</span><span class="p">:</span>
        <span class="n">distance_weights_out</span><span class="p">[</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">if</span> <span class="n">get_rchi2</span><span class="p">:</span>
        <span class="n">rchi2_out</span><span class="p">[</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">if</span> <span class="n">get_offset_variance</span><span class="p">:</span>
        <span class="n">offset_variance_out</span><span class="p">[</span><span class="n">set_index</span><span class="p">,</span> <span class="n">point_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>



<div class="viewcode-block" id="solve_polynomial_fit">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_polynomial_fit">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_polynomial_fit</span><span class="p">(</span><span class="n">phi_samples</span><span class="p">,</span> <span class="n">phi_point</span><span class="p">,</span>
                         <span class="n">data</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">distance_weight</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span>
                         <span class="n">derivative_term_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">calculate_variance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">calculate_rchi2</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">calculate_derivative_mscp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">error_weighting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">estimate_covariance</span><span class="o">=</span><span class="kc">False</span>
                         <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Derive a polynomial fit from samples, then calculate fit at single point.</span>

<span class="sd">    The fit to the sample distribution is given as</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(\Phi) = \hat{c} \cdot \Phi</span>

<span class="sd">    where :math:`\Phi` contains products of the sample coordinates for each</span>
<span class="sd">    coefficient term.  The coefficients :math:`\hat{c}` are solved for using</span>
<span class="sd">    least-squares fitting and then applied to calculate the fitted value at a</span>
<span class="sd">    single point :math:`f(\Phi_{fit})`.</span>

<span class="sd">    It is also possible to return an on the fit as a variance.  If a valid</span>
<span class="sd">    error is supplied, it will be propagated.  If no valid errors are</span>
<span class="sd">    available, they will be calculated from residuals on the fit.</span>

<span class="sd">    The reduced chi-squared (:math:`\chi^2`) statistic may also be calculated,</span>
<span class="sd">    but is only really meaningful if valid errors were supplied.  Otherwise,</span>
<span class="sd">    :math:`\chi^2 \equiv 1`.</span>

<span class="sd">    Finally, the covariance of gradients between dimensions may also be</span>
<span class="sd">    returned.  Note that these are the weighted mean of all sample gradients.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    phi_samples : numpy.ndarray (n_terms, n_samples)</span>
<span class="sd">        The array of independent terms for each sample.</span>
<span class="sd">    phi_point : numpy.ndarray (n_terms,)</span>
<span class="sd">        The array containing the independent terms at the fitting point.</span>
<span class="sd">    data : numpy.ndarray (n_samples,)</span>
<span class="sd">        The array of sample values.</span>
<span class="sd">    error : numpy.ndarray (n_samples,)</span>
<span class="sd">        The array of error values for each sample.  Note that if errors are</span>
<span class="sd">        unavailable, an array of size 0 may be supplied.  If this is the case,</span>
<span class="sd">        and an error on the fit is required, it will be derived from the</span>
<span class="sd">        residuals of the fit from the data.  In addition, the reduced</span>
<span class="sd">        chi-squared statistic will always be 1.0 if derived from residuals.</span>
<span class="sd">    distance_weight : numpy.ndarray (n_samples,)</span>
<span class="sd">        The distance weighting factor (not including any error weighting)</span>
<span class="sd">        applied to each sample in the fit.</span>
<span class="sd">    weight : numpy.ndarray (n_samples,)</span>
<span class="sd">        The full weighting factor applied to each sample in the fit.</span>
<span class="sd">    derivative_term_map : numpy.ndarray, optional</span>
<span class="sd">        A mapping array for the determination of derivatives from the</span>
<span class="sd">        coefficients of the fit, and available terms in &quot;phi&quot;.  The shape of</span>
<span class="sd">        the array is (n_dimensions, 3, n_derivative_terms).  This is only</span>
<span class="sd">        required if the gradient is required as an output.  For a full</span>
<span class="sd">        description of the derivative map, please see</span>
<span class="sd">        :func:`polynomial_derivative_map`.</span>
<span class="sd">    calculate_variance : bool, optional</span>
<span class="sd">        If `True`, calculate the variance on the fit.  The variance will be</span>
<span class="sd">        calculated irrespectively if a valid error was supplied, and the</span>
<span class="sd">        reduced chi-squared statistic is required as a return value.</span>
<span class="sd">    calculate_rchi2 : bool, optional</span>
<span class="sd">        If `True`, calculate the reduced chi-squared statistic of the fit.</span>
<span class="sd">        Note that valid errors must be supplied for this to be meaningful.</span>
<span class="sd">    calculate_derivative_mscp : bool, optional</span>
<span class="sd">        If `True`, calculate the covariance of the derivatives at the fit</span>
<span class="sd">        point.</span>
<span class="sd">    error_weighting : bool, optional</span>
<span class="sd">        If `True`, indicates that `weights` includes an error weighting</span>
<span class="sd">        factor of 1/sigma^2.  This allows for a slight speed increase when</span>
<span class="sd">        performing the fit as some mathematical terms will not need to be</span>
<span class="sd">        recalculated.</span>
<span class="sd">    estimate_covariance : bool, optional</span>
<span class="sd">        If `True`, uses :func:`estimated_covariance_matrix_inverse` instead</span>
<span class="sd">        of :func:`covariance_matrix_inverse` when determining the variance.</span>
<span class="sd">        This is suggested if the errors are not well-behaved.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fit_value, variance, rchi2, gradients : float, float, float, numpy.ndarray</span>
<span class="sd">        The value of the fit at the fit point.  The variance and reduced</span>
<span class="sd">        chi-squared will only be calculated if `calculate_variance` and</span>
<span class="sd">        `calculate_rchi2` are respectively set to `True`.  The `gradients`</span>
<span class="sd">        matrix is an (n_dimensions, n_dimensions) array where</span>
<span class="sd">        gradients[i, j] = dx_i * dx_j.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">amat</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">solve_amat_beta</span><span class="p">(</span><span class="n">phi_samples</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="n">rank</span><span class="p">,</span> <span class="n">coefficients</span> <span class="o">=</span> <span class="n">solve_coefficients</span><span class="p">(</span><span class="n">amat</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">fit_value</span> <span class="o">=</span> <span class="n">fit_phi_value</span><span class="p">(</span><span class="n">phi_point</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">)</span>

    <span class="n">error_valid</span> <span class="o">=</span> <span class="n">error</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span>
    <span class="n">error_weighted_amat</span> <span class="o">=</span> <span class="n">amat</span> <span class="k">if</span> <span class="n">error_weighting</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">variance_required</span> <span class="o">=</span> <span class="n">calculate_variance</span> <span class="ow">or</span> <span class="p">(</span><span class="n">error_valid</span> <span class="ow">and</span> <span class="n">calculate_rchi2</span><span class="p">)</span>
    <span class="n">e_inv_required</span> <span class="o">=</span> <span class="n">error_valid</span> <span class="ow">and</span> <span class="p">(</span><span class="n">calculate_variance</span> <span class="ow">or</span> <span class="n">calculate_rchi2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">error_valid</span><span class="p">:</span>
        <span class="n">r_inv_required</span> <span class="o">=</span> <span class="n">calculate_rchi2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">r_inv_required</span> <span class="o">=</span> <span class="n">calculate_variance</span>

    <span class="k">if</span> <span class="n">r_inv_required</span><span class="p">:</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="n">fit_residual</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">phi_samples</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="n">data</span>  <span class="c1"># dummy allocation for Numba</span>

    <span class="n">e_inv</span><span class="p">,</span> <span class="n">r_inv</span> <span class="o">=</span> <span class="n">solve_inverse_covariance_matrices</span><span class="p">(</span>
        <span class="n">phi_samples</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">distance_weight</span><span class="p">,</span>
        <span class="n">error_weighted_amat</span><span class="o">=</span><span class="n">error_weighted_amat</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
        <span class="n">calculate_error</span><span class="o">=</span><span class="n">e_inv_required</span><span class="p">,</span>
        <span class="n">calculate_residual</span><span class="o">=</span><span class="n">r_inv_required</span><span class="p">,</span>
        <span class="n">estimate_covariance</span><span class="o">=</span><span class="n">estimate_covariance</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">variance_required</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">error_valid</span><span class="p">:</span>
            <span class="c1"># Error propagation</span>
            <span class="n">variance</span> <span class="o">=</span> <span class="n">fit_phi_variance</span><span class="p">(</span><span class="n">phi_point</span><span class="p">,</span> <span class="n">e_inv</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Error estimate based on residuals</span>
            <span class="n">variance</span> <span class="o">=</span> <span class="n">fit_phi_variance</span><span class="p">(</span><span class="n">phi_point</span><span class="p">,</span> <span class="n">r_inv</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">if</span> <span class="n">calculate_derivative_mscp</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">derivative_term_map</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">derivative_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">derivative_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">derivative_term_map</span><span class="p">)</span>
        <span class="n">gradient_mscp</span> <span class="o">=</span> <span class="n">derivative_mscp</span><span class="p">(</span>
            <span class="n">coefficients</span><span class="p">,</span> <span class="n">phi_samples</span><span class="p">,</span> <span class="n">derivative_map</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">gradient_mscp</span> <span class="o">=</span> <span class="n">r_inv</span>  <span class="c1"># dummy allocation for Numba</span>

    <span class="k">if</span> <span class="n">calculate_rchi2</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">error_valid</span><span class="p">:</span>
            <span class="n">rchi2</span> <span class="o">=</span> <span class="n">fit_phi_variance</span><span class="p">(</span><span class="n">phi_point</span><span class="p">,</span> <span class="n">r_inv</span><span class="p">)</span> <span class="o">/</span> <span class="n">variance</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rchi2</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># since error was derived from residuals</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rchi2</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="n">fit_value</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span> <span class="n">rchi2</span><span class="p">,</span> <span class="n">gradient_mscp</span></div>



<div class="viewcode-block" id="multivariate_gaussian">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.multivariate_gaussian">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multivariate_gaussian</span><span class="p">(</span><span class="n">covariance</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return values of a multivariate Gaussian in K-dimensional coordinates.</span>

<span class="sd">    The density of a multivariate Gaussian is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f_{\mathbf X}(x_1, \ldots, x_k) = \frac</span>
<span class="sd">            {\exp\left(-\frac{1}{2} (x - \mu)^T \Sigma^{-1}(x - \mu) \right)}</span>
<span class="sd">            {\sqrt{(2 \pi)^K |\Sigma|}}</span>

<span class="sd">    where the `coordinates` :math:`X` are real :math:`K` dimensional vectors,</span>
<span class="sd">    :math:`\Sigma` is the covariance matrix with determinant :math:`|\Sigma|`,</span>
<span class="sd">    and the `center` of the distribution is given by :math:`\mu`.</span>

<span class="sd">    Note that by default, the factor :math:`{\sqrt{(2 \pi)^K |\Sigma|}}` is not</span>
<span class="sd">    applied unless `normalize` is `True`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    covariance : numpy.ndarray (n_dimensions, n_dimensions)</span>
<span class="sd">        The covariance matrix (:math:`\Sigma`).  Should be symmetric and</span>
<span class="sd">        positive definite.</span>
<span class="sd">    coordinates : numpy.ndarray (n_dimensions, n_coordinates)</span>
<span class="sd">        The coordinates at which to evaluate the multivariate Gaussian.</span>
<span class="sd">    center : numpy.ndarray (n_dimensions,), optional</span>
<span class="sd">        The center of the distribution.  If not supplied, the center is</span>
<span class="sd">        assumed to be zero in all dimensions.</span>
<span class="sd">    normalize : bool, optional</span>
<span class="sd">        If `True`, normalize by dividing by :math:`\sqrt{(2 \pi)^k |\Sigma|}`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    density : numpy.ndarray (n_coordinates,)</span>
<span class="sd">        The density evaluated at each coordinate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_coordinates</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">center</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">center</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_dimensions</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_coordinates</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">covariance_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">**</span> <span class="n">n_dimensions</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">covariance</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">xi</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">cx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">xj</span> <span class="o">=</span> <span class="n">xi</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xj</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">cx</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">cij</span> <span class="o">=</span> <span class="n">covariance_inv</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">xi</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">cij</span> <span class="o">*</span> <span class="n">xj</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">/=</span> <span class="mi">2</span>
                <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coordinates</span><span class="p">):</span>
        <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">/=</span> <span class="n">norm</span>

    <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="scaled_adaptive_weight_matrix">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.scaled_adaptive_weight_matrix">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scaled_adaptive_weight_matrix</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">rchi2</span><span class="p">,</span> <span class="n">fixed</span><span class="o">=</span><span class="kc">None</span>
                                  <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Scales a Gaussian weighting kernel based on a prior fit.</span>

<span class="sd">    In the standard resampling algorithm, a polynomial fit may weight each</span>
<span class="sd">    sample (:math:`x`) according to its distance from the reference position at</span>
<span class="sd">    which the fit is derived (:math:`x_{ref}`) such that samples closer to the</span>
<span class="sd">    reference position have more influence on the fit than those that are</span>
<span class="sd">    farther.  The weighting function used is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        w(x) = exp \left(</span>
<span class="sd">           -\sum_{k=1}^{K}{\frac{(x_{ref, k} - x_k)^2}{2 \sigma_k^2}}</span>
<span class="sd">                   \right)</span>

<span class="sd">    in :math:`K` dimensions where :math:`\sigma` (supplied to this function</span>
<span class="sd">    via `sigma`) is a scaling factor, equivalent to the standard deviation of</span>
<span class="sd">    a normal distribution.  Following a fit, it is also possible to generate</span>
<span class="sd">    a reduced chi-squared statistic (:math:`\chi_r^2`) which measures the</span>
<span class="sd">    &quot;goodness&quot; of fit.</span>

<span class="sd">    With this information we can rescale `sigma` in an attempt to get</span>
<span class="sd">    :math:`\chi_r^2 \rightarrow 1` i.e., get a good fit within noise</span>
<span class="sd">    limitations.  This function assumes that if :math:`\chi_r^2 &lt; 1`, the</span>
<span class="sd">    samples have been over-fit, and therefore, the weighting function should be</span>
<span class="sd">    &quot;widened&quot; to allow more distant samples to have a stronger influence on the</span>
<span class="sd">    fit and subsequent :math:`\chi_r^2` calculation.  Likewise, if</span>
<span class="sd">    :math:`\chi_r^2 &gt; 1`, this implies that the weighting function should be</span>
<span class="sd">    truncated so that the fit focuses more strongly on providing a good fit</span>
<span class="sd">    to nearby samples.  i.e., there is likely structure away from the fit</span>
<span class="sd">    location that cannot be modelled well by a polynomial of the given order.</span>

<span class="sd">    To accomplish this, the weighting kernel is rescaled such that:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \chi_r^2 \prod_{k=1}^{K}{\sigma_{scaled, k}^2} =</span>
<span class="sd">            \prod_{k=1}^{K}{\sigma_k^2}</span>

<span class="sd">    The reason is that for a multivariate Gaussian:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \int_{R^K} exp \left(</span>
<span class="sd">            -\frac{1}{2} (x - x_{ref})^T \Sigma^{-1} (x - x_{ref})</span>
<span class="sd">        \right)</span>
<span class="sd">        = (2 \pi)^{K/2} |\Sigma|^{1/2}</span>

<span class="sd">    where :math:`\sigma^2 = diag(\Sigma)`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        |\Sigma| \propto \prod_{k=1}^{K}{\sigma_k^2} \propto \chi_r</span>

<span class="sd">    Note that in this specific implementation, the shape of the weighting</span>
<span class="sd">    kernel remains unchanged and only the overall size is allowed to vary.</span>
<span class="sd">    Therefore, a single scaling factor (:math:`\beta`) is applied over all</span>
<span class="sd">    dimensions such that:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \sigma_{scaled, k} = \frac{\sigma_k}{\sqrt{\beta}}</span>

<span class="sd">    where</span>

<span class="sd">    .. math::</span>

<span class="sd">        \beta = \chi_r^{1 / K}</span>

<span class="sd">    To reduce subsequent calculations, a scaled :math:`\alpha` value is passed</span>
<span class="sd">    out instead of :math:`\sigma_{scaled}` where:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \alpha = 2 \sigma^2</span>

<span class="sd">    Therefore, the final output value will be:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \alpha_{scaled, k}^{-1} = \frac{\beta}{2 \sigma_k^2}</span>

<span class="sd">    Finally, scaling does not need to occur across all dimensions, and it is</span>
<span class="sd">    possible to fix the shape of the kernel in one or more dimensions by using</span>
<span class="sd">    the `fixed` parameter.  If this is the case:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \beta = \chi_r^{\frac{1}{K - K_{fixed}}}</span>

<span class="sd">    where :math:`K_{fixed}` is the number dimensions in which scaling has been</span>
<span class="sd">    disabled.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sigma : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The standard deviations of the Gaussian for each dimensional component</span>
<span class="sd">        used for distance weighting of each sample in the initial fit.</span>
<span class="sd">    rchi2 : float</span>
<span class="sd">        The reduced chi-squared statistic of the fit.</span>
<span class="sd">    fixed : numpy.ndarray of bool (n_dimensions,), optional</span>
<span class="sd">        If supplied, `True` values indicate that the width of the Gaussian</span>
<span class="sd">        along the corresponding axis should not be altered in the output</span>
<span class="sd">        result.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    inverse_alpha : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The scaled `sigma` values converted to the inverse `alpha` array,</span>
<span class="sd">        required by :func:`calculate_adaptive_distance_weights_scaled` to</span>
<span class="sd">        create a set of weighting factors.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">.</span><span class="n">size</span>
    <span class="n">scaled_inverse_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">rchi2</span><span class="p">):</span>
        <span class="n">scaled_inverse_alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>  <span class="c1"># indicate failure and propagate</span>
        <span class="k">return</span> <span class="n">scaled_inverse_alpha</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">scaled_inverse_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">rchi2</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scaled_inverse_alpha</span>  <span class="c1"># no change</span>
    <span class="n">rchi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">rchi2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fixed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scaling_factor</span> <span class="o">=</span> <span class="n">rchi</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n_dimensions</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">scaled_inverse_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scaling_factor</span>
        <span class="k">return</span> <span class="n">scaled_inverse_alpha</span>

    <span class="n">fix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">fixed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">b1</span><span class="p">)</span>  <span class="c1"># for Numba hand-holding</span>
    <span class="n">n_adapt</span> <span class="o">=</span> <span class="n">n_dimensions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">fix</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">n_adapt</span> <span class="o">-=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">n_adapt</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scaled_inverse_alpha</span>  <span class="c1"># no change</span>

    <span class="n">scaling_factor</span> <span class="o">=</span> <span class="n">rchi</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">n_adapt</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">fix</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">scaled_inverse_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scaling_factor</span>

    <span class="k">return</span> <span class="n">scaled_inverse_alpha</span></div>



<div class="viewcode-block" id="scaled_adaptive_weight_matrices">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.scaled_adaptive_weight_matrices">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scaled_adaptive_weight_matrices</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">rchi2_values</span><span class="p">,</span> <span class="n">fixed</span><span class="o">=</span><span class="kc">None</span>
                                    <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper for `scaled_adaptive_weight_matrix` over multiple values.</span>

<span class="sd">    Please see :func:`scaled_adaptive_weight_matrix` for details on how the</span>
<span class="sd">    weighting kernel is modified using a single scaling factor.  This function</span>
<span class="sd">    performs the calculation for multiple scaling factors (:math:`\chi_r^2`).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sigma : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The standard deviations of the Gaussian for each dimensional component</span>
<span class="sd">        used for the distance weighting of each sample in the initial fit.</span>
<span class="sd">    rchi2_values : numpy.ndarray (n_data_sets, fit_shape)</span>
<span class="sd">        The reduced chi-squared statistics of the fit for each data set.  Here,</span>
<span class="sd">        `fit_shape` is an arbitrary array shape which depends upon the shape of</span>
<span class="sd">        the output fit coordinates defined by the user.</span>
<span class="sd">    fixed : numpy.ndarray of bool (n_dimensions,), optional</span>
<span class="sd">        If supplied, `True` values indicate that the width of the Gaussian</span>
<span class="sd">        along the corresponding axis should not be altered in the output</span>
<span class="sd">        result.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    scaled_matrices : numpy.ndarray</span>
<span class="sd">        The scaled weighting kernel with shape</span>
<span class="sd">        (n_data_sets, fit_shape, 1, n_dimensions) where `fit_shape` is</span>
<span class="sd">        determined by the shape of the output fit coordinates supplied by the</span>
<span class="sd">        user, and `n_data_sets` is the number of data sets to be fit.  The</span>
<span class="sd">        third axis (of size 1), is a dummy dimension required for Numba to</span>
<span class="sd">        compile successfully.  The last dimension contains the new scaled</span>
<span class="sd">        inverse :math:`\alpha_{scaled,k}^{-1}` values as described in</span>
<span class="sd">        :func:`scaled_adaptive_weight_matrix`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">rchi2_values</span><span class="o">.</span><span class="n">size</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">rchi2_values</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sigma</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="n">flat_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sigma</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="n">scaled_matrices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flat_shape</span><span class="p">)</span>
    <span class="n">flat_rchi2</span> <span class="o">=</span> <span class="n">rchi2_values</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">scaled_matrices</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaled_adaptive_weight_matrix</span><span class="p">(</span>
            <span class="n">sigma</span><span class="p">,</span> <span class="n">flat_rchi2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fixed</span><span class="o">=</span><span class="n">fixed</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">scaled_matrices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span></div>



<div class="viewcode-block" id="shaped_adaptive_weight_matrix">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.shaped_adaptive_weight_matrix">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">shaped_adaptive_weight_matrix</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">rchi2</span><span class="p">,</span> <span class="n">gradient_mscp</span><span class="p">,</span>
                                  <span class="n">density</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                  <span class="n">variance_offset</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                  <span class="n">fixed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                  <span class="n">tolerance</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shape and scale the weighting kernel based on a prior fit.</span>

<span class="sd">    In the standard resampling algorithm, a polynomial fit may weight each</span>
<span class="sd">    sample coordinate (:math:`x`) according to its distance from the reference</span>
<span class="sd">    position at which the fit is derived (:math:`x_{ref}`) such that samples</span>
<span class="sd">    closer to the reference position have more influence on the fit than those</span>
<span class="sd">    that are farther.  The weighting function used is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        W = exp(-\Delta x^T A^{-1} \Delta x)</span>

<span class="sd">    where :math:`{\Delta x}_k = x_{ref, k} - x_k` for dimension :math:`k`, and</span>
<span class="sd">    :math:`A` is a symmetric positive definite matrix defining the &quot;shape&quot; of</span>
<span class="sd">    the weighting kernel.  This effectively defines a multivariate Gaussian</span>
<span class="sd">    centered on the reference point where overall size, rotation, and stretch</span>
<span class="sd">    of each principle axis may be altered.  The goal of shaping the weighting</span>
<span class="sd">    kernel :math:`A`, is to produce a fit where the reduced chi-squared</span>
<span class="sd">    statistic of the fit equal to one (:math:`\chi_r^2 = 1`).  To derive the</span>
<span class="sd">    shape :math:`A`, an initial fit must have first been performed using a</span>
<span class="sd">    square diagonal matrix :math:`A_0`, whose diagonal elements are the square</span>
<span class="sd">    of the `sigma` parameter (:math:`diag(A_0) = 2 \sigma^2`).  It is then easy</span>
<span class="sd">    to define :math:`A_0^{-1}` in :math:`K` dimensions as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        A_0^{-1} = \frac{1}{2}</span>
<span class="sd">            \begin{bmatrix}</span>
<span class="sd">                \frac{1}{\sigma_0^2} &amp; 0 &amp; \dots &amp; 0 \\</span>
<span class="sd">                0 &amp; \frac{1}{\sigma_1^2} &amp; \ddots &amp; \vdots \\</span>
<span class="sd">                \vdots &amp; \ddots &amp; \ddots &amp; 0 \\</span>
<span class="sd">                0 &amp; \dots &amp; 0 &amp; \frac{1}{\sigma_K^2}</span>
<span class="sd">            \end{bmatrix}</span>

<span class="sd">    Following (or during) the initial fit with :math:`A_0`, the mean</span>
<span class="sd">    square cross products of the derivatives evaluated at the sample</span>
<span class="sd">    coordinates should be calculated using :func:`derivative_mscp`, where the</span>
<span class="sd">    returned matrix has values:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{g}_{ij}^2 = \frac{\partial \bar{f}}{\partial X_i}</span>
<span class="sd">                         \frac{\partial \bar{f}}{\partial X_j}</span>

<span class="sd">    for dimensions :math:`X_i` and :math:`X_j` in K-dimensions, where</span>
<span class="sd">    :math:`\partial \bar{f} / \partial X_i` is the weighted mean of the partial</span>
<span class="sd">    derivatives over all samples in the fit with respect to :math:`X_i`, with</span>
<span class="sd">    weighting defined by :math:`W` (above) using :math:`A_0^{-1}`.</span>

<span class="sd">    The matrix :math:`\bar{g}^2` is only used to define the shape of new</span>
<span class="sd">    weighting kernel, not the overall size.  Therefore, it is normalized such</span>
<span class="sd">    that :math:`|\bar{g}^2| = 1`.</span>

<span class="sd">    We can then use singular value decomposition to factorize :math:`\bar{g}^2`</span>
<span class="sd">    into:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \bar{g}^2 = U S V^T</span>

<span class="sd">    Here, the matrices :math:`U` and :math:`V^T` represent rotations (since</span>
<span class="sd">    :math:`|\bar{g}^2| &gt; 0`), and the singular values (:math:`S`) can be</span>
<span class="sd">    thought of as the magnitudes of the semi-axes of an ellipsoid in</span>
<span class="sd">    K-dimensional space.  Naively, this provides us with a basis from which to</span>
<span class="sd">    determine the final &quot;shape&quot; matrix where:</span>

<span class="sd">    .. math::</span>

<span class="sd">        A^{-1} = \beta\, \bar{g}^2</span>

<span class="sd">    and :math:`\beta` is an as yet undetermined scaling factor representing</span>
<span class="sd">    the overall size of the new kernel.  The resulting weighting kernel has the</span>
<span class="sd">    shape of an ellipsoid with the smallest semi-axis oriented parallel to</span>
<span class="sd">    the gradient.  In other words, the new weighting will result in a fit that</span>
<span class="sd">    is less sensitive to distant samples in directions where the gradient is</span>
<span class="sd">    high, and more sensitive to distant samples in directions where the</span>
<span class="sd">    gradient is low.</span>

<span class="sd">    However, we must still keep in mind that our overall goal is to get</span>
<span class="sd">    :math:`\chi_r^2 \rightarrow 1` when a fit is performed using the new</span>
<span class="sd">    kernel :math:`A`.  For example, if :math:`\chi_r=1` in the initial fit,</span>
<span class="sd">    there is no need to modify the kernel, and if :math:`\chi_r &lt; 1`, then we</span>
<span class="sd">    do not want to get an even better fit.</span>

<span class="sd">    Another factor to consider is that we cannot be completely confident in</span>
<span class="sd">    this new shape due to the distribution of samples.  If we are fitting at a</span>
<span class="sd">    point that is away from the center of the sample distribution, it is</span>
<span class="sd">    unadvisable to use a highly shaped kernel due to increased uncertainty in</span>
<span class="sd">    the mean partial derivatives.  Furthermore, even if we are fitting close to</span>
<span class="sd">    the center of the distribution, that does not mean that the derivative</span>
<span class="sd">    calculations were not skewed by a few nearby samples when fitting in a</span>
<span class="sd">    local depression of the sample density (for example, near the center of a</span>
<span class="sd">    donut-like distribution).</span>

<span class="sd">    We model our confidence (:math:`\gamma`) in the &quot;shape&quot; using a logistic</span>
<span class="sd">    function (see :func:`stretch_correction`) that factors in :math:`\chi_r^2`,</span>
<span class="sd">    a measure of the sample density profile (:math:`\rho`) at the fit</span>
<span class="sd">    coordinate, and from the deviation of the fit coordinate from the center of</span>
<span class="sd">    the sample distribution (:math:`\sigma_d`):</span>

<span class="sd">    .. math::</span>

<span class="sd">        \gamma = \frac{2}</span>
<span class="sd">                 {\left(</span>
<span class="sd">                     {1 + (2^{exp(\sigma)} - 1)e^{\rho (1 - \chi_r^2)}}</span>
<span class="sd">                 \right)^{1/exp(\sigma)}} - 1</span>

<span class="sd">    The density :math:`\rho` is calculated using :func:`relative_density` which</span>
<span class="sd">    sets :math:`\rho=1` when the samples are uniformly distributed,</span>
<span class="sd">    :math:`\rho &gt; 1` when the distribution is concentrated on the fit</span>
<span class="sd">    coordinate, and :math:`0 &lt; \rho &lt; 1` when the fitting in a local depression</span>
<span class="sd">    of the distribution density.  The deviation (:math:`\sigma_d`) is</span>
<span class="sd">    calculated using :func:`offset_variance`.</span>

<span class="sd">    The confidence parameter has asymptotes at :math:`\gamma = \pm 1`, is</span>
<span class="sd">    equal to zero at :math:`\chi_r^2=1`, is positive for :math:`\chi_r^2 &gt; 1`,</span>
<span class="sd">    and is negative for :math:`\chi_r^2 &lt; 1`.  Also, the magnitude increases</span>
<span class="sd">    with :math:`\rho`, and decreases with :math:`\sigma_d`.  The final shape</span>
<span class="sd">    matrix is then defined as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        A^{-1} = \beta\, U S^{\gamma} V^T</span>

<span class="sd">    Note that as :math:`\gamma \rightarrow 0`, the kernel approaches that of</span>
<span class="sd">    a spheroid.  For :math:`\chi_r^2 &gt; 1`, the kernel approaches</span>
<span class="sd">    :math:`\bar{g}^2`.  When :math:`\chi_r^2 &lt; 1`, the kernel effectively</span>
<span class="sd">    rotates so that the fit becomes increasingly sensitive to samples along</span>
<span class="sd">    the direction of the derivative.  The overall size of the kernel remains</span>
<span class="sd">    constant since :math:`|S^{\gamma}| = |\bar{g}^2| = 1`.</span>

<span class="sd">    Finally, the only remaining factor to calculate is the scaling factor</span>
<span class="sd">    :math:`\beta` which is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \beta = \left( \frac{\chi_r}{|A_0|} \right)^{1/K}</span>

<span class="sd">    Note that this scaling has the effect of setting</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{|A_0|}{|A|} = \chi_r</span>

<span class="sd">    The user has the option of fixing the kernel in certain dimensions such</span>
<span class="sd">    that :math:`{A_0}_{k, k} = A_{k, k}`.  If this is the case, for any fixed</span>
<span class="sd">    dimension :math:`k` we set:</span>

<span class="sd">    .. math::</span>

<span class="sd">        {U S^{\gamma} V^T}_{k, k} = 1</span>

<span class="sd">        {U S^{\gamma} V^T}_{k, i \neq k}^2 = 0</span>

<span class="sd">        {U S^{\gamma} V^T}_{i \neq k, k}^2 = 0</span>

<span class="sd">    meaning the scaling is unaltered for dimensions :math:`k`, and no rotation</span>
<span class="sd">    will be applied to any other dimension with respect to :math:`k`.  Since</span>
<span class="sd">    the overall size must be controlled through fewer dimensions,</span>
<span class="sd">    :math:`\beta` must take the form of a diagonal matrix:</span>

<span class="sd">    .. math::</span>

<span class="sd">         diag(\beta)_{i \in fixed} = \frac{1}{2 \sigma_i^2}</span>
<span class="sd">         ,\,\,</span>
<span class="sd">         diag(\beta)_{i \notin fixed} =</span>
<span class="sd">             \left(</span>
<span class="sd">             \frac{\chi_r |A_0|}{|{U S^{\gamma} V^T}|}</span>
<span class="sd">             \prod_{i \in fixed}{2 \sigma_i^2}</span>
<span class="sd">             \right)^{1 / (K - K_{fixed})}</span>

<span class="sd">    Once again :math:`A^{-1} = \beta\, U S^{\gamma} V^T`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sigma : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The standard deviations of the Gaussian for each dimensional component</span>
<span class="sd">        used for the distance weighting of each sample in the initial fit.</span>
<span class="sd">    rchi2 : float</span>
<span class="sd">        The reduced chi-squared statistic of the fit.</span>
<span class="sd">    gradient_mscp : numpy.ndarray (n_dimensions, n_dimensions)</span>
<span class="sd">        An array where gradient_mscp[i, j] = derivative[i] * derivative[j] in</span>
<span class="sd">        dimensions i and j.  Please see :func:`derivative_mscp` for further</span>
<span class="sd">        information.  Must be Hermitian and real-valued (symmetric).</span>
<span class="sd">    density : float, optional</span>
<span class="sd">        The local relative density of the samples around the fit coordinate.  A</span>
<span class="sd">        value of 1 represents uniform distribution.  Values greater than 1</span>
<span class="sd">        indicate clustering around the fitting point, and values less than 1</span>
<span class="sd">        indicate that samples are sparsely distributed around the fitting</span>
<span class="sd">        point.  Please see :func:`relative_density` for further information.</span>
<span class="sd">    variance_offset : float, optional</span>
<span class="sd">        The variance at the fit coordinate determined from the sample</span>
<span class="sd">        coordinate distribution. i.e., if a fit is performed at the center of</span>
<span class="sd">        the sample distribution, the variance is zero.  If done at 2-sigma from</span>
<span class="sd">        the sample distribution center, the variance is 4.</span>
<span class="sd">    fixed : numpy.ndarray of bool (n_dimensions,), optional</span>
<span class="sd">        If supplied, `True` values indicate that the width of the Gaussian</span>
<span class="sd">        along the corresponding axis should not be altered in the output</span>
<span class="sd">        result.</span>
<span class="sd">    tolerance : float, optional</span>
<span class="sd">        The threshold below which SVD values are considered zero when</span>
<span class="sd">        determining the matrix rank of `derivative_mscp`.  Please</span>
<span class="sd">        see :func:`numpy.linalg.matrix_rank` for further information.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    shape_matrix : numpy.ndarray (n_dimensions, n_dimensions)</span>
<span class="sd">        A matrix defining the shape of the weighting kernel required by</span>
<span class="sd">        :func:`calculate_adaptive_distance_weights_shaped` to create a set of</span>
<span class="sd">        weighting factors.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_dimensions</span> <span class="o">=</span> <span class="n">gradient_mscp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">rchi2</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">n_adapt</span> <span class="o">=</span> <span class="n">n_dimensions</span>
    <span class="k">if</span> <span class="n">fixed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fast</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">fix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">b1</span><span class="p">)</span>  <span class="c1"># for Numba</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">fixed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">b1</span><span class="p">)</span>
        <span class="n">fast</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">fix</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">fast</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
                <span class="n">n_adapt</span> <span class="o">-=</span> <span class="n">fix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">rchi2</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_adapt</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># In case of a bad value, exact fit, or nothing to be done.</span>
        <span class="c1"># Just return the same input sigma values (as an inverse alpha).</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">shape_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                    <span class="n">shape_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">shape_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="n">shape_matrix</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="n">shape_matrix</span>

    <span class="n">rchi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">rchi2</span><span class="p">)</span>

    <span class="c1"># Define the shape of the matrix here (stretch and rotation).  It is</span>
    <span class="c1"># normalized since we are only interested in the shape at this point, not</span>
    <span class="c1"># the size.  If a shape cannot be determined, the solution is equal</span>
    <span class="c1"># to the scaled solution on a spheroid.</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">gradient_mscp</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">gradient_mscp</span><span class="p">,</span>
                                 <span class="n">tol</span><span class="o">=</span><span class="n">tolerance</span><span class="p">)</span> <span class="o">==</span> <span class="n">n_dimensions</span><span class="p">:</span>
            <span class="n">norm_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">gradient_mscp</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">norm_factor</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">if</span> <span class="n">norm_factor</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">norm_factor</span><span class="p">):</span>

            <span class="n">shape_matrix</span> <span class="o">=</span> <span class="n">gradient_mscp</span> <span class="o">/</span> <span class="p">(</span><span class="n">norm_factor</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n_dimensions</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">shape_matrix</span><span class="p">)):</span>
                <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">shape_matrix</span><span class="p">)</span>

                <span class="c1"># u and vh define the rotation, while s defines the stretch.</span>
                <span class="c1"># The stretch is reduced for low density/rchi2 and/or high</span>
                <span class="c1"># offset variance.</span>

                <span class="n">correction</span> <span class="o">=</span> <span class="n">stretch_correction</span><span class="p">(</span>
                    <span class="n">rchi</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">variance_offset</span><span class="p">)</span>

                <span class="n">s</span> <span class="o">**=</span> <span class="n">correction</span>
                <span class="n">shape_matrix</span> <span class="o">=</span> <span class="n">u</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">@</span> <span class="n">vh</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">shape_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shape_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shape_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="c1"># Now rescale according to the reduced chi-squared statistic in an attempt</span>
    <span class="c1"># to get rchi2 = 1.</span>

    <span class="n">inverse_alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">fast</span><span class="p">:</span>
        <span class="n">determinant</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
            <span class="n">determinant</span> <span class="o">*=</span> <span class="n">inverse_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">scale_factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">rchi</span> <span class="o">*</span> <span class="n">determinant</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">n_dimensions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">shape_matrix</span> <span class="o">*</span> <span class="n">scale_factor</span>

    <span class="n">initial_determinant</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">fixed_alpha_product</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">n_adapt</span> <span class="o">=</span> <span class="n">n_dimensions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="n">initial_determinant</span> <span class="o">*=</span> <span class="n">inverse_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">fix</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">fixed_alpha_product</span> <span class="o">*=</span> <span class="n">inverse_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">n_adapt</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="n">shape_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
                    <span class="n">shape_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="n">shape_matrix</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="n">shaped_determinant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">shape_matrix</span><span class="p">)</span> <span class="o">*</span> <span class="n">fixed_alpha_product</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="n">rchi</span> <span class="o">*</span> <span class="n">initial_determinant</span>
             <span class="o">/</span> <span class="n">shaped_determinant</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">n_adapt</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">fix</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">shape_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_alpha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">fix</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                    <span class="k">continue</span>
                <span class="n">shape_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale</span>

    <span class="k">return</span> <span class="n">shape_matrix</span></div>



<div class="viewcode-block" id="shaped_adaptive_weight_matrices">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.shaped_adaptive_weight_matrices">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">shaped_adaptive_weight_matrices</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">rchi2_values</span><span class="p">,</span> <span class="n">gradient_mscp</span><span class="p">,</span>
                                    <span class="n">density</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">variance_offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">fixed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper for `shaped_adaptive_weight_matrix` over multiple values.</span>

<span class="sd">    Please see :func:`shaped_adaptive_weight_matrix` for details on how the</span>
<span class="sd">    weighting kernel is modified using a scale factor and measure of the</span>
<span class="sd">    derivatives of the fitting function.  This function performs the</span>
<span class="sd">    calculation for multiple scaling factors (:math:`\chi_r^2`) and</span>
<span class="sd">    derivative measures.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sigma : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The standard deviations of the Gaussian for each dimensional component</span>
<span class="sd">        used for the distance weighting of each sample in the initial fit.</span>
<span class="sd">    rchi2_values : numpy.ndarray (n_sets, shape)</span>
<span class="sd">        The reduced chi-squared statistics of the fit for each data set.  Here,</span>
<span class="sd">        `shape` is an arbitrary array shape which depends upon the shape of</span>
<span class="sd">        the output fit coordinates defined by the user.</span>
<span class="sd">    gradient_mscp : numpy.ndarray (n_sets, shape, n_dimensions, n_dimensions)</span>
<span class="sd">        An array where gradient_mscp[i, j] = derivative[i] * derivative[j] in</span>
<span class="sd">        dimensions i and j.  Please see :func:`derivative_mscp` for further</span>
<span class="sd">        information.  The last two dimensions must be Hermitian and real-valued</span>
<span class="sd">        (symmetric) for each fit set/coordinate.</span>
<span class="sd">    density : numpy.ndarray (n_sets, shape)</span>
<span class="sd">        The local relative density of the samples around the fit coordinate.  A</span>
<span class="sd">        value of 1 represents uniform distribution.  Values greater than 1</span>
<span class="sd">        indicate clustering around the fitting point, and values less than 1</span>
<span class="sd">        indicate that samples are sparsely distributed around the fitting</span>
<span class="sd">        point.  Please see :func:`relative_density` for further information.</span>
<span class="sd">    variance_offsets : numpy.ndarray (n_sets, shape)</span>
<span class="sd">        The variance at the fit coordinate determined from the sample</span>
<span class="sd">        coordinate distribution. i.e., if a fit is performed at the center of</span>
<span class="sd">        the sample distribution, the variance is zero.  If done at 2-sigma from</span>
<span class="sd">        the sample distribution center, the variance is 4.</span>
<span class="sd">    fixed : numpy.ndarray of bool (n_dimensions,), optional</span>
<span class="sd">        If supplied, `True` values indicate that the width of the Gaussian</span>
<span class="sd">        along the corresponding axis should not be altered in the output</span>
<span class="sd">        result.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    shape_matrices : numpy.ndarray (n_sets, shape, n_dimensions, n_dimensions)</span>
<span class="sd">        Shape matrices defined for each set/coordinate.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">gradient_mscp</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">rchi2_values</span><span class="o">.</span><span class="n">size</span>
    <span class="n">flat_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,)</span> <span class="o">+</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>

    <span class="n">shape_matrices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flat_shape</span><span class="p">)</span>

    <span class="n">flat_matrices</span> <span class="o">=</span> <span class="n">gradient_mscp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">flat_shape</span><span class="p">)</span>
    <span class="n">flat_rchi2</span> <span class="o">=</span> <span class="n">rchi2_values</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">variance_offsets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">flat_offsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">flat_rchi2</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">flat_offsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">variance_offsets</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">density</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">flat_density</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">flat_rchi2</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">flat_density</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">density</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">shape_matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">shaped_adaptive_weight_matrix</span><span class="p">(</span>
            <span class="n">sigma</span><span class="p">,</span> <span class="n">flat_rchi2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">flat_matrices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">density</span><span class="o">=</span><span class="n">flat_density</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">variance_offset</span><span class="o">=</span><span class="n">flat_offsets</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">fixed</span><span class="o">=</span><span class="n">fixed</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">shape_matrices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span></div>



<div class="viewcode-block" id="stretch_correction">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.stretch_correction">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">stretch_correction</span><span class="p">(</span><span class="n">rchi2</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">variance_offset</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A sigmoid function used by the &quot;shaped&quot; adaptive resampling algorithm.</span>

<span class="sd">    This sigmoid function is applied when determining the severity of stretch</span>
<span class="sd">    (:math:`s`) applied to principle axes of a rotated weighting kernel.  The</span>
<span class="sd">    correction term (:math:`\gamma`) is applied as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        s_{corrected} = s^\gamma</span>

<span class="sd">    Since the stretch values are determined from the singular values of</span>
<span class="sd">    a normalized Hermitian matrix :math:`A` (see</span>
<span class="sd">    :func:`shaped_adaptive_weight_matrix`), where :math:`|A| \equiv 1`, then:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \prod_{k=1}^{K}{s_k} = \prod_{k=1}^{K}{s_{corrected, k}} = 1</span>

<span class="sd">    in :math:`K` dimensions.  In other words, this does not affect the overall</span>
<span class="sd">    size (or volume) of the weighting kernel.</span>

<span class="sd">    The correction factor is calculated using :func:`half_max_sigmoid` using</span>
<span class="sd">    :math:`c=1`, lower and upper asymptotes as -1 and 1, such that the midpoint</span>
<span class="sd">    is fixed at zero when :math:`x=0`.  After making the necessary</span>
<span class="sd">    substitutions, the correction factor is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \gamma = \frac{2}</span>
<span class="sd">                 {\left( {1 + (2^{\nu} - 1)e^{B(1 - x)}} \right)^{1/\nu}} - 1</span>

<span class="sd">    We then set the rate as :math:`B = \rho` where :math:`\rho` is the</span>
<span class="sd">    `density` as determined by :func:`relative_density`, and the point of</span>
<span class="sd">    inflection as :math:`exp(\sigma)` where :math:`\sigma^2` is the</span>
<span class="sd">    `variance_offset` as determined by :func:`offset_variance`.  Finally,</span>
<span class="sd">    setting :math:`x = \chi_r^2` we arrive at:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \gamma = \frac{2}</span>
<span class="sd">                 {\left(</span>
<span class="sd">                     {1 + (2^{exp(\sigma)} - 1)e^{\rho (1 - \chi_r^2)}}</span>
<span class="sd">                 \right)^{1/exp(\sigma)}} - 1</span>

<span class="sd">    As :math:`\gamma \rightarrow 0`, the resulting shape becomes more</span>
<span class="sd">    symmetrical.  This will be the case when the fitting point is away from</span>
<span class="sd">    the center of the sample distribution (high :math:`\sigma^2`), the fit</span>
<span class="sd">    occurs in a low density area (low :math:`\beta`), or</span>
<span class="sd">    :math:`\chi_r^2 \rightarrow 1`.</span>

<span class="sd">    It should be noted that :math:`s_{corrected} \rightarrow s` as</span>
<span class="sd">    :math:`\chi_r^2 \rightarrow \infty`.  However, in the range</span>
<span class="sd">    :math:`0 &lt; \chi_r^2 &lt; 1`, the correction factor is actually negative, with</span>
<span class="sd">    :math:`\gamma \rightarrow -1` as :math:`\chi_r^2 \rightarrow 0`.  This</span>
<span class="sd">    has the effect of effectively rotating the shape so that its major axis is</span>
<span class="sd">    perpendicular to the mean sample gradient rather than parallel.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rchi2 : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The reduced chi-squared statistic of the initial fit.</span>
<span class="sd">    density : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The local relative density at the fitting point (see</span>
<span class="sd">        :func:`relative_density`).</span>
<span class="sd">    variance_offset : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The variance at the fitting with respect to the coordinate distribution</span>
<span class="sd">        of the sample used in the fit.  Please see :func:`offset_variance` for</span>
<span class="sd">        further information.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    correction : numpy.ndarray</span>
<span class="sd">        The correction factor.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For high valued inflection points, :mod:`numpy` will set values in the</span>
<span class="sd">    denominator of the above equation to infinity, or 1, resulting in a</span>
<span class="sd">    misleading correction factor of :math:`\pm 1`.  In order to counter this,</span>
<span class="sd">    :func:`half_max_sigmoid` could not be used, and the calculation is done</span>
<span class="sd">    &quot;by hand&quot; with spurious values resulting in a correction factor of zero.</span>
<span class="sd">    This also requires some :mod:`numba` hackery resulting in the final output</span>
<span class="sd">    value being a `numpy.ndarray` in all cases.  When single valued inputs are</span>
<span class="sd">    supplied, the output will be a single-valued array of zero dimensions</span>
<span class="sd">    which should be suitable for subsequent calculations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance_offset</span><span class="p">))</span>  <span class="c1"># inflection point</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">density</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">rchi2</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">**</span> <span class="n">v</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">denominator</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">denominator</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">denominator</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">correction</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">denominator</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">v</span><span class="p">)))</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">denominator</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">denominator</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
            <span class="n">correction</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="n">correction</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span></div>



<div class="viewcode-block" id="sigmoid">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.sigmoid">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate a scaled and shifted logistic function.</span>

<span class="sd">    The sigmoid function has the form:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = \frac{1}{1 + e^{\beta (x - \alpha)}}</span>

<span class="sd">    where :math:`\beta` is the scaling `factor`, and :math:`\alpha` is an</span>
<span class="sd">    `offset` applied to `x`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The independent variable.  If an array is supplied, must be the same</span>
<span class="sd">        shape as `factor` and `offset` (if both/either are also arrays).</span>
<span class="sd">    factor : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The scaling factor applied to `x`.  If an array is supplied, must be</span>
<span class="sd">        the same shape as `x` and `offset` (if both/either are also arrays).</span>
<span class="sd">    offset : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The offset to applied to `x`.  If an array is supplied, must be</span>
<span class="sd">        the same shape as `x` and `factor` (if both/either are also arrays).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : float or numpy.ndarray (shape)</span>
<span class="sd">        The sigmoid function evaluated at `x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xx</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">offset</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">xx</span><span class="p">))</span></div>



<div class="viewcode-block" id="logistic_curve">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.logistic_curve">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">logistic_curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="mf">1.0</span>
                   <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the generalized logistic function.</span>

<span class="sd">    The generalized logistic function is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = A + \frac{K - A}</span>
<span class="sd">                        {\left( C + Q e^{-B(x - x_0)} \right)^{1/\nu}}</span>

<span class="sd">    Taken from Wikipedia contributors. (2020, June 11). Generalised logistic</span>
<span class="sd">    function. In Wikipedia, The Free Encyclopedia.</span>
<span class="sd">    Retrieved 23:51, July 6, 2020, from</span>
<span class="sd">    https://en.wikipedia.org/w/index.php?title=Generalised_logistic_function&amp;oldid=961965809</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The independent variable.</span>
<span class="sd">    x0 : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        An offset applied to `x`.</span>
<span class="sd">    k : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The upper asymptote when `c` is one.</span>
<span class="sd">    a : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The lower asymptote.</span>
<span class="sd">    c : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        Typically takes a value of 1.  Otherwise, the upper asymptote is</span>
<span class="sd">        a + ((k - a) / c^(1/v)).</span>
<span class="sd">    q : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        Related to the value of f(0).</span>
<span class="sd">    b : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The growth rate.</span>
<span class="sd">    v : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        Must be greater than zero.  Affects near which asymptote the maximum</span>
<span class="sd">        growth occurs.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : float or numpy.ndarray (shape)</span>
<span class="sd">        The logistic function evaluated at `x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x0</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="p">((</span><span class="n">k</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="p">(</span><span class="n">q</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">b</span> <span class="o">*</span> <span class="n">t</span><span class="p">)))</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">v</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">result</span></div>



<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">richards_curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate a Richards&#39; curve.</span>

<span class="sd">    The Richards&#39; curve is a special case of the generalized logistic curve</span>
<span class="sd">    (see :func:`logistic_curve`) for :math:`c=1`, and :math:`v=q`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = A + \frac{K - A}</span>
<span class="sd">                {\left( 1 + Q e^{-B(x - x_0)} \right)^{1/Q}}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The independent variable.</span>
<span class="sd">    q : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        Related to the value of f(0).  Fixes the point of inflection.</span>
<span class="sd">    a : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The lower asymptote.</span>
<span class="sd">    k : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The upper asymptote.</span>
<span class="sd">    b : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The growth rate.</span>
<span class="sd">    x0 : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The value of `x` at which maximum growth occurs.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : float or numpy.ndarray (shape)</span>
<span class="sd">        The Richards&#39; curve evaluated at `x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">logistic_curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">q</span><span class="p">)</span>


<div class="viewcode-block" id="half_max_sigmoid">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.half_max_sigmoid">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">half_max_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_half</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="mf">1.0</span>
                     <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate a special case of the logistic function where f(x0) = 0.5.</span>

<span class="sd">    The generalized logistic function is given as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(x) = A + \frac{K - A}</span>
<span class="sd">                        {\left( C + Q e^{-B(x - x_0)} \right)^{1/\nu}}</span>

<span class="sd">    and may be evaluated with :func:`logistic_curve`.</span>

<span class="sd">    We can manipulate this function so that :math:`f(x_{half}) = (K + A) / 2`</span>
<span class="sd">    (the midpoint of the function) by setting the location of maximum growth</span>
<span class="sd">    (:math:`x_0`) to occur at:</span>

<span class="sd">    .. math::</span>

<span class="sd">        x_0 = x_{half} + \frac{1}{B}</span>
<span class="sd">                         \ln{\left( \frac{2^\nu - C}{Q} \right)}</span>

<span class="sd">    Since a logarithm is required, it is incumbent on the user to ensure that</span>
<span class="sd">    no logarithms are taken of any quantity :math:`\leq 0`, i.e.,</span>
<span class="sd">    :math:`(2^\nu - C) / Q &gt; 0`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : int or float or numpy.ndarray (shape)</span>
<span class="sd">        The independent variable.</span>
<span class="sd">    x_half : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The x value for which f(x) = 0.5.</span>
<span class="sd">    k : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The upper asymptote when `c` is one.</span>
<span class="sd">    a : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The lower asymptote.</span>
<span class="sd">    c : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        Typically takes a value of 1.  Otherwise, the upper asymptote is</span>
<span class="sd">        a + ((k - a) / c^(1/v)).</span>
<span class="sd">    q : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        Related to the value of f(0).  Fixes the point of inflection.  In this</span>
<span class="sd">        implementation, `q` is completely factored out after simplifying and</span>
<span class="sd">        does not have any affec</span>
<span class="sd">    b : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        The growth rate.</span>
<span class="sd">    v : int or float or numpy.ndarray (shape), optional</span>
<span class="sd">        Must be greater than zero.  Affects near which asymptote the maximum</span>
<span class="sd">        growth occurs (point of inflection).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : float or numpy.ndarray</span>
<span class="sd">        The half-max sigmoid evaluated at `x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(((</span><span class="mi">2</span> <span class="o">**</span> <span class="n">v</span><span class="p">)</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">/</span> <span class="n">q</span><span class="p">)</span> <span class="o">/</span> <span class="n">b</span>  <span class="c1"># Note that q is irrelevant</span>
    <span class="k">return</span> <span class="n">logistic_curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x_half</span> <span class="o">+</span> <span class="n">dx</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">)</span></div>



<div class="viewcode-block" id="solve_fits">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_fits">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_fits</span><span class="p">(</span><span class="n">sample_indices</span><span class="p">,</span> <span class="n">sample_coordinates</span><span class="p">,</span> <span class="n">sample_phi_terms</span><span class="p">,</span>
               <span class="n">sample_data</span><span class="p">,</span> <span class="n">sample_error</span><span class="p">,</span> <span class="n">sample_mask</span><span class="p">,</span>
               <span class="n">fit_coordinates</span><span class="p">,</span> <span class="n">fit_phi_terms</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">adaptive_alpha</span><span class="p">,</span>
               <span class="n">is_covar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mean_fit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cval</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
               <span class="n">fit_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">error_weighting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">estimate_covariance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">order_algorithm_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">order_term_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">derivative_term_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">derivative_term_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_algorithm_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">edge_threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">minimum_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">get_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">get_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_distance_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_rchi2</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">get_cross_derivatives</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_offset_variance</span><span class="o">=</span><span class="kc">True</span>
               <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve all fits within one intersection block.</span>

<span class="sd">    This function is a wrapper for :func:`solve_fit` over all data sets and</span>
<span class="sd">    fit points.  The main computations here involve:</span>

<span class="sd">        1. Creating and populating the output arrays.</span>
<span class="sd">        2. Selecting the correct samples within the region of each fitting</span>
<span class="sd">           window.</span>
<span class="sd">        3. Calculating the full weighting factors for the fits.</span>

<span class="sd">    For further details on the actual fitting, please see :func:`solve_fit`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sample_indices : numba.typed.List</span>
<span class="sd">        A list of 1-dimensional numpy.ndarray (dtype=int) of length n_fits.</span>
<span class="sd">        Each list element `sample_indices[i]`, contains the indices of samples</span>
<span class="sd">        within the &quot;window&quot; region of `fit_indices[i]`.</span>
<span class="sd">    sample_coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The independent coordinates for each sample in n_dimensions</span>
<span class="sd">    sample_phi_terms : numpy.ndarray (n_terms, n_samples)</span>
<span class="sd">        The polynomial terms of `sample_coordinates`.  Please see</span>
<span class="sd">        :func:`polynomial_terms` for further details.</span>
<span class="sd">    sample_data : numpy.ndarray (n_sets, n_samples)</span>
<span class="sd">        The dependent values of the samples for n_sets, each containing</span>
<span class="sd">        n_samples.</span>
<span class="sd">    sample_error : numpy.ndarray (n_sets, n_samples)</span>
<span class="sd">        The associated 1-sigma error values for each sample in each set.  The</span>
<span class="sd">        user may also supply an array of shape (n_sets, 1) in which case all</span>
<span class="sd">        samples in a set will share the same associated error value.  If</span>
<span class="sd">        the shape is set to (n_sets, 0), this indicates that no error values</span>
<span class="sd">        are available for the samples.</span>
<span class="sd">    sample_mask : numpy.ndarray (n_sets, n_samples)</span>
<span class="sd">        A mask where `False` indicates that the associated sample should be</span>
<span class="sd">        excluded from all fits.</span>
<span class="sd">    fit_coordinates : numpy.ndarray (n_dimensions, n_fits)</span>
<span class="sd">        The independent variables at each fit coordinate in d_dimensions.</span>
<span class="sd">    fit_phi_terms : numpy.ndarray (n_terms, n_fits)</span>
<span class="sd">        The polynomial terms of `fit_coordinates`.  Please see</span>
<span class="sd">        :func:`polynomial_terms` for further details.</span>
<span class="sd">    order : numpy.ndarray</span>
<span class="sd">        The desired order of the fit as a (1,) or (n_dimensions,) array.  If</span>
<span class="sd">        only a single value is supplied, it will be applied over all</span>
<span class="sd">        dimensions.</span>
<span class="sd">    alpha : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        A distance weighting scaling factor per dimension.  The weighting</span>
<span class="sd">        kernel is applied equally to all sets and samples.  For further</span>
<span class="sd">        details, please see :func:`calculate_distance_weights`.  Will be</span>
<span class="sd">        overridden by `adaptive_alpha` if `adaptive_alpha.size &gt; 0`.</span>
<span class="sd">    adaptive_alpha : numpy.ndarray</span>
<span class="sd">        Shape = (n_samples, n_sets, [1 or n_dimensions], n_dimensions).</span>
<span class="sd">        Defines a weighting kernel for each sample in each set.  The function</span>
<span class="sd">        :func:`calculate_adaptive_distance_weights_scaled` will be used for</span>
<span class="sd">        kernels of shape (1, n_dimensions), and</span>
<span class="sd">        :func:`calculate_adaptive_distance_weights_shaped` will be used for</span>
<span class="sd">        kernels of shape (n_dimensions, n_dimensions).  `adaptive_alpha` is</span>
<span class="sd">        a required parameter due to Numba constraints, and will override</span>
<span class="sd">        the `alpha` parameter unless it has a size of 0.  Therefore, to</span>
<span class="sd">        disable, please set the size of any dimension to zero.</span>
<span class="sd">    is_covar : bool, optional</span>
<span class="sd">        If `True`, indicates that `sample_data` contains covariance values</span>
<span class="sd">        that should be propagated through algorithm.  If this is the case,</span>
<span class="sd">        polynomial fitting is disabled, and a weighted variance is calculated</span>
<span class="sd">        instead.</span>
<span class="sd">    mean_fit : bool, optional</span>
<span class="sd">        If `True`, a weighted mean is performed instead of calculating a</span>
<span class="sd">        polynomial fit.</span>
<span class="sd">    cval : float, optional</span>
<span class="sd">        In a case that a fit is unable to be calculated at certain location,</span>
<span class="sd">        `cval` determines the fill value for the output `fit` array at those</span>
<span class="sd">        locations.</span>
<span class="sd">    fit_threshold : float, optional</span>
<span class="sd">        If fit_threshold is non-zero, perform a check on the goodness of the</span>
<span class="sd">        fit.  When the reduced-chi statistic is greater than</span>
<span class="sd">        abs(fit_threshold), the fit is determined to be a failure, and a</span>
<span class="sd">        replacement value is used. If `fit_threshold` &lt; 0, failed fit values</span>
<span class="sd">        will be set to `cval`.  If `fit_threshold` &gt; 0, failed fit values will</span>
<span class="sd">        be replaced by the weighted mean.</span>
<span class="sd">    error_weighting : bool, optional</span>
<span class="sd">        If `True`, weight the samples in the fit by the inverse variance</span>
<span class="sd">        (1 / sample_error^2) in addition to distance weighting.</span>
<span class="sd">    estimate_covariance : bool, optional</span>
<span class="sd">        If True, calculate the covariance of the fit coefficients using</span>
<span class="sd">        :func:`estimated_covariance_matrix_inverse`.  Otherwise, use</span>
<span class="sd">        :func:`covariance_matrix_inverse`.</span>
<span class="sd">    order_algorithm_idx : int, optional</span>
<span class="sd">        An integer specifying which polynomial order validation algorithm to</span>
<span class="sd">        use.  The default (1), will always be the more robust of all available</span>
<span class="sd">        options.  For further information, please see :func:`check_edges`.</span>
<span class="sd">    order_term_indices : numpy.ndarray (&gt; max(order) + 1,), optional</span>
<span class="sd">        A 1-dimensional lookup array for use in determining the correct phi</span>
<span class="sd">        terms to use for a given polynomial order.  The order validation</span>
<span class="sd">        algorithm ensures a fit of the requested order is possible.  If not,</span>
<span class="sd">        and the orders are equal in all dimensions, it may also optionally</span>
<span class="sd">        return a suggested order.  In this case, `order_term_indices` is used</span>
<span class="sd">        to select the correct `sample_phi_terms` and `fit_phi_terms` for a</span>
<span class="sd">        given order (k), where terms are extracted via</span>
<span class="sd">        `phi[order_term_indices[k]:order_term_indices[k + 2]]`.</span>
<span class="sd">    derivative_term_map : numpy.ndarray, optional</span>
<span class="sd">        A mapping array for the determination of derivatives from the</span>
<span class="sd">        coefficients of the fit, and available terms in &quot;phi&quot;.  The shape of</span>
<span class="sd">        the array is (n_dimensions, 3, n_derivative_terms).  This is only</span>
<span class="sd">        required if the gradient is required as an output.  For a full</span>
<span class="sd">        description of the derivative map, please see</span>
<span class="sd">        :func:`polynomial_derivative_map`.</span>
<span class="sd">    derivative_term_indices : numpy.ndarray (max(order) + 1,), optional</span>
<span class="sd">        If the fit order is allowed to vary, gives the indices in</span>
<span class="sd">        `derivative_term_map` for a given symmetrical order.  The correct</span>
<span class="sd">        `derivative_term_map` mapping for order k is given as</span>
<span class="sd">        `derivative_term_map[:, :, indices[k]:indices[k + 2]]`.</span>
<span class="sd">    edge_algorithm_idx : int, optional</span>
<span class="sd">        Integer specifying the algorithm used to determine whether a fit should</span>
<span class="sd">        be attempted with respect to the sample distribution.  Please see</span>
<span class="sd">        :func:`check_edges` for further information.  The default (1), is</span>
<span class="sd">        always the most robust of the available algorithms.</span>
<span class="sd">    edge_threshold : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        A threshold parameter determining how close an edge should be to the</span>
<span class="sd">        center of the distribution during :func:`check_edges`.  Higher values</span>
<span class="sd">        result in an edge closer to the sample mean.  A value should be</span>
<span class="sd">        provided for each dimension.  A zero value in any dimension will result</span>
<span class="sd">        in an infinite edge for that dimension.</span>
<span class="sd">    minimum_points : int, optional</span>
<span class="sd">        Certain order validation algorithms check the number of available</span>
<span class="sd">        samples as a means to determine what order of fit is appropriate.</span>
<span class="sd">        If pre-calculated for the base `order`, it may be passed in here for</span>
<span class="sd">        a slight speed advantage.</span>
<span class="sd">    get_error : bool, optional</span>
<span class="sd">        If `True`, return the error on the fit.</span>
<span class="sd">    get_counts : bool, optional</span>
<span class="sd">        If `True`, return the number of samples used when determining the fit</span>
<span class="sd">        at each fitting point.</span>
<span class="sd">    get_weights : bool, optional</span>
<span class="sd">        If `True`, return the sum of all sample weights used in determining the</span>
<span class="sd">        fit at each point.</span>
<span class="sd">    get_distance_weights : bool, optional</span>
<span class="sd">        If `True`, return the sum of only the distance weights used in</span>
<span class="sd">        determining the fit at each point.</span>
<span class="sd">    get_rchi2 : bool, optional</span>
<span class="sd">        If `True`, return the reduced chi-squared statistic for each of the</span>
<span class="sd">        fitted points.</span>
<span class="sd">    get_cross_derivatives : bool, optional</span>
<span class="sd">        If `True`, return the derivative mean-squared-cross-products of the</span>
<span class="sd">        samples for each of the fitted points.  See :func:`derivative_mscp`</span>
<span class="sd">        for further information.</span>
<span class="sd">    get_offset_variance : bool optional</span>
<span class="sd">        If `True`, return the offset of the fitting point from the sample</span>
<span class="sd">        distribution.  See :func:`offset_variance` for further information.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fit_results : 8-tuple of numpy.ndarray</span>
<span class="sd">        fit_results[0]: Fitted values.</span>
<span class="sd">        fit_results[1]: Error on the fit.</span>
<span class="sd">        fit_results[2]: Number of samples in each fit.</span>
<span class="sd">        fit_results[3]: Weight sums.</span>
<span class="sd">        fit_results[4]: Distance weight sums.</span>
<span class="sd">        fit_results[5]: Reduced chi-squared statistic.</span>
<span class="sd">        fit_results[6]: Derivative mean-squared-cross-products.</span>
<span class="sd">        fit_results[7]: Offset variances from the sample distribution center.</span>

<span class="sd">        All arrays except for fit_results[6] have the shape (n_sets, n_fits)</span>
<span class="sd">        or (0, 0) depending on whether `get_&lt;name&gt;` is `True` or `False`</span>
<span class="sd">        respectively.  The derivative MSCP is of shape</span>
<span class="sd">        (n_sets, n_fits, n_dimensions, n_dimensions) if requested, and</span>
<span class="sd">        (1, 0, 0, 0) otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_sets</span> <span class="o">=</span> <span class="n">sample_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_fits</span> <span class="o">=</span> <span class="n">fit_coordinates</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">fit_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_error</span><span class="p">:</span>
        <span class="n">error_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">error_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_counts</span><span class="p">:</span>
        <span class="n">counts_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">counts_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_weights</span><span class="p">:</span>
        <span class="n">weights_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_distance_weights</span><span class="p">:</span>
        <span class="n">distance_weights_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">distance_weights_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_rchi2</span><span class="p">:</span>
        <span class="n">rchi2_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rchi2_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_cross_derivatives</span><span class="p">:</span>
        <span class="n">cov_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">,</span> <span class="n">n_dimensions</span><span class="p">),</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cov_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_offset_variance</span><span class="p">:</span>
        <span class="n">offset_variance_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_sets</span><span class="p">,</span> <span class="n">n_fits</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">offset_variance_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_sets</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">n_fits</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">fit_out</span><span class="p">,</span> <span class="n">error_out</span><span class="p">,</span>
                <span class="n">counts_out</span><span class="p">,</span> <span class="n">weights_out</span><span class="p">,</span> <span class="n">distance_weights_out</span><span class="p">,</span>
                <span class="n">rchi2_out</span><span class="p">,</span> <span class="n">cov_out</span><span class="p">,</span> <span class="n">offset_variance_out</span><span class="p">)</span>

    <span class="n">adaptive_smoothing</span> <span class="o">=</span> <span class="n">adaptive_alpha</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">adaptive_smoothing</span><span class="p">:</span>
        <span class="n">shaped</span> <span class="o">=</span> <span class="n">adaptive_alpha</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shaped</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># For Numba compilation success</span>
    <span class="n">dummy_fixed_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">dummy_adaptive_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">fit_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_indices</span><span class="p">)):</span>

        <span class="n">fit_coordinate</span> <span class="o">=</span> <span class="n">fit_coordinates</span><span class="p">[:,</span> <span class="n">fit_index</span><span class="p">]</span>
        <span class="n">fit_phi</span> <span class="o">=</span> <span class="n">fit_phi_terms</span><span class="p">[:,</span> <span class="n">fit_index</span><span class="p">]</span>

        <span class="c1"># Arrays for all datasets within window region</span>
        <span class="n">window_indices</span> <span class="o">=</span> <span class="n">sample_indices</span><span class="p">[</span><span class="n">fit_index</span><span class="p">]</span>
        <span class="n">window_coordinates</span> <span class="o">=</span> <span class="n">sample_coordinates</span><span class="p">[:,</span> <span class="n">window_indices</span><span class="p">]</span>
        <span class="n">window_values</span> <span class="o">=</span> <span class="n">sample_data</span><span class="p">[:,</span> <span class="n">window_indices</span><span class="p">]</span>
        <span class="n">window_mask</span> <span class="o">=</span> <span class="n">sample_mask</span><span class="p">[:,</span> <span class="n">window_indices</span><span class="p">]</span>
        <span class="n">window_phi</span> <span class="o">=</span> <span class="n">sample_phi_terms</span><span class="p">[:,</span> <span class="n">window_indices</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">sample_error</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">window_error</span> <span class="o">=</span> <span class="n">sample_error</span><span class="p">[:,</span> <span class="n">window_indices</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Single values are expanded in apply_mask_to_set_arrays</span>
            <span class="n">window_error</span> <span class="o">=</span> <span class="n">sample_error</span>

        <span class="c1"># Determine distance weighting</span>
        <span class="k">if</span> <span class="n">adaptive_smoothing</span><span class="p">:</span>
            <span class="n">fixed_weights</span> <span class="o">=</span> <span class="n">dummy_fixed_weights</span>
            <span class="k">if</span> <span class="n">shaped</span><span class="p">:</span>
                <span class="n">adaptive_weights</span> <span class="o">=</span> <span class="n">calculate_adaptive_distance_weights_shaped</span><span class="p">(</span>
                    <span class="n">window_coordinates</span><span class="p">,</span> <span class="n">fit_coordinate</span><span class="p">,</span>
                    <span class="n">adaptive_alpha</span><span class="p">[</span><span class="n">window_indices</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">adaptive_weights</span> <span class="o">=</span> <span class="n">calculate_adaptive_distance_weights_scaled</span><span class="p">(</span>
                    <span class="n">window_coordinates</span><span class="p">,</span> <span class="n">fit_coordinate</span><span class="p">,</span>
                    <span class="n">adaptive_alpha</span><span class="p">[</span><span class="n">window_indices</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">adaptive_weights</span> <span class="o">=</span> <span class="n">dummy_adaptive_weights</span>
            <span class="n">fixed_weights</span> <span class="o">=</span> <span class="n">calculate_distance_weights</span><span class="p">(</span>
                <span class="n">window_coordinates</span><span class="p">,</span> <span class="n">fit_coordinate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">data_set</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sets</span><span class="p">):</span>

            <span class="k">if</span> <span class="n">adaptive_smoothing</span><span class="p">:</span>
                <span class="n">window_distance_weights</span> <span class="o">=</span> <span class="n">adaptive_weights</span><span class="p">[</span><span class="n">data_set</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">window_distance_weights</span> <span class="o">=</span> <span class="n">fixed_weights</span>

            <span class="p">(</span><span class="n">fitted_value</span><span class="p">,</span>
             <span class="n">fitted_error</span><span class="p">,</span>
             <span class="n">counts</span><span class="p">,</span>
             <span class="n">weightsum</span><span class="p">,</span>
             <span class="n">distance_weight</span><span class="p">,</span>
             <span class="n">rchi2</span><span class="p">,</span>
             <span class="n">deriv_mscp</span><span class="p">,</span>
             <span class="n">variance_offset</span>
             <span class="p">)</span> <span class="o">=</span> <span class="n">solve_fit</span><span class="p">(</span><span class="n">window_coordinates</span><span class="p">,</span> <span class="n">window_phi</span><span class="p">,</span>
                           <span class="n">window_values</span><span class="p">[</span><span class="n">data_set</span><span class="p">],</span> <span class="n">window_error</span><span class="p">[</span><span class="n">data_set</span><span class="p">],</span>
                           <span class="n">window_mask</span><span class="p">[</span><span class="n">data_set</span><span class="p">],</span> <span class="n">window_distance_weights</span><span class="p">,</span>
                           <span class="n">fit_coordinate</span><span class="p">,</span> <span class="n">fit_phi</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span>
                           <span class="n">is_covar</span><span class="o">=</span><span class="n">is_covar</span><span class="p">,</span> <span class="n">fit_threshold</span><span class="o">=</span><span class="n">fit_threshold</span><span class="p">,</span>
                           <span class="n">mean_fit</span><span class="o">=</span><span class="n">mean_fit</span><span class="p">,</span> <span class="n">cval</span><span class="o">=</span><span class="n">cval</span><span class="p">,</span>
                           <span class="n">error_weighting</span><span class="o">=</span><span class="n">error_weighting</span><span class="p">,</span>
                           <span class="n">estimate_covariance</span><span class="o">=</span><span class="n">estimate_covariance</span><span class="p">,</span>
                           <span class="n">order_algorithm_idx</span><span class="o">=</span><span class="n">order_algorithm_idx</span><span class="p">,</span>
                           <span class="n">term_indices</span><span class="o">=</span><span class="n">order_term_indices</span><span class="p">,</span>
                           <span class="n">derivative_term_map</span><span class="o">=</span><span class="n">derivative_term_map</span><span class="p">,</span>
                           <span class="n">derivative_term_indices</span><span class="o">=</span><span class="n">derivative_term_indices</span><span class="p">,</span>
                           <span class="n">edge_algorithm_idx</span><span class="o">=</span><span class="n">edge_algorithm_idx</span><span class="p">,</span>
                           <span class="n">edge_threshold</span><span class="o">=</span><span class="n">edge_threshold</span><span class="p">,</span>
                           <span class="n">minimum_points</span><span class="o">=</span><span class="n">minimum_points</span><span class="p">,</span>
                           <span class="n">get_error</span><span class="o">=</span><span class="n">get_error</span><span class="p">,</span> <span class="n">get_weights</span><span class="o">=</span><span class="n">get_weights</span><span class="p">,</span>
                           <span class="n">get_distance_weights</span><span class="o">=</span><span class="n">get_distance_weights</span><span class="p">,</span>
                           <span class="n">get_rchi2</span><span class="o">=</span><span class="n">get_rchi2</span><span class="p">,</span>
                           <span class="n">get_cross_derivatives</span><span class="o">=</span><span class="n">get_cross_derivatives</span><span class="p">,</span>
                           <span class="n">get_offset_variance</span><span class="o">=</span><span class="n">get_offset_variance</span><span class="p">)</span>

            <span class="n">fit_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">fitted_value</span>
            <span class="k">if</span> <span class="n">get_error</span><span class="p">:</span>
                <span class="n">error_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">fitted_error</span>

            <span class="k">if</span> <span class="n">get_counts</span><span class="p">:</span>
                <span class="n">counts_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">counts</span>

            <span class="k">if</span> <span class="n">get_weights</span><span class="p">:</span>
                <span class="n">weights_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">weightsum</span>

            <span class="k">if</span> <span class="n">get_distance_weights</span><span class="p">:</span>
                <span class="n">distance_weights_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">distance_weight</span>

            <span class="k">if</span> <span class="n">get_rchi2</span><span class="p">:</span>
                <span class="n">rchi2_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">rchi2</span>

            <span class="k">if</span> <span class="n">get_cross_derivatives</span> <span class="ow">and</span> <span class="n">deriv_mscp</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">cov_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">deriv_mscp</span>

            <span class="k">if</span> <span class="n">get_offset_variance</span><span class="p">:</span>
                <span class="n">offset_variance_out</span><span class="p">[</span><span class="n">data_set</span><span class="p">,</span> <span class="n">fit_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">variance_offset</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">fit_out</span><span class="p">,</span> <span class="n">error_out</span><span class="p">,</span>
            <span class="n">counts_out</span><span class="p">,</span> <span class="n">weights_out</span><span class="p">,</span> <span class="n">distance_weights_out</span><span class="p">,</span>
            <span class="n">rchi2_out</span><span class="p">,</span> <span class="n">cov_out</span><span class="p">,</span> <span class="n">offset_variance_out</span><span class="p">)</span></div>



<div class="viewcode-block" id="solve_fit">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.solve_fit">[docs]</a>
<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">solve_fit</span><span class="p">(</span><span class="n">window_coordinates</span><span class="p">,</span> <span class="n">window_phi</span><span class="p">,</span> <span class="n">window_values</span><span class="p">,</span> <span class="n">window_error</span><span class="p">,</span>
              <span class="n">window_mask</span><span class="p">,</span> <span class="n">window_distance_weights</span><span class="p">,</span>
              <span class="n">fit_coordinate</span><span class="p">,</span> <span class="n">fit_phi</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span>
              <span class="n">is_covar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fit_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">mean_fit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">cval</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">error_weighting</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">estimate_covariance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">order_algorithm_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">term_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">derivative_term_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">derivative_term_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">edge_algorithm_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">edge_threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">minimum_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">get_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">get_distance_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_rchi2</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">get_cross_derivatives</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_offset_variance</span><span class="o">=</span><span class="kc">True</span>
              <span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solve for a fit at a single coordinate.</span>

<span class="sd">    Solves a polynomial fit of the form:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(\Phi) = \hat{c} \cdot \Phi</span>

<span class="sd">    where :math:`\hat{c}` are the derived polynomial coefficients for the</span>
<span class="sd">    :math:`\Phi` terms.  The :math:`\Phi` terms are derived from the</span>
<span class="sd">    independent values of the samples within the window region of the fit</span>
<span class="sd">    coordinate, and from the fit coordinates themselves (see</span>
<span class="sd">    :func:`polynomial_terms` for further details).</span>

<span class="sd">    The :math:`\Phi` terms are pre-calculated early in the resampling algorithm</span>
<span class="sd">    as this is a relatively cheap calculation, and we do not want to repeat</span>
<span class="sd">    the same calculation multiple times.  For example, if sample[1] is within</span>
<span class="sd">    the window region of point[1] and point[2], there should be no need</span>
<span class="sd">    to repeat the polynomial term calculation twice.  Initially, one might</span>
<span class="sd">    think that the actual coordinates could then be discarded, but there are a</span>
<span class="sd">    number of calculations that depend on the sample coordinates relative to</span>
<span class="sd">    the fitting points, which must therefore be dealt with &quot;on-the-fly&quot;.</span>

<span class="sd">    EDGE CHECKING</span>

<span class="sd">    The first of the on-the-fly calculation is the &quot;edge check&quot;.  Generally,</span>
<span class="sd">    polynomial fits are not well-defined away from the sample distribution</span>
<span class="sd">    from which they were derived.  This is especially true for higher order</span>
<span class="sd">    fits that may fit the sample distribution well, but start to deviate wildly</span>
<span class="sd">    when evaluated outside of the distribution.  The edge check step defines a</span>
<span class="sd">    border around the distribution, outside of which the fit will be aborted.</span>
<span class="sd">    There are a number of algorithms available which vary in robustness and</span>
<span class="sd">    speed.  Please see :func:`check_edges` for details on available algorithms.</span>

<span class="sd">    ORDER CHECKING</span>

<span class="sd">    The next step is to determine if it is possible to perform a polynomial</span>
<span class="sd">    fit of the given order.  For example, a 1-dimensional 2nd order polynomial</span>
<span class="sd">    fit can only be derived from a minimum of 3 samples.  Additionally, if</span>
<span class="sd">    some samples share the same coordinate, the fit becomes underdetermined, or</span>
<span class="sd">    if dealing with multidimensional data, one needs to ensure that the samples</span>
<span class="sd">    are not colinear.  If we also wish to propagate or derive valid errors, we</span>
<span class="sd">    should ensure the system is overdetermined.  There are a number of order</span>
<span class="sd">    checking algorithms which vary in robustness and speed.  Please see</span>
<span class="sd">    :func:`check_orders` for details on the available algorithms.</span>

<span class="sd">    There are two available actions if the samples fail the order check.  The</span>
<span class="sd">    first (default) is to simply abort fitting.  The second option is to</span>
<span class="sd">    lower the order of fit until the samples meet the order check requirements.</span>
<span class="sd">    This is only possible if the fit order is equal across all dimensions.  To</span>
<span class="sd">    allow for variable orders, set the `order_term_indices` (see parameter</span>
<span class="sd">    descriptions) to a valid value, and update `window_phi` and `fit_phi`</span>
<span class="sd">    accordingly.</span>

<span class="sd">    FITTING</span>

<span class="sd">    If the above checks pass, a fit can be attempted.  There are actually</span>
<span class="sd">    three types of fit that may be performed.  The first is the standard</span>
<span class="sd">    polynomial fit described above.  The second is a weighted mean which may</span>
<span class="sd">    explicitly be performed by setting `mean_fit` to `True`, or may be</span>
<span class="sd">    performed on-the-fly if the order was lowered to zero during the order</span>
<span class="sd">    check.  Finally, if `is_covar` was set to `True`, the `window_values` are</span>
<span class="sd">    considered covariances to propagate, and a fit will derived by propagating</span>
<span class="sd">    a weighted variance.</span>

<span class="sd">    FINAL VALIDATION</span>

<span class="sd">    If a polynomial fit was performed, a final check may be performed to</span>
<span class="sd">    confirm that the solution does not deviate to significantly from the</span>
<span class="sd">    expected values.  This is done by evaluating the reduced chi-squared</span>
<span class="sd">    statistic of the fit (:math:`\chi_r^2`).  If</span>
<span class="sd">    :math:`\sqrt{\chi_r^2} &gt; | \text{fit\_threshold} |`, the fit is not</span>
<span class="sd">    accepted, and is aborted if `fit_threshold` &lt; 0, or set to the weighted</span>
<span class="sd">    mean of the samples if `fit_threshold` &gt; 0.  No validation will be</span>
<span class="sd">    performed if `fit_threshold` is set to zero (default).  Note that</span>
<span class="sd">    `window_error` must be supplied in order for validation to be meaningful.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    window_coordinates : numpy.ndarray (n_dimensions, n_samples)</span>
<span class="sd">        The independent coordinates within the window region of the fitting</span>
<span class="sd">        coordinate.</span>
<span class="sd">    window_phi : numpy.ndarray (n_terms, n_samples)</span>
<span class="sd">        The polynomial terms of `window_coordinates`.  Please see</span>
<span class="sd">        :func:`polynomial_terms` for further details.</span>
<span class="sd">    window_values : numpy.ndarray (n_samples,)</span>
<span class="sd">        The dependent values of the samples.</span>
<span class="sd">    window_error : numpy.ndarray (n_samples,)</span>
<span class="sd">        The associated 1-sigma error values for each sample in each set.  The</span>
<span class="sd">        user may also supply an array of shape (1,) in which case all</span>
<span class="sd">        samples in a set will share the same associated error value.  If the</span>
<span class="sd">        shape is set to (0,) this indicates that no error values are available</span>
<span class="sd">        for the samples.</span>
<span class="sd">    window_mask : numpy.ndarray (n_samples,)</span>
<span class="sd">        A mask where `False` indicates that the associated sample should be</span>
<span class="sd">        excluded from the fit.</span>
<span class="sd">    window_distance_weights : numpy.ndarray (n_samples,)</span>
<span class="sd">        The distance weighting factors applied to each sample in the fit.</span>
<span class="sd">    fit_coordinate : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        The coordinate of the fitting point.</span>
<span class="sd">    fit_phi : numpy.ndarray (n_terms,)</span>
<span class="sd">        The polynomial of `fit_coordinate`.  Please see</span>
<span class="sd">        :func:`polynomial_terms` for further details.</span>
<span class="sd">    order : numpy.ndarray</span>
<span class="sd">        The desired order of the fit as a (1,) or (n_dimensions,) array.  If</span>
<span class="sd">        only a single value is supplied, it will be applied over all</span>
<span class="sd">        dimensions.</span>
<span class="sd">    is_covar : bool, optional</span>
<span class="sd">        If `True`, indicates that `window_values` contains covariance values</span>
<span class="sd">        that should be propagated through algorithm.  If this is the case,</span>
<span class="sd">        polynomial fitting is disabled, and a weighted variance is calculated</span>
<span class="sd">        instead.</span>
<span class="sd">    fit_threshold : float, optional</span>
<span class="sd">        If fit_threshold is non-zero, perform a check on the goodness of the</span>
<span class="sd">        fit.  When the reduced-chi statistic is greater than</span>
<span class="sd">        abs(fit_threshold), the fit is determined to be a failure, and a</span>
<span class="sd">        replacement value is used. If `fit_threshold` &lt; 0, failed fit values</span>
<span class="sd">        will be set to `cval`.  If `fit_threshold` &gt; 0, failed fit values</span>
<span class="sd">        will be replaced by the weighted mean.</span>
<span class="sd">    mean_fit : bool, optional</span>
<span class="sd">        If `True`, a weighted mean is performed instead of calculating a</span>
<span class="sd">        polynomial fit.</span>
<span class="sd">    cval : float, optional</span>
<span class="sd">        In a case that a fit is unable to be calculated at certain location,</span>
<span class="sd">        `cval` determines the returned fit value.</span>
<span class="sd">    error_weighting : bool, optional</span>
<span class="sd">        If `True`, weight the samples in the fit by the inverse variance</span>
<span class="sd">        (1 / window_error^2) in addition to distance weighting.</span>
<span class="sd">    estimate_covariance : bool, optional</span>
<span class="sd">        If `True`, when determining the error on the fit and reduced</span>
<span class="sd">        chi-squared, calculate the covariance of the fit coefficients using</span>
<span class="sd">        :func:`estimated_covariance_matrix_inverse`.  Otherwise, use</span>
<span class="sd">        :func:`covariance_matrix_inverse`.</span>
<span class="sd">    order_algorithm_idx : int, optional</span>
<span class="sd">        An integer specifying which polynomial order validation algorithm to</span>
<span class="sd">        use.  The default (1), will always be the more robust of all available</span>
<span class="sd">        options.  For further information, please see :func:`check_edges`.</span>
<span class="sd">    term_indices : numpy.ndarray (&gt; max(order) + 1,), optional</span>
<span class="sd">        A 1-dimensional lookup array for use in determining the correct phi</span>
<span class="sd">        terms to use for a given polynomial order.  The order validation</span>
<span class="sd">        algorithm ensures a fit of the requested order is possible.  If not,</span>
<span class="sd">        and the orders are equal in all dimensions, it may also optionally</span>
<span class="sd">        return a suggested order.  In this case, `order_term_indices` is used</span>
<span class="sd">        to select the correct `window_phi` and `fit_phi` for a given order (k),</span>
<span class="sd">        where terms are extracted via</span>
<span class="sd">        `phi[order_term_indices[k]:order_term_indices[k+1]]`.</span>
<span class="sd">    derivative_term_map : numpy.ndarray, optional</span>
<span class="sd">        A mapping array for the determination of derivatives from the</span>
<span class="sd">        coefficients of the fit, and available terms in &quot;phi&quot;.  The shape of</span>
<span class="sd">        the array is (n_dimensions, 3, n_derivative_terms).  This is only</span>
<span class="sd">        required if the gradient is required as an output.  For a full</span>
<span class="sd">        description of the derivative map, please see</span>
<span class="sd">        :func:`polynomial_derivative_map`.</span>
<span class="sd">    derivative_term_indices : numpy.ndarray (max(order) + 1,), optional</span>
<span class="sd">        If the fit order is allowed to vary, gives the indices in</span>
<span class="sd">        `derivative_term_map` for a given symmetrical order.  The correct</span>
<span class="sd">        `derivative_term_map` mapping for order k is given as</span>
<span class="sd">        `derivative_term_map[:, :, indices[k]:indices[k + 2]]`.</span>
<span class="sd">    edge_algorithm_idx : int, optional</span>
<span class="sd">        Integer specifying the algorithm used to determine whether a fit should</span>
<span class="sd">        be attempted with respect to the sample distribution.  Please see</span>
<span class="sd">        :func:`check_edges` for further information.  The default (1), is</span>
<span class="sd">        always the most robust of the available algorithms.</span>
<span class="sd">    edge_threshold : numpy.ndarray (n_dimensions,)</span>
<span class="sd">        A threshold parameter determining how close an edge should be to the</span>
<span class="sd">        center of the distribution during :func:`check_edges`.  Higher values</span>
<span class="sd">        result in an edge closer to the sample mean.  A value should be</span>
<span class="sd">        provided for each dimension.  A zero value in any dimension will result</span>
<span class="sd">        in an infinite edge for that dimension.</span>
<span class="sd">    minimum_points : int, optional</span>
<span class="sd">        Certain order validation algorithms check the number of available</span>
<span class="sd">        samples as a means to determine what order of fit is appropriate.</span>
<span class="sd">        If pre-calculated for the base `order`, it may be passed in here for</span>
<span class="sd">        a slight speed advantage.</span>
<span class="sd">    get_error : bool, optional</span>
<span class="sd">        If `True`, return the error on the fit.</span>
<span class="sd">    get_weights : bool, optional</span>
<span class="sd">        If `True`, return the sum of all sample weights used in determining the</span>
<span class="sd">        fit.</span>
<span class="sd">    get_distance_weights : bool, optional</span>
<span class="sd">        If `True`, return the sum of only the distance weights used in</span>
<span class="sd">        determining the fit.</span>
<span class="sd">    get_rchi2 : bool, optional</span>
<span class="sd">        If `True`, return the reduced chi-squared statistic for each of</span>
<span class="sd">        the fits.</span>
<span class="sd">    get_cross_derivatives : bool, optional</span>
<span class="sd">        If `True`, return the derivative mean-squared-cross-products of the</span>
<span class="sd">        samples in the fit.  See :func:`derivative_mscp` for further</span>
<span class="sd">        information.</span>
<span class="sd">    get_offset_variance : bool optional</span>
<span class="sd">        If `True`, return the offset of the fitting point from the sample</span>
<span class="sd">        distribution.  See :func:`offset_variance` for further information.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fit_result : 8-tuple</span>
<span class="sd">        fit_result[0]: Fitted value (float).</span>
<span class="sd">                       Set to `cval` on fit failure.</span>
<span class="sd">        fit_result[1]: Error on the fit (float).</span>
<span class="sd">                       Set to NaN on fit failure.</span>
<span class="sd">        fit_result[2]: Number of samples included in the fit (int).</span>
<span class="sd">                       Set to 0 on fit failure.</span>
<span class="sd">        fit_result[3]: Weight sum (float).</span>
<span class="sd">                       Set to 0.0 on fit failure.</span>
<span class="sd">        fit_result[4]: Distance weight sum (float).</span>
<span class="sd">                       Set to 0.0 on fit failure.</span>
<span class="sd">        fit_result[5]: Reduced chi-squared statistic (float).</span>
<span class="sd">                       Set to NaN on fit failure.</span>
<span class="sd">        fit_result[6]: Derivative mean-squared-cross-product (numpy.ndarray).</span>
<span class="sd">                       Set to shape (0, 0) on fit failure, and</span>
<span class="sd">                       (n_dimensions, n_dimensions) otherwise.</span>
<span class="sd">        fit_result[7]: Offset variance from the distribution center (float).</span>
<span class="sd">                       Set to NaN on fit failure.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Determine whether to check fits and what to do with failures</span>
    <span class="n">check_fit</span> <span class="o">=</span> <span class="n">fit_threshold</span> <span class="o">!=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">check_fit</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">fit_threshold</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">replace_rejects</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">fit_threshold</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">replace_rejects</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">replace_rejects</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Switches determining what needs to be calculated</span>
    <span class="n">rchi2_required</span> <span class="o">=</span> <span class="n">get_rchi2</span> <span class="ow">or</span> <span class="n">check_fit</span>
    <span class="n">weightsum_required</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean_fit</span> <span class="ow">or</span> <span class="n">get_error</span> <span class="ow">or</span> <span class="n">rchi2_required</span>
                          <span class="ow">or</span> <span class="n">is_covar</span> <span class="ow">or</span> <span class="n">get_weights</span><span class="p">)</span>

    <span class="n">order_varies</span> <span class="o">=</span> <span class="n">term_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="c1"># need to update mask and counts for zero/bad weights</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">update_mask</span><span class="p">(</span><span class="n">window_distance_weights</span><span class="p">,</span> <span class="n">window_mask</span><span class="p">)</span>

    <span class="c1"># The order is: fitted_value, fitted_error, counts,</span>
    <span class="c1">#               weight, distance_weight,</span>
    <span class="c1">#               rchi2, derivative_mscp, offset_variance</span>
    <span class="n">failure_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">cval</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">counts</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">failure_values</span>

    <span class="c1"># Check edges</span>
    <span class="k">if</span> <span class="n">edge_threshold</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">edge_thresh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">edge_thresh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">edge_threshold</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">check_edges</span><span class="p">(</span><span class="n">window_coordinates</span><span class="p">,</span> <span class="n">fit_coordinate</span><span class="p">,</span> <span class="n">window_mask</span><span class="p">,</span>
                       <span class="n">edge_thresh</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">edge_algorithm_idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">failure_values</span>

    <span class="c1"># Validate order</span>
    <span class="n">order</span> <span class="o">=</span> <span class="n">check_orders</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">window_coordinates</span><span class="p">,</span> <span class="n">fit_coordinate</span><span class="p">,</span>
                         <span class="n">order_algorithm_idx</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">window_mask</span><span class="p">,</span>
                         <span class="n">minimum_points</span><span class="o">=</span><span class="n">minimum_points</span><span class="p">,</span>
                         <span class="n">required</span><span class="o">=</span><span class="ow">not</span> <span class="n">order_varies</span><span class="p">,</span>
                         <span class="n">counts</span><span class="o">=</span><span class="n">counts</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">order</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">failure_values</span>

    <span class="c1"># Select the correct phi terms set in the case that orders vary</span>
    <span class="c1"># This only works for symmetric orders</span>
    <span class="k">if</span> <span class="n">derivative_term_map</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">derivative_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">derivative_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">derivative_term_map</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">order_varies</span> <span class="ow">and</span> <span class="n">term_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">order</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Should be equal for all dimensions</span>
        <span class="n">phi_term_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">term_indices</span><span class="p">)</span>
        <span class="n">i0</span><span class="p">,</span> <span class="n">i1</span> <span class="o">=</span> <span class="n">phi_term_indices</span><span class="p">[</span><span class="n">o</span><span class="p">:</span> <span class="n">o</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span>
        <span class="n">fit_phi</span> <span class="o">=</span> <span class="n">fit_phi</span><span class="p">[</span><span class="n">i0</span><span class="p">:</span> <span class="n">i1</span><span class="p">]</span>
        <span class="n">window_phi</span> <span class="o">=</span> <span class="n">window_phi</span><span class="p">[</span><span class="n">i0</span><span class="p">:</span> <span class="n">i1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">get_cross_derivatives</span> <span class="ow">and</span> <span class="n">derivative_term_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deriv_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">derivative_term_indices</span><span class="p">)</span>
            <span class="n">i0</span><span class="p">,</span> <span class="n">i1</span> <span class="o">=</span> <span class="n">deriv_indices</span><span class="p">[</span><span class="n">o</span><span class="p">:</span> <span class="n">o</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span>
            <span class="n">derivative_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">derivative_map</span><span class="p">,</span>
                                        <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">int64</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="n">i0</span><span class="p">:</span> <span class="n">i1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">derivative_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">i8</span><span class="p">)</span>

    <span class="c1"># Remove masked values</span>
    <span class="n">window_values</span><span class="p">,</span> <span class="n">window_phi</span><span class="p">,</span> <span class="n">window_error</span><span class="p">,</span> <span class="n">window_distance_weights</span> <span class="o">=</span> \
        <span class="n">apply_mask_to_set_arrays</span><span class="p">(</span><span class="n">window_mask</span><span class="p">,</span> <span class="n">window_values</span><span class="p">,</span> <span class="n">window_phi</span><span class="p">,</span>
                                 <span class="n">window_error</span><span class="p">,</span> <span class="n">window_distance_weights</span><span class="p">,</span>
                                 <span class="n">counts</span><span class="p">)</span>

    <span class="c1"># If the order varies, and the suggested order is set to zero in all</span>
    <span class="c1"># dimensions, a mean fit should be performed.</span>
    <span class="n">calculate_weightsum</span> <span class="o">=</span> <span class="n">weightsum_required</span>
    <span class="n">calculate_mean</span> <span class="o">=</span> <span class="n">mean_fit</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">calculate_mean</span> <span class="ow">and</span> <span class="n">order_varies</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">order</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">o</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">calculate_mean</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">calculate_weightsum</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">get_cross_derivatives</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Calculate fitting weights</span>
    <span class="n">window_full_weights</span> <span class="o">=</span> <span class="n">calculate_fitting_weights</span><span class="p">(</span>
        <span class="n">window_error</span><span class="p">,</span> <span class="n">window_distance_weights</span><span class="p">,</span> <span class="n">error_weighting</span><span class="o">=</span><span class="n">error_weighting</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">calculate_weightsum</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">window_full_weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weightsum</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">failure_values</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weightsum</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># For Numba happiness</span>

    <span class="k">if</span> <span class="n">is_covar</span><span class="p">:</span>
        <span class="c1"># Propagate variance</span>
        <span class="n">fitted_value</span> <span class="o">=</span> <span class="n">weighted_mean_variance</span><span class="p">(</span>
            <span class="n">window_values</span><span class="p">,</span> <span class="n">window_full_weights</span><span class="p">,</span> <span class="n">weightsum</span><span class="o">=</span><span class="n">weightsum</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">get_distance_weights</span><span class="p">:</span>
            <span class="n">total_distance_weights</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">window_distance_weights</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">total_distance_weights</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">if</span> <span class="n">get_weights</span><span class="p">:</span>
            <span class="n">total_weights</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">window_full_weights</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">total_weights</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">fitted_value</span><span class="p">,</span>
                <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>  <span class="c1"># error</span>
                <span class="n">counts</span><span class="p">,</span>
                <span class="n">total_weights</span><span class="p">,</span>
                <span class="n">total_distance_weights</span><span class="p">,</span>
                <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>  <span class="c1"># rchi2</span>
                <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>  <span class="c1"># derivative_mscp</span>
                <span class="n">np</span><span class="o">.</span><span class="n">nan</span>  <span class="c1"># offset_variance</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="n">calculate_mean</span><span class="p">:</span>  <span class="c1"># i.e. symmetric order 0 (mean)</span>
        <span class="n">fitted_value</span><span class="p">,</span> <span class="n">fitted_variance</span><span class="p">,</span> <span class="n">rchi2</span> <span class="o">=</span> <span class="n">solve_mean_fit</span><span class="p">(</span>
            <span class="n">window_values</span><span class="p">,</span> <span class="n">window_error</span><span class="p">,</span> <span class="n">window_full_weights</span><span class="p">,</span>
            <span class="n">weightsum</span><span class="o">=</span><span class="n">weightsum</span><span class="p">,</span>
            <span class="n">calculate_variance</span><span class="o">=</span><span class="n">get_error</span><span class="p">,</span>
            <span class="n">calculate_rchi2</span><span class="o">=</span><span class="n">rchi2_required</span><span class="p">)</span>

        <span class="n">deriv_mscp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>  <span class="c1"># solve with polynomial</span>
        <span class="n">fitted_value</span><span class="p">,</span> <span class="n">fitted_variance</span><span class="p">,</span> <span class="n">rchi2</span><span class="p">,</span> <span class="n">deriv_mscp</span> <span class="o">=</span> \
            <span class="n">solve_polynomial_fit</span><span class="p">(</span>
                <span class="n">window_phi</span><span class="p">,</span> <span class="n">fit_phi</span><span class="p">,</span> <span class="n">window_values</span><span class="p">,</span> <span class="n">window_error</span><span class="p">,</span>
                <span class="n">window_distance_weights</span><span class="p">,</span> <span class="n">window_full_weights</span><span class="p">,</span>
                <span class="n">derivative_term_map</span><span class="o">=</span><span class="n">derivative_map</span><span class="p">,</span>
                <span class="n">calculate_variance</span><span class="o">=</span><span class="n">get_error</span><span class="p">,</span>
                <span class="n">calculate_rchi2</span><span class="o">=</span><span class="n">rchi2_required</span><span class="p">,</span>
                <span class="n">calculate_derivative_mscp</span><span class="o">=</span><span class="n">get_cross_derivatives</span><span class="p">,</span>
                <span class="n">error_weighting</span><span class="o">=</span><span class="n">error_weighting</span><span class="p">,</span>
                <span class="n">estimate_covariance</span><span class="o">=</span><span class="n">estimate_covariance</span><span class="p">)</span>

        <span class="c1"># Check the fit didn&#39;t explode (optional)</span>
        <span class="k">if</span> <span class="n">check_fit</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">rchi2</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">fit_threshold</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">replace_rejects</span><span class="p">:</span>  <span class="c1"># Use a weighted mean instead</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">calculate_weightsum</span><span class="p">:</span>
                        <span class="c1"># Then it should be calculated now</span>
                        <span class="n">weightsum</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">window_full_weights</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">weightsum</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="k">return</span> <span class="n">failure_values</span>

                    <span class="n">fitted_value</span><span class="p">,</span> <span class="n">fitted_variance</span><span class="p">,</span> <span class="n">rchi2</span> <span class="o">=</span> <span class="n">solve_mean_fit</span><span class="p">(</span>
                        <span class="n">window_values</span><span class="p">,</span> <span class="n">window_error</span><span class="p">,</span> <span class="n">window_full_weights</span><span class="p">,</span>
                        <span class="n">weightsum</span><span class="o">=</span><span class="n">weightsum</span><span class="p">,</span>
                        <span class="n">calculate_variance</span><span class="o">=</span><span class="n">get_error</span><span class="p">,</span>
                        <span class="n">calculate_rchi2</span><span class="o">=</span><span class="n">rchi2_required</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">fitted_value</span> <span class="o">=</span> <span class="n">cval</span>
                    <span class="n">fitted_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                    <span class="n">rchi2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fitted_value</span> <span class="o">=</span> <span class="n">cval</span>
                <span class="n">fitted_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="n">rchi2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="n">fitted_error</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fitted_variance</span><span class="p">)</span> <span class="k">if</span> <span class="n">get_error</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">if</span> <span class="n">get_distance_weights</span><span class="p">:</span>
        <span class="n">distance_weight</span> <span class="o">=</span> <span class="n">array_sum</span><span class="p">(</span><span class="n">window_distance_weights</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">distance_weight</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">if</span> <span class="n">get_offset_variance</span><span class="p">:</span>
        <span class="n">variance_offset</span> <span class="o">=</span> <span class="n">offset_variance</span><span class="p">(</span>
            <span class="n">window_coordinates</span><span class="p">,</span> <span class="n">fit_coordinate</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">window_mask</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">variance_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">fitted_value</span><span class="p">,</span>
            <span class="n">fitted_error</span><span class="p">,</span>
            <span class="n">counts</span><span class="p">,</span>
            <span class="n">weightsum</span><span class="p">,</span>
            <span class="n">distance_weight</span><span class="p">,</span>
            <span class="n">rchi2</span><span class="p">,</span>
            <span class="n">deriv_mscp</span><span class="p">,</span>
            <span class="n">variance_offset</span><span class="p">)</span></div>



<div class="viewcode-block" id="fasttrapz">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.fasttrapz">[docs]</a>
<span class="nd">@nb</span><span class="o">.</span><span class="n">njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nogil</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fastmath</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fasttrapz</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>  <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fast 1-D integration using Trapezium method.</span>

<span class="sd">    Approximates the integration of a 1-D discrete valued function</span>
<span class="sd">    :math:`y_i = f(x_i)` with :math:`N` measurements as:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \int_a^b f(x) \approx \frac{1}{2}</span>
<span class="sd">           \sum_{i=1}^{N}{ \left( y_{i - 1} + y_i \right)</span>
<span class="sd">                           \left( x_i - x_{i - 1} \right) }</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : numpy.ndarray (N,)</span>
<span class="sd">        Dependent variable</span>
<span class="sd">    x : numpy.ndarray (N,)</span>
<span class="sd">        Independent variable</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    area : float</span>
<span class="sd">        The integrated area</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span>
    <span class="n">area</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">area</span> <span class="o">+=</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y0</span> <span class="o">+</span> <span class="n">y1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">x1</span>
        <span class="n">y0</span> <span class="o">=</span> <span class="n">y1</span>

    <span class="k">return</span> <span class="n">area</span></div>



<div class="viewcode-block" id="convert_to_numba_list">
<a class="viewcode-back" href="../../source/grig.html#grig.resample_utils.convert_to_numba_list">[docs]</a>
<span class="k">def</span> <span class="nf">convert_to_numba_list</span><span class="p">(</span><span class="n">thing</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a Python iterable to a Numba list for use in jitted functions.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    thing : iterable</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numba.typed.List()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_list</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">typed</span><span class="o">.</span><span class="n">List</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">thing</span><span class="p">:</span>
        <span class="n">new_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_list</span></div>



<span class="k">def</span> <span class="nf">convert_to_list</span><span class="p">(</span><span class="n">thing</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a Python iterable to a standard list suitable for jit functions.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    thing : iterable</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">thing</span><span class="p">:</span>
        <span class="n">new_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_list</span>


<span class="k">def</span> <span class="nf">get_object_size</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the size of an object and all members in bytes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obj : object</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    bytes : int</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">blacklist</span> <span class="o">=</span> <span class="nb">type</span><span class="p">,</span> <span class="n">ModuleType</span><span class="p">,</span> <span class="n">FunctionType</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">blacklist</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;get_object_size() does not take argument of type: </span><span class="si">%s</span><span class="s1">&#39;</span>
                        <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>
    <span class="n">seen_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">size</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">objects</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span><span class="p">]</span>
    <span class="k">while</span> <span class="n">objects</span><span class="p">:</span>
        <span class="n">need_referents</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objects</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">blacklist</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">id</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen_ids</span><span class="p">:</span>
                <span class="n">seen_ids</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>
                <span class="n">size</span> <span class="o">+=</span> <span class="n">sys</span><span class="o">.</span><span class="n">getsizeof</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
                <span class="n">need_referents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
        <span class="n">objects</span> <span class="o">=</span> <span class="n">get_referents</span><span class="p">(</span><span class="o">*</span><span class="n">need_referents</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">size</span>
</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Grig 1.0.1.dev4+g74c80f7 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">grig.resample_utils</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2023, SOFIA-USRA.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    </div>
  </body>
</html>